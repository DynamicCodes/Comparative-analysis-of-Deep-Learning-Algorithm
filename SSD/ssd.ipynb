{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ssd.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PvZrbX5YeH5l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595997263492,"user_tz":-330,"elapsed":1629,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"ef807fce-0123-4678-e61e-4b533561c563"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"imuk5k9_eUxY","colab_type":"code","colab":{}},"source":["function ClickConnect(){\n","console.log(\"Working\"); \n","document.querySelector(\"colab-toolbar-button#connect\").click() \n","}\n","setInterval(ClickConnect,60000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2CocVTJ-vZhY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591858554673,"user_tz":-330,"elapsed":6468,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"68c96e62-f135-4ca7-ca80-92f418bfe39f"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3aEcNpg8yLwk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":538},"executionInfo":{"status":"ok","timestamp":1591881548479,"user_tz":-330,"elapsed":9243,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"0d618551-afd9-4230-adeb-bd39be6a2898"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 212515756207765008\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 9346960378543533356\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 17219115301114144828\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 11330115994\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 2993700541118929653\n","physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lZJgUP9_vbPa","colab_type":"code","colab":{}},"source":["#pip install tensorflow==1.12.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Gx28k6mvVwu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1595997293437,"user_tz":-330,"elapsed":24787,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"6fce692d-9d75-4f73-8fd2-3734a9d61ddc"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7hzaNgICewc4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1595997300107,"user_tz":-330,"elapsed":5292,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"57752b37-c080-4429-f5ab-141daf6a74c7"},"source":["!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive"],"execution_count":3,"outputs":[{"output_type":"stream","text":["203.jpg  a.jpg\t    faster  j.mp4\t\t     plot_graph.ipynb  un.jpg\n","215.jpg  d.jpg\t    f.jpg   MCA04_presentation.pptx  ssd\t       yolov3\n","271.jpg  encrypted  g.jpg   output.avi\t\t     tensorflow        yolov4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nnt-7qFof5_W","colab_type":"code","colab":{}},"source":["import cv2\n","print(cv2.__version__)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j--ao5TqvFy1","colab_type":"code","colab":{}},"source":["###!cp -r /mydrive/faster/training ./"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AyUS5LhEg704","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595997375995,"user_tz":-330,"elapsed":70989,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"91e093d0-0e0e-4ecf-b181-a6e92ca26830"},"source":["!cp /mydrive/tensorflow/tensorflow.zip ./\n","!unzip tensorflow.zip -d ./"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","  inflating: ./models/research/object_detection/images/train/2120.xml  \n","  inflating: ./models/research/object_detection/images/train/2212.xml  \n","  inflating: ./models/research/object_detection/images/train/2468.xml  \n","  inflating: ./models/research/object_detection/images/train/1044.jpg  \n","  inflating: ./models/research/object_detection/images/train/1733.jpg  \n","  inflating: ./models/research/object_detection/images/train/744.jpg  \n","  inflating: ./models/research/object_detection/images/train/2188.xml  \n","  inflating: ./models/research/object_detection/images/train/774.xml  \n","  inflating: ./models/research/object_detection/images/train/581.xml  \n","  inflating: ./models/research/object_detection/images/train/1386.xml  \n","  inflating: ./models/research/object_detection/images/train/2438.xml  \n","  inflating: ./models/research/object_detection/images/train/560.xml  \n","  inflating: ./models/research/object_detection/images/train/1802.xml  \n","  inflating: ./models/research/object_detection/images/train/1822.xml  \n","  inflating: ./models/research/object_detection/images/train/146.jpg  \n","  inflating: ./models/research/object_detection/images/train/2062.xml  \n","  inflating: ./models/research/object_detection/images/train/724.jpg  \n","  inflating: ./models/research/object_detection/images/train/804.jpg  \n","  inflating: ./models/research/object_detection/images/train/131.jpg  \n","  inflating: ./models/research/object_detection/images/train/1652.xml  \n","  inflating: ./models/research/object_detection/images/train/2013.xml  \n","  inflating: ./models/research/object_detection/images/train/763.xml  \n","  inflating: ./models/research/object_detection/images/train/1545.jpg  \n","  inflating: ./models/research/object_detection/images/train/2272.xml  \n","  inflating: ./models/research/object_detection/images/train/508.xml  \n","  inflating: ./models/research/object_detection/images/train/1254.jpg  \n","  inflating: ./models/research/object_detection/images/train/683.xml  \n","  inflating: ./models/research/object_detection/images/train/2343.jpg  \n","  inflating: ./models/research/object_detection/images/train/382.jpg  \n","  inflating: ./models/research/object_detection/images/train/1594.jpg  \n","  inflating: ./models/research/object_detection/images/train/2007.jpg  \n","  inflating: ./models/research/object_detection/images/train/1072.jpg  \n","  inflating: ./models/research/object_detection/images/train/367.jpg  \n","  inflating: ./models/research/object_detection/images/train/356.xml  \n","  inflating: ./models/research/object_detection/images/train/89.xml  \n","  inflating: ./models/research/object_detection/images/train/1853.xml  \n","  inflating: ./models/research/object_detection/images/train/661.jpg  \n","  inflating: ./models/research/object_detection/images/train/1917.jpg  \n","  inflating: ./models/research/object_detection/images/train/2361.jpg  \n","  inflating: ./models/research/object_detection/images/train/225.xml  \n","  inflating: ./models/research/object_detection/images/train/1823.xml  \n","  inflating: ./models/research/object_detection/images/train/1591.jpg  \n","  inflating: ./models/research/object_detection/images/train/1656.xml  \n","  inflating: ./models/research/object_detection/images/train/2408.xml  \n","  inflating: ./models/research/object_detection/images/train/2066.xml  \n","  inflating: ./models/research/object_detection/images/train/1142.xml  \n","  inflating: ./models/research/object_detection/images/train/1061.xml  \n","  inflating: ./models/research/object_detection/images/train/1568.jpg  \n","  inflating: ./models/research/object_detection/images/train/1860.jpg  \n","  inflating: ./models/research/object_detection/images/train/2179.jpg  \n","  inflating: ./models/research/object_detection/images/train/2314.jpg  \n","  inflating: ./models/research/object_detection/images/train/285.xml  \n","  inflating: ./models/research/object_detection/images/train/1440.xml  \n","  inflating: ./models/research/object_detection/images/train/1477.xml  \n","  inflating: ./models/research/object_detection/images/train/1694.xml  \n","  inflating: ./models/research/object_detection/images/train/2356.xml  \n","  inflating: ./models/research/object_detection/images/train/316.xml  \n","  inflating: ./models/research/object_detection/images/train/1944.xml  \n","  inflating: ./models/research/object_detection/images/train/1422.jpg  \n","  inflating: ./models/research/object_detection/images/train/2018.jpg  \n","  inflating: ./models/research/object_detection/images/train/2417.xml  \n","  inflating: ./models/research/object_detection/images/train/968.jpg  \n","  inflating: ./models/research/object_detection/images/train/1218.jpg  \n","  inflating: ./models/research/object_detection/images/train/1839.jpg  \n","  inflating: ./models/research/object_detection/images/train/1001.xml  \n","  inflating: ./models/research/object_detection/images/train/984.jpg  \n","  inflating: ./models/research/object_detection/images/train/2047.jpg  \n","  inflating: ./models/research/object_detection/images/train/721.xml  \n","  inflating: ./models/research/object_detection/images/train/2487.xml  \n","  inflating: ./models/research/object_detection/images/train/168.xml  \n","  inflating: ./models/research/object_detection/images/train/144.xml  \n","  inflating: ./models/research/object_detection/images/train/1036.jpg  \n","  inflating: ./models/research/object_detection/images/train/1267.jpg  \n","  inflating: ./models/research/object_detection/images/train/410.xml  \n","  inflating: ./models/research/object_detection/images/train/319.xml  \n","  inflating: ./models/research/object_detection/images/train/802.jpg  \n","  inflating: ./models/research/object_detection/images/train/784.xml  \n","  inflating: ./models/research/object_detection/images/train/64.jpg  \n","  inflating: ./models/research/object_detection/images/train/1921.xml  \n","  inflating: ./models/research/object_detection/images/train/309.xml  \n","  inflating: ./models/research/object_detection/images/train/2252.xml  \n","  inflating: ./models/research/object_detection/images/train/105.xml  \n","  inflating: ./models/research/object_detection/images/train/2458.jpg  \n","  inflating: ./models/research/object_detection/images/train/1221.xml  \n","  inflating: ./models/research/object_detection/images/train/1543.jpg  \n","  inflating: ./models/research/object_detection/images/train/1565.xml  \n","  inflating: ./models/research/object_detection/images/train/461.xml  \n","  inflating: ./models/research/object_detection/images/train/1513.jpg  \n","  inflating: ./models/research/object_detection/images/train/967.xml  \n","  inflating: ./models/research/object_detection/images/train/2055.jpg  \n","  inflating: ./models/research/object_detection/images/train/2336.jpg  \n","  inflating: ./models/research/object_detection/images/train/1073.xml  \n","  inflating: ./models/research/object_detection/images/train/2137.jpg  \n","  inflating: ./models/research/object_detection/images/train/1801.xml  \n","  inflating: ./models/research/object_detection/images/train/364.xml  \n","  inflating: ./models/research/object_detection/images/train/2237.jpg  \n","  inflating: ./models/research/object_detection/images/train/781.jpg  \n","  inflating: ./models/research/object_detection/images/train/720.xml  \n","  inflating: ./models/research/object_detection/images/train/1196.xml  \n","  inflating: ./models/research/object_detection/images/train/510.jpg  \n","  inflating: ./models/research/object_detection/images/train/318.xml  \n","  inflating: ./models/research/object_detection/images/train/1313.xml  \n","  inflating: ./models/research/object_detection/images/train/7.xml  \n","  inflating: ./models/research/object_detection/images/train/1445.jpg  \n","  inflating: ./models/research/object_detection/images/train/1154.jpg  \n","  inflating: ./models/research/object_detection/images/train/159.xml  \n","  inflating: ./models/research/object_detection/images/train/2127.jpg  \n","  inflating: ./models/research/object_detection/images/train/2083.jpg  \n","  inflating: ./models/research/object_detection/images/train/893.jpg  \n","  inflating: ./models/research/object_detection/images/train/1341.jpg  \n","  inflating: ./models/research/object_detection/images/train/46.jpg  \n","  inflating: ./models/research/object_detection/images/train/484.jpg  \n","  inflating: ./models/research/object_detection/images/train/1583.xml  \n","  inflating: ./models/research/object_detection/images/train/53.jpg  \n","  inflating: ./models/research/object_detection/images/train/919.xml  \n","  inflating: ./models/research/object_detection/images/train/759.jpg  \n","  inflating: ./models/research/object_detection/images/train/1860.xml  \n","  inflating: ./models/research/object_detection/images/train/2294.xml  \n","  inflating: ./models/research/object_detection/images/train/1795.xml  \n","  inflating: ./models/research/object_detection/images/train/602.jpg  \n","  inflating: ./models/research/object_detection/images/train/1083.jpg  \n","  inflating: ./models/research/object_detection/images/train/2472.jpg  \n","  inflating: ./models/research/object_detection/images/train/553.xml  \n","  inflating: ./models/research/object_detection/images/train/1807.jpg  \n","  inflating: ./models/research/object_detection/images/train/2425.xml  \n","  inflating: ./models/research/object_detection/images/train/636.xml  \n","  inflating: ./models/research/object_detection/images/train/1779.xml  \n","  inflating: ./models/research/object_detection/images/train/2261.xml  \n","  inflating: ./models/research/object_detection/images/train/2332.jpg  \n","  inflating: ./models/research/object_detection/images/train/1841.xml  \n","  inflating: ./models/research/object_detection/images/train/2312.xml  \n","  inflating: ./models/research/object_detection/images/train/317.jpg  \n","  inflating: ./models/research/object_detection/images/train/12.jpg  \n","  inflating: ./models/research/object_detection/images/train/1395.jpg  \n","  inflating: ./models/research/object_detection/images/train/1530.xml  \n","  inflating: ./models/research/object_detection/images/train/655.jpg  \n","  inflating: ./models/research/object_detection/images/train/350.jpg  \n","  inflating: ./models/research/object_detection/images/train/65.xml  \n","  inflating: ./models/research/object_detection/images/train/776.xml  \n","  inflating: ./models/research/object_detection/images/train/175.xml  \n","  inflating: ./models/research/object_detection/images/train/547.xml  \n","  inflating: ./models/research/object_detection/images/train/10.xml  \n","  inflating: ./models/research/object_detection/images/train/431.jpg  \n","  inflating: ./models/research/object_detection/images/train/1654.jpg  \n","  inflating: ./models/research/object_detection/images/train/1168.jpg  \n","  inflating: ./models/research/object_detection/images/train/1442.xml  \n","  inflating: ./models/research/object_detection/images/train/2185.jpg  \n","  inflating: ./models/research/object_detection/images/train/1054.jpg  \n","  inflating: ./models/research/object_detection/images/train/1642.xml  \n","  inflating: ./models/research/object_detection/images/train/345.jpg  \n","  inflating: ./models/research/object_detection/images/train/419.jpg  \n","  inflating: ./models/research/object_detection/images/train/311.xml  \n","  inflating: ./models/research/object_detection/images/train/1269.jpg  \n","  inflating: ./models/research/object_detection/images/train/1385.xml  \n","  inflating: ./models/research/object_detection/images/train/383.jpg  \n","  inflating: ./models/research/object_detection/images/train/1088.jpg  \n","  inflating: ./models/research/object_detection/images/train/1669.jpg  \n","  inflating: ./models/research/object_detection/images/train/1434.xml  \n","  inflating: ./models/research/object_detection/images/train/2192.xml  \n","  inflating: ./models/research/object_detection/images/train/1648.xml  \n","  inflating: ./models/research/object_detection/images/train/1256.jpg  \n","  inflating: ./models/research/object_detection/images/train/1244.jpg  \n","  inflating: ./models/research/object_detection/images/train/436.jpg  \n","  inflating: ./models/research/object_detection/images/train/1919.xml  \n","  inflating: ./models/research/object_detection/images/train/95.xml  \n","  inflating: ./models/research/object_detection/images/train/428.xml  \n","  inflating: ./models/research/object_detection/images/train/762.jpg  \n","  inflating: ./models/research/object_detection/images/train/5.xml  \n","  inflating: ./models/research/object_detection/images/train/527.xml  \n","  inflating: ./models/research/object_detection/images/train/1359.jpg  \n","  inflating: ./models/research/object_detection/images/train/127.jpg  \n","  inflating: ./models/research/object_detection/images/train/466.jpg  \n","  inflating: ./models/research/object_detection/images/train/2248.xml  \n","  inflating: ./models/research/object_detection/images/train/470.jpg  \n","  inflating: ./models/research/object_detection/images/train/450.jpg  \n","  inflating: ./models/research/object_detection/images/train/2506.jpg  \n","  inflating: ./models/research/object_detection/images/train/1663.jpg  \n","  inflating: ./models/research/object_detection/images/train/1893.xml  \n","  inflating: ./models/research/object_detection/images/train/699.jpg  \n","  inflating: ./models/research/object_detection/images/train/1324.xml  \n","  inflating: ./models/research/object_detection/images/train/124.xml  \n","  inflating: ./models/research/object_detection/images/train/855.jpg  \n","  inflating: ./models/research/object_detection/images/train/795.jpg  \n","  inflating: ./models/research/object_detection/images/train/2277.jpg  \n","  inflating: ./models/research/object_detection/images/train/1090.xml  \n","  inflating: ./models/research/object_detection/images/train/2411.xml  \n","  inflating: ./models/research/object_detection/images/train/1486.jpg  \n","  inflating: ./models/research/object_detection/images/train/1716.jpg  \n","  inflating: ./models/research/object_detection/images/train/483.xml  \n","  inflating: ./models/research/object_detection/images/train/2285.xml  \n","  inflating: ./models/research/object_detection/images/train/2115.xml  \n","  inflating: ./models/research/object_detection/images/train/1615.jpg  \n","  inflating: ./models/research/object_detection/images/train/407.xml  \n","  inflating: ./models/research/object_detection/images/train/1455.jpg  \n","  inflating: ./models/research/object_detection/images/train/511.jpg  \n","  inflating: ./models/research/object_detection/images/train/877.jpg  \n","  inflating: ./models/research/object_detection/images/train/390.jpg  \n","  inflating: ./models/research/object_detection/images/train/22.jpg  \n","  inflating: ./models/research/object_detection/images/train/2239.jpg  \n","  inflating: ./models/research/object_detection/images/train/1878.jpg  \n","  inflating: ./models/research/object_detection/images/train/1644.xml  \n","  inflating: ./models/research/object_detection/images/train/410.jpg  \n","  inflating: ./models/research/object_detection/images/train/1344.xml  \n","  inflating: ./models/research/object_detection/images/train/202.xml  \n","  inflating: ./models/research/object_detection/images/train/1981.jpg  \n","  inflating: ./models/research/object_detection/images/train/783.xml  \n","  inflating: ./models/research/object_detection/images/train/1108.xml  \n","  inflating: ./models/research/object_detection/images/train/959.xml  \n","  inflating: ./models/research/object_detection/images/train/2464.xml  \n","  inflating: ./models/research/object_detection/images/train/2.xml  \n","  inflating: ./models/research/object_detection/images/train/2456.jpg  \n","  inflating: ./models/research/object_detection/images/train/30.xml  \n","  inflating: ./models/research/object_detection/images/train/816.jpg  \n","  inflating: ./models/research/object_detection/images/train/2094.xml  \n","  inflating: ./models/research/object_detection/images/train/1900.xml  \n","  inflating: ./models/research/object_detection/images/train/254.jpg  \n","  inflating: ./models/research/object_detection/images/train/501.xml  \n","  inflating: ./models/research/object_detection/images/train/2112.xml  \n","  inflating: ./models/research/object_detection/images/train/1752.jpg  \n","  inflating: ./models/research/object_detection/images/train/259.xml  \n","  inflating: ./models/research/object_detection/images/train/191.jpg  \n","  inflating: ./models/research/object_detection/images/train/1863.xml  \n","  inflating: ./models/research/object_detection/images/train/1225.jpg  \n","  inflating: ./models/research/object_detection/images/train/1652.jpg  \n","  inflating: ./models/research/object_detection/images/train/1979.xml  \n","  inflating: ./models/research/object_detection/images/train/1515.xml  \n","  inflating: ./models/research/object_detection/images/train/1387.jpg  \n","  inflating: ./models/research/object_detection/images/train/1487.xml  \n","  inflating: ./models/research/object_detection/images/train/1230.xml  \n","  inflating: ./models/research/object_detection/images/train/675.xml  \n","  inflating: ./models/research/object_detection/images/train/954.jpg  \n","  inflating: ./models/research/object_detection/images/train/1363.jpg  \n","  inflating: ./models/research/object_detection/images/train/628.xml  \n","  inflating: ./models/research/object_detection/images/train/2305.xml  \n","  inflating: ./models/research/object_detection/images/train/535.jpg  \n","  inflating: ./models/research/object_detection/images/train/181.jpg  \n","  inflating: ./models/research/object_detection/images/train/809.jpg  \n","  inflating: ./models/research/object_detection/images/train/2075.jpg  \n","  inflating: ./models/research/object_detection/images/train/125.jpg  \n","  inflating: ./models/research/object_detection/images/train/2214.xml  \n","  inflating: ./models/research/object_detection/images/train/756.jpg  \n","  inflating: ./models/research/object_detection/images/train/196.xml  \n","  inflating: ./models/research/object_detection/images/train/17.xml  \n","  inflating: ./models/research/object_detection/images/train/1912.jpg  \n","  inflating: ./models/research/object_detection/images/train/900.xml  \n","  inflating: ./models/research/object_detection/images/train/1096.xml  \n","  inflating: ./models/research/object_detection/images/train/1585.xml  \n","  inflating: ./models/research/object_detection/images/train/1887.xml  \n","  inflating: ./models/research/object_detection/images/train/1028.xml  \n","  inflating: ./models/research/object_detection/images/train/1905.xml  \n","  inflating: ./models/research/object_detection/images/train/1750.jpg  \n","  inflating: ./models/research/object_detection/images/train/863.xml  \n","  inflating: ./models/research/object_detection/images/train/1526.jpg  \n","  inflating: ./models/research/object_detection/images/train/783.jpg  \n","  inflating: ./models/research/object_detection/images/train/961.xml  \n","  inflating: ./models/research/object_detection/images/train/2131.jpg  \n","  inflating: ./models/research/object_detection/images/train/1391.xml  \n","  inflating: ./models/research/object_detection/images/train/1512.jpg  \n","  inflating: ./models/research/object_detection/images/train/2036.jpg  \n","  inflating: ./models/research/object_detection/images/train/765.jpg  \n","  inflating: ./models/research/object_detection/images/train/1170.jpg  \n","  inflating: ./models/research/object_detection/images/train/1128.xml  \n","  inflating: ./models/research/object_detection/images/train/352.xml  \n","  inflating: ./models/research/object_detection/images/train/2123.jpg  \n","  inflating: ./models/research/object_detection/images/train/1425.jpg  \n","  inflating: ./models/research/object_detection/images/train/301.jpg  \n","  inflating: ./models/research/object_detection/images/train/2283.jpg  \n","  inflating: ./models/research/object_detection/images/train/1792.xml  \n","  inflating: ./models/research/object_detection/images/train/1203.xml  \n","  inflating: ./models/research/object_detection/images/train/1045.jpg  \n","  inflating: ./models/research/object_detection/images/train/99.jpg  \n","  inflating: ./models/research/object_detection/images/train/1561.xml  \n","  inflating: ./models/research/object_detection/images/train/704.jpg  \n","  inflating: ./models/research/object_detection/images/train/1873.xml  \n","  inflating: ./models/research/object_detection/images/train/825.xml  \n","  inflating: ./models/research/object_detection/images/train/1641.jpg  \n","  inflating: ./models/research/object_detection/images/train/345.xml  \n","  inflating: ./models/research/object_detection/images/train/2427.jpg  \n","  inflating: ./models/research/object_detection/images/train/1370.jpg  \n","  inflating: ./models/research/object_detection/images/train/2034.jpg  \n","  inflating: ./models/research/object_detection/images/train/448.jpg  \n","  inflating: ./models/research/object_detection/images/train/346.jpg  \n","  inflating: ./models/research/object_detection/images/train/1375.xml  \n","  inflating: ./models/research/object_detection/images/train/2248.jpg  \n","  inflating: ./models/research/object_detection/images/train/1776.xml  \n","  inflating: ./models/research/object_detection/images/train/2503.xml  \n","  inflating: ./models/research/object_detection/images/train/2480.xml  \n","  inflating: ./models/research/object_detection/images/train/2175.xml  \n","  inflating: ./models/research/object_detection/images/train/905.xml  \n","  inflating: ./models/research/object_detection/images/train/2447.xml  \n","  inflating: ./models/research/object_detection/images/train/2329.jpg  \n","  inflating: ./models/research/object_detection/images/train/459.jpg  \n","  inflating: ./models/research/object_detection/images/train/269.jpg  \n","  inflating: ./models/research/object_detection/images/train/1827.xml  \n","  inflating: ./models/research/object_detection/images/train/1447.xml  \n","  inflating: ./models/research/object_detection/images/train/1160.xml  \n","  inflating: ./models/research/object_detection/images/train/970.jpg  \n","  inflating: ./models/research/object_detection/images/train/1760.jpg  \n","  inflating: ./models/research/object_detection/images/train/1229.xml  \n","  inflating: ./models/research/object_detection/images/train/376.jpg  \n","  inflating: ./models/research/object_detection/images/train/1074.jpg  \n","  inflating: ./models/research/object_detection/images/train/995.xml  \n","  inflating: ./models/research/object_detection/images/train/947.jpg  \n","  inflating: ./models/research/object_detection/images/train/187.jpg  \n","  inflating: ./models/research/object_detection/images/train/2380.jpg  \n","  inflating: ./models/research/object_detection/images/train/2011.xml  \n","  inflating: ./models/research/object_detection/images/train/1290.xml  \n","  inflating: ./models/research/object_detection/images/train/671.xml  \n","  inflating: ./models/research/object_detection/images/train/1341.xml  \n","  inflating: ./models/research/object_detection/images/train/1852.xml  \n","  inflating: ./models/research/object_detection/images/train/1913.jpg  \n","  inflating: ./models/research/object_detection/images/train/841.xml  \n","  inflating: ./models/research/object_detection/images/train/2446.xml  \n","  inflating: ./models/research/object_detection/images/train/133.xml  \n","  inflating: ./models/research/object_detection/images/train/703.xml  \n","  inflating: ./models/research/object_detection/images/train/209.jpg  \n","  inflating: ./models/research/object_detection/images/train/1409.xml  \n","  inflating: ./models/research/object_detection/images/train/1753.jpg  \n","  inflating: ./models/research/object_detection/images/train/1022.jpg  \n","  inflating: ./models/research/object_detection/images/train/416.xml  \n","  inflating: ./models/research/object_detection/images/train/1146.jpg  \n","  inflating: ./models/research/object_detection/images/train/63.jpg  \n","  inflating: ./models/research/object_detection/images/train/717.xml  \n","  inflating: ./models/research/object_detection/images/train/2193.xml  \n","  inflating: ./models/research/object_detection/images/train/663.jpg  \n","  inflating: ./models/research/object_detection/images/train/2289.jpg  \n","  inflating: ./models/research/object_detection/images/train/1325.xml  \n","  inflating: ./models/research/object_detection/images/train/2008.jpg  \n","  inflating: ./models/research/object_detection/images/train/1121.xml  \n","  inflating: ./models/research/object_detection/images/train/1880.jpg  \n","  inflating: ./models/research/object_detection/images/train/2338.jpg  \n","  inflating: ./models/research/object_detection/images/train/1631.xml  \n","  inflating: ./models/research/object_detection/images/train/1762.xml  \n","  inflating: ./models/research/object_detection/images/train/2106.jpg  \n","  inflating: ./models/research/object_detection/images/train/2467.xml  \n","  inflating: ./models/research/object_detection/images/train/1453.xml  \n","  inflating: ./models/research/object_detection/images/train/956.xml  \n","  inflating: ./models/research/object_detection/images/train/1010.xml  \n","  inflating: ./models/research/object_detection/images/train/2390.jpg  \n","  inflating: ./models/research/object_detection/images/train/2170.xml  \n","  inflating: ./models/research/object_detection/images/train/2439.jpg  \n","  inflating: ./models/research/object_detection/images/train/518.xml  \n","  inflating: ./models/research/object_detection/images/train/101.xml  \n","  inflating: ./models/research/object_detection/images/train/866.xml  \n","  inflating: ./models/research/object_detection/images/train/968.xml  \n","  inflating: ./models/research/object_detection/images/train/40.xml  \n","  inflating: ./models/research/object_detection/images/train/2070.jpg  \n","  inflating: ./models/research/object_detection/images/train/86.jpg  \n","  inflating: ./models/research/object_detection/images/train/992.xml  \n","  inflating: ./models/research/object_detection/images/train/1989.jpg  \n","  inflating: ./models/research/object_detection/images/train/98.xml  \n","  inflating: ./models/research/object_detection/images/train/2370.xml  \n","  inflating: ./models/research/object_detection/images/train/1013.xml  \n","  inflating: ./models/research/object_detection/images/train/2048.jpg  \n","  inflating: ./models/research/object_detection/images/train/1734.jpg  \n","  inflating: ./models/research/object_detection/images/train/1287.jpg  \n","  inflating: ./models/research/object_detection/images/train/1829.jpg  \n","  inflating: ./models/research/object_detection/images/train/1508.jpg  \n","  inflating: ./models/research/object_detection/images/train/1568.xml  \n","  inflating: ./models/research/object_detection/images/train/1504.jpg  \n","  inflating: ./models/research/object_detection/images/train/1696.jpg  \n","  inflating: ./models/research/object_detection/images/train/283.xml  \n","  inflating: ./models/research/object_detection/images/train/1258.jpg  \n","  inflating: ./models/research/object_detection/images/train/194.jpg  \n","  inflating: ./models/research/object_detection/images/train/2186.jpg  \n","  inflating: ./models/research/object_detection/images/train/2389.xml  \n","  inflating: ./models/research/object_detection/images/train/1392.jpg  \n","  inflating: ./models/research/object_detection/images/train/238.jpg  \n","  inflating: ./models/research/object_detection/images/train/1200.jpg  \n","  inflating: ./models/research/object_detection/images/train/1620.jpg  \n","  inflating: ./models/research/object_detection/images/train/2423.xml  \n","  inflating: ./models/research/object_detection/images/train/947.xml  \n","  inflating: ./models/research/object_detection/images/train/1399.xml  \n","  inflating: ./models/research/object_detection/images/train/1199.jpg  \n","  inflating: ./models/research/object_detection/images/train/1707.jpg  \n","  inflating: ./models/research/object_detection/images/train/419.xml  \n","  inflating: ./models/research/object_detection/images/train/884.xml  \n","  inflating: ./models/research/object_detection/images/train/2448.xml  \n","  inflating: ./models/research/object_detection/images/train/1184.xml  \n","  inflating: ./models/research/object_detection/images/train/37.jpg  \n","  inflating: ./models/research/object_detection/images/train/1699.jpg  \n","  inflating: ./models/research/object_detection/images/train/447.xml  \n","  inflating: ./models/research/object_detection/images/train/2105.xml  \n","  inflating: ./models/research/object_detection/images/train/458.jpg  \n","  inflating: ./models/research/object_detection/images/train/60.jpg  \n","  inflating: ./models/research/object_detection/images/train/1645.jpg  \n","  inflating: ./models/research/object_detection/images/train/2098.xml  \n","  inflating: ./models/research/object_detection/images/train/265.jpg  \n","  inflating: ./models/research/object_detection/images/train/432.xml  \n","  inflating: ./models/research/object_detection/images/train/848.jpg  \n","  inflating: ./models/research/object_detection/images/train/1404.xml  \n","  inflating: ./models/research/object_detection/images/train/1277.jpg  \n","  inflating: ./models/research/object_detection/images/train/1050.jpg  \n","  inflating: ./models/research/object_detection/images/train/1869.xml  \n","  inflating: ./models/research/object_detection/images/train/1632.jpg  \n","  inflating: ./models/research/object_detection/images/train/644.jpg  \n","  inflating: ./models/research/object_detection/images/train/897.xml  \n","  inflating: ./models/research/object_detection/images/train/629.jpg  \n","  inflating: ./models/research/object_detection/images/train/2153.xml  \n","  inflating: ./models/research/object_detection/images/train/946.jpg  \n","  inflating: ./models/research/object_detection/images/train/1078.xml  \n","  inflating: ./models/research/object_detection/images/train/2336.xml  \n","  inflating: ./models/research/object_detection/images/train/1047.xml  \n","  inflating: ./models/research/object_detection/images/train/2340.jpg  \n","  inflating: ./models/research/object_detection/images/train/283.jpg  \n","  inflating: ./models/research/object_detection/images/train/621.jpg  \n","  inflating: ./models/research/object_detection/images/train/2185.xml  \n","  inflating: ./models/research/object_detection/images/train/1154.xml  \n","  inflating: ./models/research/object_detection/images/train/1656.jpg  \n","  inflating: ./models/research/object_detection/images/train/1794.xml  \n","  inflating: ./models/research/object_detection/images/train/2425.jpg  \n","  inflating: ./models/research/object_detection/images/train/2499.xml  \n","  inflating: ./models/research/object_detection/images/train/694.xml  \n","  inflating: ./models/research/object_detection/images/train/78.jpg  \n","  inflating: ./models/research/object_detection/images/train/1797.xml  \n","  inflating: ./models/research/object_detection/images/train/329.xml  \n","  inflating: ./models/research/object_detection/images/train/94.xml  \n","  inflating: ./models/research/object_detection/images/train/1268.xml  \n","  inflating: ./models/research/object_detection/images/train/366.jpg  \n","  inflating: ./models/research/object_detection/images/train/1725.jpg  \n","  inflating: ./models/research/object_detection/images/train/2401.jpg  \n","  inflating: ./models/research/object_detection/images/train/190.xml  \n","  inflating: ./models/research/object_detection/images/train/1299.xml  \n","  inflating: ./models/research/object_detection/images/train/914.jpg  \n","  inflating: ./models/research/object_detection/images/train/1312.xml  \n","  inflating: ./models/research/object_detection/images/train/397.jpg  \n","  inflating: ./models/research/object_detection/images/train/1253.jpg  \n","  inflating: ./models/research/object_detection/images/train/1221.jpg  \n","  inflating: ./models/research/object_detection/images/train/94.jpg  \n","  inflating: ./models/research/object_detection/images/train/2441.xml  \n","  inflating: ./models/research/object_detection/images/train/2357.jpg  \n","  inflating: ./models/research/object_detection/images/train/2125.jpg  \n","  inflating: ./models/research/object_detection/images/train/1511.xml  \n","  inflating: ./models/research/object_detection/images/train/2482.xml  \n","  inflating: ./models/research/object_detection/images/train/1986.jpg  \n","  inflating: ./models/research/object_detection/images/train/1084.xml  \n","  inflating: ./models/research/object_detection/images/train/304.jpg  \n","  inflating: ./models/research/object_detection/images/train/925.xml  \n","  inflating: ./models/research/object_detection/images/train/1178.xml  \n","  inflating: ./models/research/object_detection/images/train/1997.jpg  \n","  inflating: ./models/research/object_detection/images/train/534.jpg  \n","  inflating: ./models/research/object_detection/images/train/2031.jpg  \n","  inflating: ./models/research/object_detection/images/train/1393.jpg  \n","  inflating: ./models/research/object_detection/images/train/225.jpg  \n","  inflating: ./models/research/object_detection/images/train/198.jpg  \n","  inflating: ./models/research/object_detection/images/train/1437.jpg  \n","  inflating: ./models/research/object_detection/images/train/836.xml  \n","  inflating: ./models/research/object_detection/images/train/92.xml  \n","  inflating: ./models/research/object_detection/images/train/1560.jpg  \n","  inflating: ./models/research/object_detection/images/train/2435.xml  \n","  inflating: ./models/research/object_detection/images/train/1161.xml  \n","  inflating: ./models/research/object_detection/images/train/300.xml  \n","  inflating: ./models/research/object_detection/images/train/1109.jpg  \n","  inflating: ./models/research/object_detection/images/train/2484.jpg  \n","  inflating: ./models/research/object_detection/images/train/846.jpg  \n","  inflating: ./models/research/object_detection/images/train/1684.xml  \n","  inflating: ./models/research/object_detection/images/train/2433.jpg  \n","  inflating: ./models/research/object_detection/images/train/2509.jpg  \n","  inflating: ./models/research/object_detection/images/train/1116.xml  \n","  inflating: ./models/research/object_detection/images/train/1668.jpg  \n","  inflating: ./models/research/object_detection/images/train/1979.jpg  \n","  inflating: ./models/research/object_detection/images/train/82.xml  \n","  inflating: ./models/research/object_detection/images/train/2057.xml  \n","  inflating: ./models/research/object_detection/images/train/899.jpg  \n","  inflating: ./models/research/object_detection/images/train/1867.xml  \n","  inflating: ./models/research/object_detection/images/train/888.jpg  \n","  inflating: ./models/research/object_detection/images/train/1972.jpg  \n","  inflating: ./models/research/object_detection/images/train/586.xml  \n","  inflating: ./models/research/object_detection/images/train/1030.xml  \n","  inflating: ./models/research/object_detection/images/train/2251.xml  \n","  inflating: ./models/research/object_detection/images/train/2200.jpg  \n","  inflating: ./models/research/object_detection/images/train/237.xml  \n","  inflating: ./models/research/object_detection/images/train/1557.jpg  \n","  inflating: ./models/research/object_detection/images/train/679.jpg  \n","  inflating: ./models/research/object_detection/images/train/1003.jpg  \n","  inflating: ./models/research/object_detection/images/train/234.jpg  \n","  inflating: ./models/research/object_detection/images/train/740.xml  \n","  inflating: ./models/research/object_detection/images/train/1417.xml  \n","  inflating: ./models/research/object_detection/images/train/645.jpg  \n","  inflating: ./models/research/object_detection/images/train/2142.xml  \n","  inflating: ./models/research/object_detection/images/train/835.xml  \n","  inflating: ./models/research/object_detection/images/train/302.jpg  \n","  inflating: ./models/research/object_detection/images/train/484.xml  \n","  inflating: ./models/research/object_detection/images/train/150.xml  \n","  inflating: ./models/research/object_detection/images/train/294.jpg  \n","  inflating: ./models/research/object_detection/images/train/1927.xml  \n","  inflating: ./models/research/object_detection/images/train/1174.jpg  \n","  inflating: ./models/research/object_detection/images/train/1226.xml  \n","  inflating: ./models/research/object_detection/images/train/2113.jpg  \n","  inflating: ./models/research/object_detection/images/train/2025.xml  \n","  inflating: ./models/research/object_detection/images/train/353.xml  \n","  inflating: ./models/research/object_detection/images/train/1517.jpg  \n","  inflating: ./models/research/object_detection/images/train/498.xml  \n","  inflating: ./models/research/object_detection/images/train/567.jpg  \n","  inflating: ./models/research/object_detection/images/train/76.xml  \n","  inflating: ./models/research/object_detection/images/train/1023.jpg  \n","  inflating: ./models/research/object_detection/images/train/718.jpg  \n","  inflating: ./models/research/object_detection/images/train/1019.jpg  \n","  inflating: ./models/research/object_detection/images/train/251.xml  \n","  inflating: ./models/research/object_detection/images/train/258.jpg  \n","  inflating: ./models/research/object_detection/images/train/1598.xml  \n","  inflating: ./models/research/object_detection/images/train/109.jpg  \n","  inflating: ./models/research/object_detection/images/train/1447.jpg  \n","  inflating: ./models/research/object_detection/images/train/816.xml  \n","  inflating: ./models/research/object_detection/images/train/1577.jpg  \n","  inflating: ./models/research/object_detection/images/train/1215.jpg  \n","  inflating: ./models/research/object_detection/images/train/1266.jpg  \n","  inflating: ./models/research/object_detection/images/train/1299.jpg  \n","  inflating: ./models/research/object_detection/images/train/1027.jpg  \n","  inflating: ./models/research/object_detection/images/train/284.jpg  \n","  inflating: ./models/research/object_detection/images/train/1125.xml  \n","  inflating: ./models/research/object_detection/images/train/219.xml  \n","  inflating: ./models/research/object_detection/images/train/2119.xml  \n","  inflating: ./models/research/object_detection/images/train/1588.jpg  \n","  inflating: ./models/research/object_detection/images/train/1376.jpg  \n","  inflating: ./models/research/object_detection/images/train/997.xml  \n","  inflating: ./models/research/object_detection/images/train/1941.jpg  \n","  inflating: ./models/research/object_detection/images/train/1241.xml  \n","  inflating: ./models/research/object_detection/images/train/1580.xml  \n","  inflating: ./models/research/object_detection/images/train/1713.xml  \n","  inflating: ./models/research/object_detection/images/train/261.jpg  \n","  inflating: ./models/research/object_detection/images/train/2254.xml  \n","  inflating: ./models/research/object_detection/images/train/282.jpg  \n","  inflating: ./models/research/object_detection/images/train/2194.jpg  \n","  inflating: ./models/research/object_detection/images/train/2141.jpg  \n","  inflating: ./models/research/object_detection/images/train/1255.xml  \n","  inflating: ./models/research/object_detection/images/train/1670.xml  \n","  inflating: ./models/research/object_detection/images/train/401.xml  \n","  inflating: ./models/research/object_detection/images/train/2089.jpg  \n","  inflating: ./models/research/object_detection/images/train/1913.xml  \n","  inflating: ./models/research/object_detection/images/train/1381.xml  \n","  inflating: ./models/research/object_detection/images/train/891.xml  \n","  inflating: ./models/research/object_detection/images/train/2396.jpg  \n","  inflating: ./models/research/object_detection/images/train/501.jpg  \n","  inflating: ./models/research/object_detection/images/train/1524.xml  \n","  inflating: ./models/research/object_detection/images/train/227.xml  \n","  inflating: ./models/research/object_detection/images/train/701.xml  \n","  inflating: ./models/research/object_detection/images/train/1634.xml  \n","  inflating: ./models/research/object_detection/images/train/1746.jpg  \n","  inflating: ./models/research/object_detection/images/train/1441.jpg  \n","  inflating: ./models/research/object_detection/images/train/1399.jpg  \n","  inflating: ./models/research/object_detection/images/train/1395.xml  \n","  inflating: ./models/research/object_detection/images/train/1285.xml  \n","  inflating: ./models/research/object_detection/images/train/2356.jpg  \n","  inflating: ./models/research/object_detection/images/train/266.xml  \n","  inflating: ./models/research/object_detection/images/train/2241.jpg  \n","  inflating: ./models/research/object_detection/images/train/91.xml  \n","  inflating: ./models/research/object_detection/images/train/1669.xml  \n","  inflating: ./models/research/object_detection/images/train/2426.jpg  \n","  inflating: ./models/research/object_detection/images/train/1351.jpg  \n","  inflating: ./models/research/object_detection/images/train/462.jpg  \n","  inflating: ./models/research/object_detection/images/train/1393.xml  \n","  inflating: ./models/research/object_detection/images/train/1336.jpg  \n","  inflating: ./models/research/object_detection/images/train/1435.xml  \n","  inflating: ./models/research/object_detection/images/train/468.xml  \n","  inflating: ./models/research/object_detection/images/train/1094.jpg  \n","  inflating: ./models/research/object_detection/images/train/1984.xml  \n","  inflating: ./models/research/object_detection/images/train/2220.jpg  \n","  inflating: ./models/research/object_detection/images/train/2242.xml  \n","  inflating: ./models/research/object_detection/images/train/58.jpg  \n","  inflating: ./models/research/object_detection/images/train/2243.jpg  \n","  inflating: ./models/research/object_detection/images/train/155.xml  \n","  inflating: ./models/research/object_detection/images/train/1533.xml  \n","  inflating: ./models/research/object_detection/images/train/1248.xml  \n","  inflating: ./models/research/object_detection/images/train/2237.xml  \n","  inflating: ./models/research/object_detection/images/train/1303.xml  \n","  inflating: ./models/research/object_detection/images/train/73.xml  \n","  inflating: ./models/research/object_detection/images/train/1660.jpg  \n","  inflating: ./models/research/object_detection/images/train/2415.jpg  \n","  inflating: ./models/research/object_detection/images/train/1792.jpg  \n","  inflating: ./models/research/object_detection/images/train/1725.xml  \n","  inflating: ./models/research/object_detection/images/train/1237.jpg  \n","  inflating: ./models/research/object_detection/images/train/1901.xml  \n","  inflating: ./models/research/object_detection/images/train/405.jpg  \n","  inflating: ./models/research/object_detection/images/train/477.xml  \n","  inflating: ./models/research/object_detection/images/train/1823.jpg  \n","  inflating: ./models/research/object_detection/images/train/1601.jpg  \n","  inflating: ./models/research/object_detection/images/train/1213.jpg  \n","  inflating: ./models/research/object_detection/images/train/257.xml  \n","  inflating: ./models/research/object_detection/images/train/571.jpg  \n","  inflating: ./models/research/object_detection/images/train/1354.jpg  \n","  inflating: ./models/research/object_detection/images/train/1432.xml  \n","  inflating: ./models/research/object_detection/images/train/1289.jpg  \n","  inflating: ./models/research/object_detection/images/train/2402.jpg  \n","  inflating: ./models/research/object_detection/images/train/587.xml  \n","  inflating: ./models/research/object_detection/images/train/1846.jpg  \n","  inflating: ./models/research/object_detection/images/train/1906.xml  \n","  inflating: ./models/research/object_detection/images/train/464.jpg  \n","  inflating: ./models/research/object_detection/images/train/1097.xml  \n","  inflating: ./models/research/object_detection/images/train/214.xml  \n","  inflating: ./models/research/object_detection/images/train/15.xml  \n","  inflating: ./models/research/object_detection/images/train/1471.xml  \n","  inflating: ./models/research/object_detection/images/train/1240.xml  \n","  inflating: ./models/research/object_detection/images/train/1639.jpg  \n","  inflating: ./models/research/object_detection/images/train/1864.jpg  \n","  inflating: ./models/research/object_detection/images/train/314.jpg  \n","  inflating: ./models/research/object_detection/images/train/1486.xml  \n","  inflating: ./models/research/object_detection/images/train/626.jpg  \n","  inflating: ./models/research/object_detection/images/train/2414.jpg  \n","  inflating: ./models/research/object_detection/images/train/808.xml  \n","  inflating: ./models/research/object_detection/images/train/1816.jpg  \n","  inflating: ./models/research/object_detection/images/train/524.xml  \n","  inflating: ./models/research/object_detection/images/train/1109.xml  \n","  inflating: ./models/research/object_detection/images/train/634.xml  \n","  inflating: ./models/research/object_detection/images/train/1953.jpg  \n","  inflating: ./models/research/object_detection/images/train/1765.jpg  \n","  inflating: ./models/research/object_detection/images/train/1604.xml  \n","  inflating: ./models/research/object_detection/images/train/1276.jpg  \n","  inflating: ./models/research/object_detection/images/train/1729.xml  \n","  inflating: ./models/research/object_detection/images/train/1374.jpg  \n","  inflating: ./models/research/object_detection/images/train/538.jpg  \n","  inflating: ./models/research/object_detection/images/train/600.jpg  \n","  inflating: ./models/research/object_detection/images/train/1383.xml  \n","  inflating: ./models/research/object_detection/images/train/1948.xml  \n","  inflating: ./models/research/object_detection/images/train/1976.jpg  \n","  inflating: ./models/research/object_detection/images/train/1049.jpg  \n","  inflating: ./models/research/object_detection/images/train/741.jpg  \n","  inflating: ./models/research/object_detection/images/train/617.jpg  \n","  inflating: ./models/research/object_detection/images/train/2032.jpg  \n","  inflating: ./models/research/object_detection/images/train/557.xml  \n","  inflating: ./models/research/object_detection/images/train/430.jpg  \n","  inflating: ./models/research/object_detection/images/train/630.jpg  \n","  inflating: ./models/research/object_detection/images/train/575.xml  \n","  inflating: ./models/research/object_detection/images/train/2471.jpg  \n","  inflating: ./models/research/object_detection/images/train/269.xml  \n","  inflating: ./models/research/object_detection/images/train/1252.xml  \n","  inflating: ./models/research/object_detection/images/train/906.jpg  \n","  inflating: ./models/research/object_detection/images/train/2502.jpg  \n","  inflating: ./models/research/object_detection/images/train/1353.xml  \n","  inflating: ./models/research/object_detection/images/train/2421.jpg  \n","  inflating: ./models/research/object_detection/images/train/1069.jpg  \n","  inflating: ./models/research/object_detection/images/train/1433.jpg  \n","  inflating: ./models/research/object_detection/images/train/2375.xml  \n","  inflating: ./models/research/object_detection/images/train/66.jpg  \n","  inflating: ./models/research/object_detection/images/train/691.xml  \n","  inflating: ./models/research/object_detection/images/train/1403.xml  \n","  inflating: ./models/research/object_detection/images/train/1242.xml  \n","  inflating: ./models/research/object_detection/images/train/1626.xml  \n","  inflating: ./models/research/object_detection/images/train/31.jpg  \n","  inflating: ./models/research/object_detection/images/train/2357.xml  \n","  inflating: ./models/research/object_detection/images/train/1682.jpg  \n","  inflating: ./models/research/object_detection/images/train/1243.xml  \n","  inflating: ./models/research/object_detection/images/train/1023.xml  \n","  inflating: ./models/research/object_detection/images/train/740.jpg  \n","  inflating: ./models/research/object_detection/images/train/741.xml  \n","  inflating: ./models/research/object_detection/images/train/540.jpg  \n","  inflating: ./models/research/object_detection/images/train/679.xml  \n","  inflating: ./models/research/object_detection/images/train/1492.jpg  \n","  inflating: ./models/research/object_detection/images/train/938.xml  \n","  inflating: ./models/research/object_detection/images/train/2334.jpg  \n","  inflating: ./models/research/object_detection/images/train/1132.jpg  \n","  inflating: ./models/research/object_detection/images/train/41.xml  \n","  inflating: ./models/research/object_detection/images/train/810.xml  \n","  inflating: ./models/research/object_detection/images/train/2391.jpg  \n","  inflating: ./models/research/object_detection/images/train/684.jpg  \n","  inflating: ./models/research/object_detection/images/train/550.xml  \n","  inflating: ./models/research/object_detection/images/train/730.jpg  \n","  inflating: ./models/research/object_detection/images/train/2345.jpg  \n","  inflating: ./models/research/object_detection/images/train/57.xml  \n","  inflating: ./models/research/object_detection/images/train/617.xml  \n","  inflating: ./models/research/object_detection/images/train/1217.jpg  \n","  inflating: ./models/research/object_detection/images/train/2177.jpg  \n","  inflating: ./models/research/object_detection/images/train/1777.jpg  \n","  inflating: ./models/research/object_detection/images/train/1100.xml  \n","  inflating: ./models/research/object_detection/images/train/70.xml  \n","  inflating: ./models/research/object_detection/images/train/689.jpg  \n","  inflating: ./models/research/object_detection/images/train/1815.xml  \n","  inflating: ./models/research/object_detection/images/train/1097.jpg  \n","  inflating: ./models/research/object_detection/images/train/2208.jpg  \n","  inflating: ./models/research/object_detection/images/train/2422.jpg  \n","  inflating: ./models/research/object_detection/images/train/372.xml  \n","  inflating: ./models/research/object_detection/images/train/154.jpg  \n","  inflating: ./models/research/object_detection/images/train/1721.jpg  \n","  inflating: ./models/research/object_detection/images/train/788.jpg  \n","  inflating: ./models/research/object_detection/images/train/1065.jpg  \n","  inflating: ./models/research/object_detection/images/train/2381.jpg  \n","  inflating: ./models/research/object_detection/images/train/464.xml  \n","  inflating: ./models/research/object_detection/images/train/1783.xml  \n","  inflating: ./models/research/object_detection/images/train/722.xml  \n","  inflating: ./models/research/object_detection/images/train/274.jpg  \n","  inflating: ./models/research/object_detection/images/train/764.xml  \n","  inflating: ./models/research/object_detection/images/train/887.jpg  \n","  inflating: ./models/research/object_detection/images/train/1413.jpg  \n","  inflating: ./models/research/object_detection/images/train/1763.jpg  \n","  inflating: ./models/research/object_detection/images/train/197.xml  \n","  inflating: ./models/research/object_detection/images/train/1122.xml  \n","  inflating: ./models/research/object_detection/images/train/2044.xml  \n","  inflating: ./models/research/object_detection/images/train/2046.jpg  \n","  inflating: ./models/research/object_detection/images/train/1343.jpg  \n","  inflating: ./models/research/object_detection/images/train/1684.jpg  \n","  inflating: ./models/research/object_detection/images/train/2318.jpg  \n","  inflating: ./models/research/object_detection/images/train/252.jpg  \n","  inflating: ./models/research/object_detection/images/train/1714.xml  \n","  inflating: ./models/research/object_detection/images/train/837.jpg  \n","  inflating: ./models/research/object_detection/images/train/1391.jpg  \n","  inflating: ./models/research/object_detection/images/train/2313.xml  \n","  inflating: ./models/research/object_detection/images/train/129.jpg  \n","  inflating: ./models/research/object_detection/images/train/2492.xml  \n","  inflating: ./models/research/object_detection/images/train/2028.jpg  \n","  inflating: ./models/research/object_detection/images/train/149.jpg  \n","  inflating: ./models/research/object_detection/images/train/187.xml  \n","  inflating: ./models/research/object_detection/images/train/1212.jpg  \n","  inflating: ./models/research/object_detection/images/train/1475.jpg  \n","  inflating: ./models/research/object_detection/images/train/568.jpg  \n","  inflating: ./models/research/object_detection/images/train/1768.jpg  \n","  inflating: ./models/research/object_detection/images/train/2469.jpg  \n","  inflating: ./models/research/object_detection/images/train/933.jpg  \n","  inflating: ./models/research/object_detection/images/train/1884.jpg  \n","  inflating: ./models/research/object_detection/images/train/354.jpg  \n","  inflating: ./models/research/object_detection/images/train/1667.jpg  \n","  inflating: ./models/research/object_detection/images/train/2002.xml  \n","  inflating: ./models/research/object_detection/images/train/544.xml  \n","  inflating: ./models/research/object_detection/images/train/10.jpg  \n","  inflating: ./models/research/object_detection/images/train/552.jpg  \n","  inflating: ./models/research/object_detection/images/train/883.xml  \n","  inflating: ./models/research/object_detection/images/train/1531.xml  \n","  inflating: ./models/research/object_detection/images/train/217.xml  \n","  inflating: ./models/research/object_detection/images/train/1233.jpg  \n","  inflating: ./models/research/object_detection/images/train/293.jpg  \n","  inflating: ./models/research/object_detection/images/train/2224.jpg  \n","  inflating: ./models/research/object_detection/images/train/108.xml  \n","  inflating: ./models/research/object_detection/images/train/480.xml  \n","  inflating: ./models/research/object_detection/images/train/442.xml  \n","  inflating: ./models/research/object_detection/images/train/186.jpg  \n","  inflating: ./models/research/object_detection/images/train/698.jpg  \n","  inflating: ./models/research/object_detection/images/train/264.jpg  \n","  inflating: ./models/research/object_detection/images/train/307.xml  \n","  inflating: ./models/research/object_detection/images/train/158.jpg  \n","  inflating: ./models/research/object_detection/images/train/750.jpg  \n","  inflating: ./models/research/object_detection/images/train/2408.jpg  \n","  inflating: ./models/research/object_detection/images/train/845.jpg  \n","  inflating: ./models/research/object_detection/images/train/1820.xml  \n","  inflating: ./models/research/object_detection/images/train/1223.jpg  \n","  inflating: ./models/research/object_detection/images/train/500.xml  \n","  inflating: ./models/research/object_detection/images/train/2488.xml  \n","  inflating: ./models/research/object_detection/images/train/2352.jpg  \n","  inflating: ./models/research/object_detection/images/train/1552.xml  \n","  inflating: ./models/research/object_detection/images/train/1476.jpg  \n","  inflating: ./models/research/object_detection/images/train/23.xml  \n","  inflating: ./models/research/object_detection/images/train/45.jpg  \n","  inflating: ./models/research/object_detection/images/train/2127.xml  \n","  inflating: ./models/research/object_detection/images/train/1308.jpg  \n","  inflating: ./models/research/object_detection/images/train/1546.jpg  \n","  inflating: ./models/research/object_detection/images/train/81.xml  \n","  inflating: ./models/research/object_detection/images/train/1033.jpg  \n","  inflating: ./models/research/object_detection/images/train/1654.xml  \n","  inflating: ./models/research/object_detection/images/train/1358.xml  \n","  inflating: ./models/research/object_detection/images/train/1234.jpg  \n","  inflating: ./models/research/object_detection/images/train/395.jpg  \n","  inflating: ./models/research/object_detection/images/train/977.xml  \n","  inflating: ./models/research/object_detection/images/train/184.xml  \n","  inflating: ./models/research/object_detection/images/train/1042.xml  \n","  inflating: ./models/research/object_detection/images/train/2354.xml  \n","  inflating: ./models/research/object_detection/images/train/2020.jpg  \n","  inflating: ./models/research/object_detection/images/train/2232.xml  \n","  inflating: ./models/research/object_detection/images/train/86.xml  \n","  inflating: ./models/research/object_detection/images/train/1195.jpg  \n","  inflating: ./models/research/object_detection/images/train/2382.jpg  \n","  inflating: ./models/research/object_detection/images/train/185.jpg  \n","  inflating: ./models/research/object_detection/images/train/1506.xml  \n","  inflating: ./models/research/object_detection/images/train/1781.jpg  \n","  inflating: ./models/research/object_detection/images/train/2262.jpg  \n","  inflating: ./models/research/object_detection/images/train/315.xml  \n","  inflating: ./models/research/object_detection/images/train/363.jpg  \n","  inflating: ./models/research/object_detection/images/train/1563.jpg  \n","  inflating: ./models/research/object_detection/images/train/1379.jpg  \n","  inflating: ./models/research/object_detection/images/train/2395.jpg  \n","  inflating: ./models/research/object_detection/images/train/49.jpg  \n","  inflating: ./models/research/object_detection/images/train/2171.jpg  \n","  inflating: ./models/research/object_detection/images/train/1835.jpg  \n","  inflating: ./models/research/object_detection/images/train/1098.jpg  \n","  inflating: ./models/research/object_detection/images/train/1708.xml  \n","  inflating: ./models/research/object_detection/images/train/1338.xml  \n","  inflating: ./models/research/object_detection/images/train/206.xml  \n","  inflating: ./models/research/object_detection/images/train/2306.jpg  \n","  inflating: ./models/research/object_detection/images/train/969.xml  \n","  inflating: ./models/research/object_detection/images/train/301.xml  \n","  inflating: ./models/research/object_detection/images/train/746.xml  \n","  inflating: ./models/research/object_detection/images/train/270.jpg  \n","  inflating: ./models/research/object_detection/images/train/1163.xml  \n","  inflating: ./models/research/object_detection/images/train/2079.xml  \n","  inflating: ./models/research/object_detection/images/train/2327.jpg  \n","  inflating: ./models/research/object_detection/images/train/2506.xml  \n","  inflating: ./models/research/object_detection/images/train/449.jpg  \n","  inflating: ./models/research/object_detection/images/train/82.jpg  \n","  inflating: ./models/research/object_detection/images/train/653.xml  \n","  inflating: ./models/research/object_detection/images/train/370.jpg  \n","  inflating: ./models/research/object_detection/images/train/2233.xml  \n","  inflating: ./models/research/object_detection/images/train/2055.xml  \n","  inflating: ./models/research/object_detection/images/train/2342.xml  \n","  inflating: ./models/research/object_detection/images/train/648.xml  \n","  inflating: ./models/research/object_detection/images/train/443.jpg  \n","  inflating: ./models/research/object_detection/images/train/2119.jpg  \n","  inflating: ./models/research/object_detection/images/train/2370.jpg  \n","  inflating: ./models/research/object_detection/images/train/1865.jpg  \n","  inflating: ./models/research/object_detection/images/train/72.jpg  \n","  inflating: ./models/research/object_detection/images/train/2451.jpg  \n","  inflating: ./models/research/object_detection/images/train/2016.jpg  \n","  inflating: ./models/research/object_detection/images/train/149.xml  \n","  inflating: ./models/research/object_detection/images/train/1608.jpg  \n","  inflating: ./models/research/object_detection/images/train/2196.xml  \n","  inflating: ./models/research/object_detection/images/train/677.xml  \n","  inflating: ./models/research/object_detection/images/train/1077.xml  \n","  inflating: ./models/research/object_detection/images/train/2418.xml  \n","  inflating: ./models/research/object_detection/images/train/427.jpg  \n","  inflating: ./models/research/object_detection/images/train/883.jpg  \n","  inflating: ./models/research/object_detection/images/train/1552.jpg  \n","  inflating: ./models/research/object_detection/images/train/904.xml  \n","  inflating: ./models/research/object_detection/images/train/676.xml  \n","  inflating: ./models/research/object_detection/images/train/2202.jpg  \n","  inflating: ./models/research/object_detection/images/train/2508.jpg  \n","  inflating: ./models/research/object_detection/images/train/1994.xml  \n","  inflating: ./models/research/object_detection/images/train/439.xml  \n","  inflating: ./models/research/object_detection/images/train/202.jpg  \n","  inflating: ./models/research/object_detection/images/train/921.jpg  \n","  inflating: ./models/research/object_detection/images/train/2221.jpg  \n","  inflating: ./models/research/object_detection/images/train/1469.xml  \n","  inflating: ./models/research/object_detection/images/train/1630.jpg  \n","  inflating: ./models/research/object_detection/images/train/533.xml  \n","  inflating: ./models/research/object_detection/images/train/830.xml  \n","  inflating: ./models/research/object_detection/images/train/441.xml  \n","  inflating: ./models/research/object_detection/images/train/155.jpg  \n","  inflating: ./models/research/object_detection/images/train/2004.jpg  \n","  inflating: ./models/research/object_detection/images/train/2190.jpg  \n","  inflating: ./models/research/object_detection/images/train/1078.jpg  \n","  inflating: ./models/research/object_detection/images/train/2195.jpg  \n","  inflating: ./models/research/object_detection/images/train/930.xml  \n","  inflating: ./models/research/object_detection/images/train/2096.jpg  \n","  inflating: ./models/research/object_detection/images/train/296.xml  \n","  inflating: ./models/research/object_detection/images/train/2111.xml  \n","  inflating: ./models/research/object_detection/images/train/305.jpg  \n","  inflating: ./models/research/object_detection/images/train/2070.xml  \n","  inflating: ./models/research/object_detection/images/train/229.xml  \n","  inflating: ./models/research/object_detection/images/train/246.jpg  \n","  inflating: ./models/research/object_detection/images/train/1412.xml  \n","  inflating: ./models/research/object_detection/images/train/1980.jpg  \n","  inflating: ./models/research/object_detection/images/train/909.xml  \n","  inflating: ./models/research/object_detection/images/train/1579.xml  \n","  inflating: ./models/research/object_detection/images/train/2339.xml  \n","  inflating: ./models/research/object_detection/images/train/2114.xml  \n","  inflating: ./models/research/object_detection/images/train/343.jpg  \n","  inflating: ./models/research/object_detection/images/train/1727.xml  \n","  inflating: ./models/research/object_detection/images/train/957.jpg  \n","  inflating: ./models/research/object_detection/images/train/1790.jpg  \n","  inflating: ./models/research/object_detection/images/train/606.xml  \n","  inflating: ./models/research/object_detection/images/train/1949.xml  \n","  inflating: ./models/research/object_detection/images/train/1646.jpg  \n","  inflating: ./models/research/object_detection/images/train/643.xml  \n","  inflating: ./models/research/object_detection/images/train/2102.jpg  \n","  inflating: ./models/research/object_detection/images/train/1061.jpg  \n","  inflating: ./models/research/object_detection/images/train/400.jpg  \n","  inflating: ./models/research/object_detection/images/train/1643.jpg  \n","  inflating: ./models/research/object_detection/images/train/489.xml  \n","  inflating: ./models/research/object_detection/images/train/2168.xml  \n","  inflating: ./models/research/object_detection/images/train/1537.xml  \n","  inflating: ./models/research/object_detection/images/train/357.jpg  \n","  inflating: ./models/research/object_detection/images/train/2358.jpg  \n","  inflating: ./models/research/object_detection/images/train/1859.jpg  \n","  inflating: ./models/research/object_detection/images/train/1566.jpg  \n","  inflating: ./models/research/object_detection/images/train/2404.jpg  \n","  inflating: ./models/research/object_detection/images/train/1397.xml  \n","  inflating: ./models/research/object_detection/images/train/1703.jpg  \n","  inflating: ./models/research/object_detection/images/train/495.xml  \n","  inflating: ./models/research/object_detection/images/train/2155.jpg  \n","  inflating: ./models/research/object_detection/images/train/1930.xml  \n","  inflating: ./models/research/object_detection/images/train/1766.xml  \n","  inflating: ./models/research/object_detection/images/train/1738.jpg  \n","  inflating: ./models/research/object_detection/images/train/1271.jpg  \n","  inflating: ./models/research/object_detection/images/train/14.xml  \n","  inflating: ./models/research/object_detection/images/train/1955.jpg  \n","  inflating: ./models/research/object_detection/images/train/2497.xml  \n","  inflating: ./models/research/object_detection/images/train/59.jpg  \n","  inflating: ./models/research/object_detection/images/train/2368.xml  \n","  inflating: ./models/research/object_detection/images/train/2135.xml  \n","  inflating: ./models/research/object_detection/images/train/639.jpg  \n","  inflating: ./models/research/object_detection/images/train/1722.xml  \n","  inflating: ./models/research/object_detection/images/train/1405.xml  \n","  inflating: ./models/research/object_detection/images/train/171.xml  \n","  inflating: ./models/research/object_detection/images/train/2459.jpg  \n","  inflating: ./models/research/object_detection/images/train/982.jpg  \n","  inflating: ./models/research/object_detection/images/train/595.xml  \n","  inflating: ./models/research/object_detection/images/train/738.xml  \n","  inflating: ./models/research/object_detection/images/train/1292.jpg  \n","  inflating: ./models/research/object_detection/images/train/581.jpg  \n","  inflating: ./models/research/object_detection/images/train/771.xml  \n","  inflating: ./models/research/object_detection/images/train/1605.jpg  \n","  inflating: ./models/research/object_detection/images/train/1340.jpg  \n","  inflating: ./models/research/object_detection/images/train/2473.jpg  \n","  inflating: ./models/research/object_detection/images/train/1138.xml  \n","  inflating: ./models/research/object_detection/images/train/2410.jpg  \n","  inflating: ./models/research/object_detection/images/train/1622.jpg  \n","  inflating: ./models/research/object_detection/images/train/1826.jpg  \n","  inflating: ./models/research/object_detection/images/train/2493.xml  \n","  inflating: ./models/research/object_detection/images/train/292.jpg  \n","  inflating: ./models/research/object_detection/images/train/2328.xml  \n","  inflating: ./models/research/object_detection/images/train/887.xml  \n","  inflating: ./models/research/object_detection/images/train/385.xml  \n","  inflating: ./models/research/object_detection/images/train/2204.xml  \n","  inflating: ./models/research/object_detection/images/train/428.jpg  \n","  inflating: ./models/research/object_detection/images/train/1024.xml  \n","  inflating: ./models/research/object_detection/images/train/1915.jpg  \n","  inflating: ./models/research/object_detection/images/train/2026.jpg  \n","  inflating: ./models/research/object_detection/images/train/511.xml  \n","  inflating: ./models/research/object_detection/images/train/435.jpg  \n","  inflating: ./models/research/object_detection/images/train/34.xml  \n","  inflating: ./models/research/object_detection/images/train/2081.jpg  \n","  inflating: ./models/research/object_detection/images/train/767.xml  \n","  inflating: ./models/research/object_detection/images/train/902.jpg  \n","  inflating: ./models/research/object_detection/images/train/295.xml  \n","  inflating: ./models/research/object_detection/images/train/1052.xml  \n","  inflating: ./models/research/object_detection/images/train/287.jpg  \n","  inflating: ./models/research/object_detection/images/train/884.jpg  \n","  inflating: ./models/research/object_detection/images/train/1673.jpg  \n","  inflating: ./models/research/object_detection/images/train/128.xml  \n","  inflating: ./models/research/object_detection/images/train/2384.xml  \n","  inflating: ./models/research/object_detection/images/train/1458.xml  \n","  inflating: ./models/research/object_detection/images/train/117.jpg  \n","  inflating: ./models/research/object_detection/images/train/859.jpg  \n","  inflating: ./models/research/object_detection/images/train/387.jpg  \n","  inflating: ./models/research/object_detection/images/train/894.xml  \n","  inflating: ./models/research/object_detection/images/train/1573.xml  \n","  inflating: ./models/research/object_detection/images/train/1799.jpg  \n","  inflating: ./models/research/object_detection/images/train/1234.xml  \n","  inflating: ./models/research/object_detection/images/train/1889.xml  \n","  inflating: ./models/research/object_detection/images/train/141.xml  \n","  inflating: ./models/research/object_detection/images/train/1412.jpg  \n","  inflating: ./models/research/object_detection/images/train/2157.xml  \n","  inflating: ./models/research/object_detection/images/train/1325.jpg  \n","  inflating: ./models/research/object_detection/images/train/2223.xml  \n","  inflating: ./models/research/object_detection/images/train/238.xml  \n","  inflating: ./models/research/object_detection/images/train/1987.jpg  \n","  inflating: ./models/research/object_detection/images/train/421.xml  \n","  inflating: ./models/research/object_detection/images/train/1005.jpg  \n","  inflating: ./models/research/object_detection/images/train/192.jpg  \n","  inflating: ./models/research/object_detection/images/train/1323.xml  \n","  inflating: ./models/research/object_detection/images/train/1168.xml  \n","  inflating: ./models/research/object_detection/images/train/2079.jpg  \n","  inflating: ./models/research/object_detection/images/train/2187.xml  \n","  inflating: ./models/research/object_detection/images/train/341.xml  \n","  inflating: ./models/research/object_detection/images/train/1361.xml  \n","  inflating: ./models/research/object_detection/images/train/1885.xml  \n","  inflating: ./models/research/object_detection/images/train/2352.xml  \n","  inflating: ./models/research/object_detection/images/train/556.xml  \n","  inflating: ./models/research/object_detection/images/train/1633.xml  \n","  inflating: ./models/research/object_detection/images/train/1256.xml  \n","  inflating: ./models/research/object_detection/images/train/1778.xml  \n","  inflating: ./models/research/object_detection/images/train/2255.xml  \n","  inflating: ./models/research/object_detection/images/train/453.jpg  \n","  inflating: ./models/research/object_detection/images/train/230.xml  \n","  inflating: ./models/research/object_detection/images/train/1932.xml  \n","  inflating: ./models/research/object_detection/images/train/2133.xml  \n","  inflating: ./models/research/object_detection/images/train/1638.xml  \n","  inflating: ./models/research/object_detection/images/train/2487.jpg  \n","  inflating: ./models/research/object_detection/images/train/1763.xml  \n","  inflating: ./models/research/object_detection/images/train/2342.jpg  \n","  inflating: ./models/research/object_detection/images/train/936.xml  \n","  inflating: ./models/research/object_detection/images/train/2448.jpg  \n","  inflating: ./models/research/object_detection/images/train/154.xml  \n","  inflating: ./models/research/object_detection/images/train/1366.xml  \n","  inflating: ./models/research/object_detection/images/train/130.jpg  \n","  inflating: ./models/research/object_detection/images/train/707.jpg  \n","  inflating: ./models/research/object_detection/images/train/137.xml  \n","  inflating: ./models/research/object_detection/images/train/1618.xml  \n","  inflating: ./models/research/object_detection/images/train/1010.jpg  \n","  inflating: ./models/research/object_detection/images/train/2443.xml  \n","  inflating: ./models/research/object_detection/images/train/199.jpg  \n","  inflating: ./models/research/object_detection/images/train/249.jpg  \n","  inflating: ./models/research/object_detection/images/train/255.jpg  \n","  inflating: ./models/research/object_detection/images/train/461.jpg  \n","  inflating: ./models/research/object_detection/images/train/2188.jpg  \n","  inflating: ./models/research/object_detection/images/train/2326.xml  \n","  inflating: ./models/research/object_detection/images/train/239.xml  \n","  inflating: ./models/research/object_detection/images/train/963.jpg  \n","  inflating: ./models/research/object_detection/images/train/843.jpg  \n","  inflating: ./models/research/object_detection/images/train/1456.jpg  \n","  inflating: ./models/research/object_detection/images/train/135.xml  \n","  inflating: ./models/research/object_detection/images/train/26.xml  \n","  inflating: ./models/research/object_detection/images/train/1040.jpg  \n","  inflating: ./models/research/object_detection/images/train/1015.xml  \n","  inflating: ./models/research/object_detection/images/train/332.xml  \n","  inflating: ./models/research/object_detection/images/train/1320.jpg  \n","  inflating: ./models/research/object_detection/images/train/360.xml  \n","  inflating: ./models/research/object_detection/images/train/335.jpg  \n","  inflating: ./models/research/object_detection/images/train/1740.xml  \n","  inflating: ./models/research/object_detection/images/train/4.xml  \n","  inflating: ./models/research/object_detection/images/train/1615.xml  \n","  inflating: ./models/research/object_detection/images/train/50.jpg  \n","  inflating: ./models/research/object_detection/images/train/1796.jpg  \n","  inflating: ./models/research/object_detection/images/train/1523.jpg  \n","  inflating: ./models/research/object_detection/images/train/995.jpg  \n","  inflating: ./models/research/object_detection/images/train/1830.jpg  \n","  inflating: ./models/research/object_detection/images/train/2253.jpg  \n","  inflating: ./models/research/object_detection/images/train/1926.xml  \n","  inflating: ./models/research/object_detection/images/train/2333.xml  \n","  inflating: ./models/research/object_detection/images/train/1228.xml  \n","  inflating: ./models/research/object_detection/images/train/1661.jpg  \n","  inflating: ./models/research/object_detection/images/train/1868.jpg  \n","  inflating: ./models/research/object_detection/images/train/826.xml  \n","  inflating: ./models/research/object_detection/images/train/2090.jpg  \n","  inflating: ./models/research/object_detection/images/train/668.xml  \n","  inflating: ./models/research/object_detection/images/train/475.xml  \n","  inflating: ./models/research/object_detection/images/train/2083.xml  \n","  inflating: ./models/research/object_detection/images/train/692.jpg  \n","  inflating: ./models/research/object_detection/images/train/1067.xml  \n","  inflating: ./models/research/object_detection/images/train/284.xml  \n","  inflating: ./models/research/object_detection/images/train/2275.xml  \n","  inflating: ./models/research/object_detection/images/train/1346.jpg  \n","  inflating: ./models/research/object_detection/images/train/880.xml  \n","  inflating: ./models/research/object_detection/images/train/1853.jpg  \n","  inflating: ./models/research/object_detection/images/train/105.jpg  \n","  inflating: ./models/research/object_detection/images/train/2263.jpg  \n","  inflating: ./models/research/object_detection/images/train/392.jpg  \n","  inflating: ./models/research/object_detection/images/train/1414.xml  \n","  inflating: ./models/research/object_detection/images/train/1101.xml  \n","  inflating: ./models/research/object_detection/images/train/1712.xml  \n","  inflating: ./models/research/object_detection/images/train/1509.jpg  \n","  inflating: ./models/research/object_detection/images/train/819.jpg  \n","  inflating: ./models/research/object_detection/images/train/665.jpg  \n","  inflating: ./models/research/object_detection/images/train/1184.jpg  \n","  inflating: ./models/research/object_detection/images/train/1625.xml  \n","  inflating: ./models/research/object_detection/images/train/1739.xml  \n","  inflating: ./models/research/object_detection/images/train/1422.xml  \n","  inflating: ./models/research/object_detection/images/train/2403.jpg  \n","  inflating: ./models/research/object_detection/images/train/841.jpg  \n","  inflating: ./models/research/object_detection/images/train/1789.jpg  \n","  inflating: ./models/research/object_detection/images/train/2060.jpg  \n","  inflating: ./models/research/object_detection/images/train/321.jpg  \n","  inflating: ./models/research/object_detection/images/train/1495.xml  \n","  inflating: ./models/research/object_detection/images/train/2240.jpg  \n","  inflating: ./models/research/object_detection/images/train/1883.xml  \n","  inflating: ./models/research/object_detection/images/train/210.jpg  \n","  inflating: ./models/research/object_detection/images/train/1009.xml  \n","  inflating: ./models/research/object_detection/images/train/1990.jpg  \n","  inflating: ./models/research/object_detection/images/train/1059.xml  \n","  inflating: ./models/research/object_detection/images/train/2282.jpg  \n","  inflating: ./models/research/object_detection/images/train/2457.xml  \n","  inflating: ./models/research/object_detection/images/train/882.xml  \n","  inflating: ./models/research/object_detection/images/train/1934.jpg  \n","  inflating: ./models/research/object_detection/images/train/2438.jpg  \n","  inflating: ./models/research/object_detection/images/train/2443.jpg  \n","  inflating: ./models/research/object_detection/images/train/2281.jpg  \n","  inflating: ./models/research/object_detection/images/train/1731.xml  \n","  inflating: ./models/research/object_detection/images/train/1923.xml  \n","  inflating: ./models/research/object_detection/images/train/809.xml  \n","  inflating: ./models/research/object_detection/images/train/1197.xml  \n","  inflating: ./models/research/object_detection/images/train/1105.jpg  \n","  inflating: ./models/research/object_detection/images/train/1383.jpg  \n","  inflating: ./models/research/object_detection/images/train/1000.xml  \n","  inflating: ./models/research/object_detection/images/train/2213.xml  \n","  inflating: ./models/research/object_detection/images/train/286.jpg  \n","  inflating: ./models/research/object_detection/images/train/2462.xml  \n","  inflating: ./models/research/object_detection/images/train/673.xml  \n","  inflating: ./models/research/object_detection/images/train/1609.jpg  \n","  inflating: ./models/research/object_detection/images/train/2314.xml  \n","  inflating: ./models/research/object_detection/images/train/926.jpg  \n","  inflating: ./models/research/object_detection/images/train/624.xml  \n","  inflating: ./models/research/object_detection/images/train/140.jpg  \n","  inflating: ./models/research/object_detection/images/train/2297.jpg  \n","  inflating: ./models/research/object_detection/images/train/1711.jpg  \n","  inflating: ./models/research/object_detection/images/train/2386.xml  \n","  inflating: ./models/research/object_detection/images/train/2142.jpg  \n","  inflating: ./models/research/object_detection/images/train/778.xml  \n","  inflating: ./models/research/object_detection/images/train/1757.xml  \n","  inflating: ./models/research/object_detection/images/train/1047.jpg  \n","  inflating: ./models/research/object_detection/images/train/373.jpg  \n","  inflating: ./models/research/object_detection/images/train/1120.jpg  \n","  inflating: ./models/research/object_detection/images/train/536.jpg  \n","  inflating: ./models/research/object_detection/images/train/1625.jpg  \n","  inflating: ./models/research/object_detection/images/train/1451.jpg  \n","  inflating: ./models/research/object_detection/images/train/1226.jpg  \n","  inflating: ./models/research/object_detection/images/train/431.xml  \n","  inflating: ./models/research/object_detection/images/train/2219.xml  \n","  inflating: ./models/research/object_detection/images/train/624.jpg  \n","  inflating: ./models/research/object_detection/images/train/2374.jpg  \n","  inflating: ./models/research/object_detection/images/train/612.xml  \n","  inflating: ./models/research/object_detection/images/train/879.xml  \n","  inflating: ./models/research/object_detection/images/train/1469.jpg  \n","  inflating: ./models/research/object_detection/images/train/1095.jpg  \n","  inflating: ./models/research/object_detection/images/train/1993.jpg  \n","  inflating: ./models/research/object_detection/images/train/264.xml  \n","  inflating: ./models/research/object_detection/images/train/473.jpg  \n","  inflating: ./models/research/object_detection/images/train/1535.xml  \n","  inflating: ./models/research/object_detection/images/train/1555.jpg  \n","  inflating: ./models/research/object_detection/images/train/2103.xml  \n","  inflating: ./models/research/object_detection/images/train/43.xml  \n","  inflating: ./models/research/object_detection/images/train/984.xml  \n","  inflating: ./models/research/object_detection/images/train/1770.jpg  \n","  inflating: ./models/research/object_detection/images/train/1491.xml  \n","  inflating: ./models/research/object_detection/images/train/847.jpg  \n","  inflating: ./models/research/object_detection/images/train/2285.jpg  \n","  inflating: ./models/research/object_detection/images/train/1090.jpg  \n","  inflating: ./models/research/object_detection/images/train/1257.jpg  \n","  inflating: ./models/research/object_detection/images/train/1091.jpg  \n","  inflating: ./models/research/object_detection/images/train/993.jpg  \n","  inflating: ./models/research/object_detection/images/train/924.jpg  \n","  inflating: ./models/research/object_detection/images/train/2175.jpg  \n","  inflating: ./models/research/object_detection/images/train/455.jpg  \n","  inflating: ./models/research/object_detection/images/train/1582.jpg  \n","  inflating: ./models/research/object_detection/images/train/384.jpg  \n","  inflating: ./models/research/object_detection/images/train/402.jpg  \n","  inflating: ./models/research/object_detection/images/train/1446.xml  \n","  inflating: ./models/research/object_detection/images/train/450.xml  \n","  inflating: ./models/research/object_detection/images/train/268.jpg  \n","  inflating: ./models/research/object_detection/images/train/2450.jpg  \n","  inflating: ./models/research/object_detection/images/train/2001.jpg  \n","  inflating: ./models/research/object_detection/images/train/2050.jpg  \n","  inflating: ./models/research/object_detection/images/train/1263.jpg  \n","  inflating: ./models/research/object_detection/images/train/1124.jpg  \n","  inflating: ./models/research/object_detection/images/train/1742.jpg  \n","  inflating: ./models/research/object_detection/images/train/927.jpg  \n","  inflating: ./models/research/object_detection/images/train/1206.xml  \n","  inflating: ./models/research/object_detection/images/train/706.xml  \n","  inflating: ./models/research/object_detection/images/train/1365.xml  \n","  inflating: ./models/research/object_detection/images/train/1243.jpg  \n","  inflating: ./models/research/object_detection/images/train/572.xml  \n","  inflating: ./models/research/object_detection/images/train/30.jpg  \n","  inflating: ./models/research/object_detection/images/train/1037.jpg  \n","  inflating: ./models/research/object_detection/images/train/2300.jpg  \n","  inflating: ./models/research/object_detection/images/train/2030.xml  \n","  inflating: ./models/research/object_detection/images/train/289.jpg  \n","  inflating: ./models/research/object_detection/images/train/2269.xml  \n","  inflating: ./models/research/object_detection/images/train/79.jpg  \n","  inflating: ./models/research/object_detection/images/train/1107.jpg  \n","  inflating: ./models/research/object_detection/images/train/2371.xml  \n","  inflating: ./models/research/object_detection/images/train/2090.xml  \n","  inflating: ./models/research/object_detection/images/train/1496.xml  \n","  inflating: ./models/research/object_detection/images/train/705.jpg  \n","  inflating: ./models/research/object_detection/images/train/1581.xml  \n","  inflating: ./models/research/object_detection/images/train/1165.xml  \n","  inflating: ./models/research/object_detection/images/train/1890.xml  \n","  inflating: ./models/research/object_detection/images/train/496.xml  \n","  inflating: ./models/research/object_detection/images/train/1693.jpg  \n","  inflating: ./models/research/object_detection/images/train/603.xml  \n","  inflating: ./models/research/object_detection/images/train/474.xml  \n","  inflating: ./models/research/object_detection/images/train/1342.xml  \n","  inflating: ./models/research/object_detection/images/train/2149.jpg  \n","  inflating: ./models/research/object_detection/images/train/236.jpg  \n","  inflating: ./models/research/object_detection/images/train/2012.xml  \n","  inflating: ./models/research/object_detection/images/train/1875.xml  \n","  inflating: ./models/research/object_detection/images/train/73.jpg  \n","  inflating: ./models/research/object_detection/images/train/1785.xml  \n","  inflating: ./models/research/object_detection/images/train/2122.jpg  \n","  inflating: ./models/research/object_detection/images/train/890.jpg  \n","  inflating: ./models/research/object_detection/images/train/888.xml  \n","  inflating: ./models/research/object_detection/images/train/2371.jpg  \n","  inflating: ./models/research/object_detection/images/train/2074.jpg  \n","  inflating: ./models/research/object_detection/images/train/2349.xml  \n","  inflating: ./models/research/object_detection/images/train/1518.jpg  \n","  inflating: ./models/research/object_detection/images/train/2228.xml  \n","  inflating: ./models/research/object_detection/images/train/1166.xml  \n","  inflating: ./models/research/object_detection/images/train/179.jpg  \n","  inflating: ./models/research/object_detection/images/train/252.xml  \n","  inflating: ./models/research/object_detection/images/train/2311.xml  \n","  inflating: ./models/research/object_detection/images/train/2125.xml  \n","  inflating: ./models/research/object_detection/images/train/1382.jpg  \n","  inflating: ./models/research/object_detection/images/train/722.jpg  \n","  inflating: ./models/research/object_detection/images/train/1042.jpg  \n","  inflating: ./models/research/object_detection/images/train/1117.jpg  \n","  inflating: ./models/research/object_detection/images/train/1594.xml  \n","  inflating: ./models/research/object_detection/images/train/1095.xml  \n","  inflating: ./models/research/object_detection/images/train/2117.jpg  \n","  inflating: ./models/research/object_detection/images/train/1914.jpg  \n","  inflating: ./models/research/object_detection/images/train/696.xml  \n","  inflating: ./models/research/object_detection/images/train/950.jpg  \n","  inflating: ./models/research/object_detection/images/train/609.jpg  \n","  inflating: ./models/research/object_detection/images/train/1255.jpg  \n","  inflating: ./models/research/object_detection/images/train/2472.xml  \n","  inflating: ./models/research/object_detection/images/train/1177.jpg  \n","  inflating: ./models/research/object_detection/images/train/342.jpg  \n","  inflating: ./models/research/object_detection/images/train/635.xml  \n","  inflating: ./models/research/object_detection/images/train/492.xml  \n","  inflating: ./models/research/object_detection/images/train/1893.jpg  \n","  inflating: ./models/research/object_detection/images/train/619.jpg  \n","  inflating: ./models/research/object_detection/images/train/2402.xml  \n","  inflating: ./models/research/object_detection/images/train/1896.xml  \n","  inflating: ./models/research/object_detection/images/train/130.xml  \n","  inflating: ./models/research/object_detection/images/train/2478.xml  \n","  inflating: ./models/research/object_detection/images/train/2228.jpg  \n","  inflating: ./models/research/object_detection/images/train/468.jpg  \n","  inflating: ./models/research/object_detection/images/train/2474.xml  \n","  inflating: ./models/research/object_detection/images/train/242.xml  \n","  inflating: ./models/research/object_detection/images/train/1180.jpg  \n","  inflating: ./models/research/object_detection/images/train/150.jpg  \n","  inflating: ./models/research/object_detection/images/train/1767.xml  \n","  inflating: ./models/research/object_detection/images/train/723.jpg  \n","  inflating: ./models/research/object_detection/images/train/118.jpg  \n","  inflating: ./models/research/object_detection/images/train/2368.jpg  \n","  inflating: ./models/research/object_detection/images/train/2453.xml  \n","  inflating: ./models/research/object_detection/images/train/733.xml  \n","  inflating: ./models/research/object_detection/images/train/2215.xml  \n","  inflating: ./models/research/object_detection/images/train/642.xml  \n","  inflating: ./models/research/object_detection/images/train/708.jpg  \n","  inflating: ./models/research/object_detection/images/train/212.xml  \n","  inflating: ./models/research/object_detection/images/train/1849.jpg  \n","  inflating: ./models/research/object_detection/images/train/2229.jpg  \n","  inflating: ./models/research/object_detection/images/train/2330.jpg  \n","  inflating: ./models/research/object_detection/images/train/2091.xml  \n","  inflating: ./models/research/object_detection/images/train/1916.xml  \n","  inflating: ./models/research/object_detection/images/train/1127.xml  \n","  inflating: ./models/research/object_detection/images/train/2385.xml  \n","  inflating: ./models/research/object_detection/images/train/2479.xml  \n","  inflating: ./models/research/object_detection/images/train/2497.jpg  \n","  inflating: ./models/research/object_detection/images/train/1118.xml  \n","  inflating: ./models/research/object_detection/images/train/3.xml  \n","  inflating: ./models/research/object_detection/images/train/1772.jpg  \n","  inflating: ./models/research/object_detection/images/train/1225.xml  \n","  inflating: ./models/research/object_detection/images/train/1700.jpg  \n","  inflating: ./models/research/object_detection/images/train/1357.jpg  \n","  inflating: ./models/research/object_detection/images/train/1999.jpg  \n","  inflating: ./models/research/object_detection/images/train/1590.xml  \n","  inflating: ./models/research/object_detection/images/train/1027.xml  \n","  inflating: ./models/research/object_detection/images/train/786.jpg  \n","   creating: ./models/research/object_detection/images/test/\n","  inflating: ./models/research/object_detection/images/test/3332.xml  \n","  inflating: ./models/research/object_detection/images/test/3301.xml  \n","  inflating: ./models/research/object_detection/images/test/3186.xml  \n","  inflating: ./models/research/object_detection/images/test/3016.jpg  \n","  inflating: ./models/research/object_detection/images/test/3154.jpg  \n","  inflating: ./models/research/object_detection/images/test/3020.jpg  \n","  inflating: ./models/research/object_detection/images/test/3200.xml  \n","  inflating: ./models/research/object_detection/images/test/3105.jpg  \n","  inflating: ./models/research/object_detection/images/test/3271.xml  \n","  inflating: ./models/research/object_detection/images/test/3088.xml  \n","  inflating: ./models/research/object_detection/images/test/3077.xml  \n","  inflating: ./models/research/object_detection/images/test/3161.xml  \n","  inflating: ./models/research/object_detection/images/test/3379.jpg  \n","  inflating: ./models/research/object_detection/images/test/3243.xml  \n","  inflating: ./models/research/object_detection/images/test/3393.xml  \n","  inflating: ./models/research/object_detection/images/test/3204.jpg  \n","  inflating: ./models/research/object_detection/images/test/3116.xml  \n","  inflating: ./models/research/object_detection/images/test/3360.jpg  \n","  inflating: ./models/research/object_detection/images/test/3140.jpg  \n","  inflating: ./models/research/object_detection/images/test/3386.xml  \n","  inflating: ./models/research/object_detection/images/test/3018.xml  \n","  inflating: ./models/research/object_detection/images/test/3239.jpg  \n","  inflating: ./models/research/object_detection/images/test/3246.jpg  \n","  inflating: ./models/research/object_detection/images/test/3305.jpg  \n","  inflating: ./models/research/object_detection/images/test/3127.xml  \n","  inflating: ./models/research/object_detection/images/test/3157.jpg  \n","  inflating: ./models/research/object_detection/images/test/3383.jpg  \n","  inflating: ./models/research/object_detection/images/test/3338.jpg  \n","  inflating: ./models/research/object_detection/images/test/3154.xml  \n","  inflating: ./models/research/object_detection/images/test/3249.jpg  \n","  inflating: ./models/research/object_detection/images/test/3165.jpg  \n","  inflating: ./models/research/object_detection/images/test/3103.xml  \n","  inflating: ./models/research/object_detection/images/test/3282.xml  \n","  inflating: ./models/research/object_detection/images/test/3037.xml  \n","  inflating: ./models/research/object_detection/images/test/3277.jpg  \n","  inflating: ./models/research/object_detection/images/test/3048.jpg  \n","  inflating: ./models/research/object_detection/images/test/3076.jpg  \n","  inflating: ./models/research/object_detection/images/test/3386.jpg  \n","  inflating: ./models/research/object_detection/images/test/3219.xml  \n","  inflating: ./models/research/object_detection/images/test/3077.jpg  \n","  inflating: ./models/research/object_detection/images/test/3209.jpg  \n","  inflating: ./models/research/object_detection/images/test/3142.jpg  \n","  inflating: ./models/research/object_detection/images/test/3048.xml  \n","  inflating: ./models/research/object_detection/images/test/3086.xml  \n","  inflating: ./models/research/object_detection/images/test/3385.jpg  \n","  inflating: ./models/research/object_detection/images/test/3222.jpg  \n","  inflating: ./models/research/object_detection/images/test/3355.jpg  \n","  inflating: ./models/research/object_detection/images/test/3056.xml  \n","  inflating: ./models/research/object_detection/images/test/3090.xml  \n","  inflating: ./models/research/object_detection/images/test/3078.jpg  \n","  inflating: ./models/research/object_detection/images/test/3230.xml  \n","  inflating: ./models/research/object_detection/images/test/3402.jpg  \n","  inflating: ./models/research/object_detection/images/test/3040.jpg  \n","  inflating: ./models/research/object_detection/images/test/3239.xml  \n","  inflating: ./models/research/object_detection/images/test/3390.xml  \n","  inflating: ./models/research/object_detection/images/test/3195.xml  \n","  inflating: ./models/research/object_detection/images/test/3064.jpg  \n","  inflating: ./models/research/object_detection/images/test/3379.xml  \n","  inflating: ./models/research/object_detection/images/test/3329.xml  \n","  inflating: ./models/research/object_detection/images/test/3102.xml  \n","  inflating: ./models/research/object_detection/images/test/3221.xml  \n","  inflating: ./models/research/object_detection/images/test/3189.xml  \n","  inflating: ./models/research/object_detection/images/test/3096.xml  \n","  inflating: ./models/research/object_detection/images/test/3198.xml  \n","  inflating: ./models/research/object_detection/images/test/3344.xml  \n","  inflating: ./models/research/object_detection/images/test/3061.jpg  \n","  inflating: ./models/research/object_detection/images/test/3026.jpg  \n","  inflating: ./models/research/object_detection/images/test/3334.xml  \n","  inflating: ./models/research/object_detection/images/test/3339.xml  \n","  inflating: ./models/research/object_detection/images/test/3108.xml  \n","  inflating: ./models/research/object_detection/images/test/3329.jpg  \n","  inflating: ./models/research/object_detection/images/test/3019.jpg  \n","  inflating: ./models/research/object_detection/images/test/3152.xml  \n","  inflating: ./models/research/object_detection/images/test/3385.xml  \n","  inflating: ./models/research/object_detection/images/test/3141.xml  \n","  inflating: ./models/research/object_detection/images/test/3234.jpg  \n","  inflating: ./models/research/object_detection/images/test/3101.jpg  \n","  inflating: ./models/research/object_detection/images/test/3081.jpg  \n","  inflating: ./models/research/object_detection/images/test/3406.jpg  \n","  inflating: ./models/research/object_detection/images/test/3336.jpg  \n","  inflating: ./models/research/object_detection/images/test/3072.jpg  \n","  inflating: ./models/research/object_detection/images/test/3085.jpg  \n","  inflating: ./models/research/object_detection/images/test/3318.xml  \n","  inflating: ./models/research/object_detection/images/test/3120.jpg  \n","  inflating: ./models/research/object_detection/images/test/3348.jpg  \n","  inflating: ./models/research/object_detection/images/test/3314.jpg  \n","  inflating: ./models/research/object_detection/images/test/3051.xml  \n","  inflating: ./models/research/object_detection/images/test/3341.jpg  \n","  inflating: ./models/research/object_detection/images/test/3395.jpg  \n","  inflating: ./models/research/object_detection/images/test/3358.xml  \n","  inflating: ./models/research/object_detection/images/test/3346.jpg  \n","  inflating: ./models/research/object_detection/images/test/3280.jpg  \n","  inflating: ./models/research/object_detection/images/test/3401.xml  \n","  inflating: ./models/research/object_detection/images/test/3324.xml  \n","  inflating: ./models/research/object_detection/images/test/3337.jpg  \n","  inflating: ./models/research/object_detection/images/test/3163.xml  \n","  inflating: ./models/research/object_detection/images/test/3178.jpg  \n","  inflating: ./models/research/object_detection/images/test/3186.jpg  \n","  inflating: ./models/research/object_detection/images/test/3373.xml  \n","  inflating: ./models/research/object_detection/images/test/3257.xml  \n","  inflating: ./models/research/object_detection/images/test/3109.jpg  \n","  inflating: ./models/research/object_detection/images/test/3082.jpg  \n","  inflating: ./models/research/object_detection/images/test/3035.xml  \n","  inflating: ./models/research/object_detection/images/test/3153.jpg  \n","  inflating: ./models/research/object_detection/images/test/3394.xml  \n","  inflating: ./models/research/object_detection/images/test/3050.jpg  \n","  inflating: ./models/research/object_detection/images/test/3129.xml  \n","  inflating: ./models/research/object_detection/images/test/3266.jpg  \n","  inflating: ./models/research/object_detection/images/test/3342.xml  \n","  inflating: ./models/research/object_detection/images/test/3029.xml  \n","  inflating: ./models/research/object_detection/images/test/3068.xml  \n","  inflating: ./models/research/object_detection/images/test/3017.jpg  \n","  inflating: ./models/research/object_detection/images/test/3210.xml  \n","  inflating: ./models/research/object_detection/images/test/3229.jpg  \n","  inflating: ./models/research/object_detection/images/test/3062.xml  \n","  inflating: ./models/research/object_detection/images/test/3343.xml  \n","  inflating: ./models/research/object_detection/images/test/3034.jpg  \n","  inflating: ./models/research/object_detection/images/test/3366.xml  \n","  inflating: ./models/research/object_detection/images/test/3371.jpg  \n","  inflating: ./models/research/object_detection/images/test/3201.jpg  \n","  inflating: ./models/research/object_detection/images/test/3173.xml  \n","  inflating: ./models/research/object_detection/images/test/3397.xml  \n","  inflating: ./models/research/object_detection/images/test/3085.xml  \n","  inflating: ./models/research/object_detection/images/test/3155.xml  \n","  inflating: ./models/research/object_detection/images/test/3167.xml  \n","  inflating: ./models/research/object_detection/images/test/3217.jpg  \n","  inflating: ./models/research/object_detection/images/test/3207.xml  \n","  inflating: ./models/research/object_detection/images/test/3094.jpg  \n","  inflating: ./models/research/object_detection/images/test/3403.xml  \n","  inflating: ./models/research/object_detection/images/test/3264.jpg  \n","  inflating: ./models/research/object_detection/images/test/3387.jpg  \n","  inflating: ./models/research/object_detection/images/test/3374.jpg  \n","  inflating: ./models/research/object_detection/images/test/3363.jpg  \n","  inflating: ./models/research/object_detection/images/test/3031.jpg  \n","  inflating: ./models/research/object_detection/images/test/3330.jpg  \n","  inflating: ./models/research/object_detection/images/test/3118.xml  \n","  inflating: ./models/research/object_detection/images/test/3199.xml  \n","  inflating: ./models/research/object_detection/images/test/3274.jpg  \n","  inflating: ./models/research/object_detection/images/test/3253.xml  \n","  inflating: ./models/research/object_detection/images/test/3220.jpg  \n","  inflating: ./models/research/object_detection/images/test/3378.jpg  \n","  inflating: ./models/research/object_detection/images/test/3140.xml  \n","  inflating: ./models/research/object_detection/images/test/3175.xml  \n","  inflating: ./models/research/object_detection/images/test/3208.jpg  \n","  inflating: ./models/research/object_detection/images/test/3252.xml  \n","  inflating: ./models/research/object_detection/images/test/3055.xml  \n","  inflating: ./models/research/object_detection/images/test/3234.xml  \n","  inflating: ./models/research/object_detection/images/test/3315.xml  \n","  inflating: ./models/research/object_detection/images/test/3112.jpg  \n","  inflating: ./models/research/object_detection/images/test/3307.jpg  \n","  inflating: ./models/research/object_detection/images/test/3168.jpg  \n","  inflating: ./models/research/object_detection/images/test/3111.jpg  \n","  inflating: ./models/research/object_detection/images/test/3252.jpg  \n","  inflating: ./models/research/object_detection/images/test/3161.jpg  \n","  inflating: ./models/research/object_detection/images/test/3231.xml  \n","  inflating: ./models/research/object_detection/images/test/3068.jpg  \n","  inflating: ./models/research/object_detection/images/test/3111.xml  \n","  inflating: ./models/research/object_detection/images/test/3309.xml  \n","  inflating: ./models/research/object_detection/images/test/3200.jpg  \n","  inflating: ./models/research/object_detection/images/test/3062.jpg  \n","  inflating: ./models/research/object_detection/images/test/3144.jpg  \n","  inflating: ./models/research/object_detection/images/test/3289.xml  \n","  inflating: ./models/research/object_detection/images/test/3206.xml  \n","  inflating: ./models/research/object_detection/images/test/3024.xml  \n","  inflating: ./models/research/object_detection/images/test/3410.xml  \n","  inflating: ./models/research/object_detection/images/test/3185.xml  \n","  inflating: ./models/research/object_detection/images/test/3053.xml  \n","  inflating: ./models/research/object_detection/images/test/3399.jpg  \n","  inflating: ./models/research/object_detection/images/test/3025.jpg  \n","  inflating: ./models/research/object_detection/images/test/3016.xml  \n","  inflating: ./models/research/object_detection/images/test/3042.jpg  \n","  inflating: ./models/research/object_detection/images/test/3244.jpg  \n","  inflating: ./models/research/object_detection/images/test/3272.jpg  \n","  inflating: ./models/research/object_detection/images/test/3312.jpg  \n","  inflating: ./models/research/object_detection/images/test/3409.xml  \n","  inflating: ./models/research/object_detection/images/test/3372.xml  \n","  inflating: ./models/research/object_detection/images/test/3327.jpg  \n","  inflating: ./models/research/object_detection/images/test/3018.jpg  \n","  inflating: ./models/research/object_detection/images/test/3396.xml  \n","  inflating: ./models/research/object_detection/images/test/3250.xml  \n","  inflating: ./models/research/object_detection/images/test/3316.jpg  \n","  inflating: ./models/research/object_detection/images/test/3185.jpg  \n","  inflating: ./models/research/object_detection/images/test/3150.jpg  \n","  inflating: ./models/research/object_detection/images/test/3155.jpg  \n","  inflating: ./models/research/object_detection/images/test/3391.jpg  \n","  inflating: ./models/research/object_detection/images/test/3109.xml  \n","  inflating: ./models/research/object_detection/images/test/3338.xml  \n","  inflating: ./models/research/object_detection/images/test/3084.jpg  \n","  inflating: ./models/research/object_detection/images/test/3303.jpg  \n","  inflating: ./models/research/object_detection/images/test/3123.xml  \n","  inflating: ./models/research/object_detection/images/test/3351.jpg  \n","  inflating: ./models/research/object_detection/images/test/3119.jpg  \n","  inflating: ./models/research/object_detection/images/test/3213.jpg  \n","  inflating: ./models/research/object_detection/images/test/3370.jpg  \n","  inflating: ./models/research/object_detection/images/test/3241.xml  \n","  inflating: ./models/research/object_detection/images/test/3017.xml  \n","  inflating: ./models/research/object_detection/images/test/3052.xml  \n","  inflating: ./models/research/object_detection/images/test/3293.xml  \n","  inflating: ./models/research/object_detection/images/test/3402.xml  \n","  inflating: ./models/research/object_detection/images/test/3120.xml  \n","  inflating: ./models/research/object_detection/images/test/3014.jpg  \n","  inflating: ./models/research/object_detection/images/test/3284.xml  \n","  inflating: ./models/research/object_detection/images/test/3191.xml  \n","  inflating: ./models/research/object_detection/images/test/3099.xml  \n","  inflating: ./models/research/object_detection/images/test/3046.jpg  \n","  inflating: ./models/research/object_detection/images/test/3242.xml  \n","  inflating: ./models/research/object_detection/images/test/3358.jpg  \n","  inflating: ./models/research/object_detection/images/test/3224.xml  \n","  inflating: ./models/research/object_detection/images/test/3043.jpg  \n","  inflating: ./models/research/object_detection/images/test/3212.xml  \n","  inflating: ./models/research/object_detection/images/test/3383.xml  \n","  inflating: ./models/research/object_detection/images/test/3201.xml  \n","  inflating: ./models/research/object_detection/images/test/3187.xml  \n","  inflating: ./models/research/object_detection/images/test/3389.jpg  \n","  inflating: ./models/research/object_detection/images/test/3104.jpg  \n","  inflating: ./models/research/object_detection/images/test/3366.jpg  \n","  inflating: ./models/research/object_detection/images/test/3086.jpg  \n","  inflating: ./models/research/object_detection/images/test/3286.jpg  \n","  inflating: ./models/research/object_detection/images/test/3215.jpg  \n","  inflating: ./models/research/object_detection/images/test/3164.xml  \n","  inflating: ./models/research/object_detection/images/test/3270.jpg  \n","  inflating: ./models/research/object_detection/images/test/3093.xml  \n","  inflating: ./models/research/object_detection/images/test/3134.jpg  \n","  inflating: ./models/research/object_detection/images/test/3089.jpg  \n","  inflating: ./models/research/object_detection/images/test/3279.xml  \n","  inflating: ./models/research/object_detection/images/test/3066.jpg  \n","  inflating: ./models/research/object_detection/images/test/3291.jpg  \n","  inflating: ./models/research/object_detection/images/test/3368.xml  \n","  inflating: ./models/research/object_detection/images/test/3192.jpg  \n","  inflating: ./models/research/object_detection/images/test/3284.jpg  \n","  inflating: ./models/research/object_detection/images/test/3242.jpg  \n","  inflating: ./models/research/object_detection/images/test/3236.jpg  \n","  inflating: ./models/research/object_detection/images/test/3308.xml  \n","  inflating: ./models/research/object_detection/images/test/3362.jpg  \n","  inflating: ./models/research/object_detection/images/test/3122.jpg  \n","  inflating: ./models/research/object_detection/images/test/3217.xml  \n","  inflating: ./models/research/object_detection/images/test/3158.xml  \n","  inflating: ./models/research/object_detection/images/test/3354.xml  \n","  inflating: ./models/research/object_detection/images/test/3310.xml  \n","  inflating: ./models/research/object_detection/images/test/3080.xml  \n","  inflating: ./models/research/object_detection/images/test/3040.xml  \n","  inflating: ./models/research/object_detection/images/test/3121.jpg  \n","  inflating: ./models/research/object_detection/images/test/3283.jpg  \n","  inflating: ./models/research/object_detection/images/test/3051.jpg  \n","  inflating: ./models/research/object_detection/images/test/3107.xml  \n","  inflating: ./models/research/object_detection/images/test/3076.xml  \n","  inflating: ./models/research/object_detection/images/test/3404.jpg  \n","  inflating: ./models/research/object_detection/images/test/3315.jpg  \n","  inflating: ./models/research/object_detection/images/test/3259.xml  \n","  inflating: ./models/research/object_detection/images/test/3136.xml  \n","  inflating: ./models/research/object_detection/images/test/3166.xml  \n","  inflating: ./models/research/object_detection/images/test/3176.xml  \n","  inflating: ./models/research/object_detection/images/test/3215.xml  \n","  inflating: ./models/research/object_detection/images/test/3359.xml  \n","  inflating: ./models/research/object_detection/images/test/3121.xml  \n","  inflating: ./models/research/object_detection/images/test/3145.jpg  \n","  inflating: ./models/research/object_detection/images/test/3028.jpg  \n","  inflating: ./models/research/object_detection/images/test/3041.xml  \n","  inflating: ./models/research/object_detection/images/test/3304.jpg  \n","  inflating: ./models/research/object_detection/images/test/3171.xml  \n","  inflating: ./models/research/object_detection/images/test/3060.xml  \n","  inflating: ./models/research/object_detection/images/test/3263.jpg  \n","  inflating: ./models/research/object_detection/images/test/3288.xml  \n","  inflating: ./models/research/object_detection/images/test/3067.jpg  \n","  inflating: ./models/research/object_detection/images/test/3324.jpg  \n","  inflating: ./models/research/object_detection/images/test/3059.xml  \n","  inflating: ./models/research/object_detection/images/test/3392.xml  \n","  inflating: ./models/research/object_detection/images/test/3118.jpg  \n","  inflating: ./models/research/object_detection/images/test/3218.jpg  \n","  inflating: ./models/research/object_detection/images/test/3151.jpg  \n","  inflating: ./models/research/object_detection/images/test/3194.jpg  \n","  inflating: ./models/research/object_detection/images/test/3370.xml  \n","  inflating: ./models/research/object_detection/images/test/3197.xml  \n","  inflating: ./models/research/object_detection/images/test/3146.jpg  \n","  inflating: ./models/research/object_detection/images/test/3049.jpg  \n","  inflating: ./models/research/object_detection/images/test/3346.xml  \n","  inflating: ./models/research/object_detection/images/test/3209.xml  \n","  inflating: ./models/research/object_detection/images/test/3213.xml  \n","  inflating: ./models/research/object_detection/images/test/3159.xml  \n","  inflating: ./models/research/object_detection/images/test/3158.jpg  \n","  inflating: ./models/research/object_detection/images/test/3042.xml  \n","  inflating: ./models/research/object_detection/images/test/3122.xml  \n","  inflating: ./models/research/object_detection/images/test/3367.xml  \n","  inflating: ./models/research/object_detection/images/test/3211.jpg  \n","  inflating: ./models/research/object_detection/images/test/3393.jpg  \n","  inflating: ./models/research/object_detection/images/test/3152.jpg  \n","  inflating: ./models/research/object_detection/images/test/3148.xml  \n","  inflating: ./models/research/object_detection/images/test/3193.jpg  \n","  inflating: ./models/research/object_detection/images/test/3241.jpg  \n","  inflating: ./models/research/object_detection/images/test/3124.jpg  \n","  inflating: ./models/research/object_detection/images/test/3078.xml  \n","  inflating: ./models/research/object_detection/images/test/3247.xml  \n","  inflating: ./models/research/object_detection/images/test/3246.xml  \n","  inflating: ./models/research/object_detection/images/test/3348.xml  \n","  inflating: ./models/research/object_detection/images/test/3255.xml  \n","  inflating: ./models/research/object_detection/images/test/3031.xml  \n","  inflating: ./models/research/object_detection/images/test/3119.xml  \n","  inflating: ./models/research/object_detection/images/test/3027.xml  \n","  inflating: ./models/research/object_detection/images/test/3326.jpg  \n","  inflating: ./models/research/object_detection/images/test/3013.jpg  \n","  inflating: ./models/research/object_detection/images/test/3374.xml  \n","  inflating: ./models/research/object_detection/images/test/3063.jpg  \n","  inflating: ./models/research/object_detection/images/test/3369.jpg  \n","  inflating: ./models/research/object_detection/images/test/3308.jpg  \n","  inflating: ./models/research/object_detection/images/test/3050.xml  \n","  inflating: ./models/research/object_detection/images/test/3023.xml  \n","  inflating: ./models/research/object_detection/images/test/3300.xml  \n","  inflating: ./models/research/object_detection/images/test/3125.jpg  \n","  inflating: ./models/research/object_detection/images/test/3286.xml  \n","  inflating: ./models/research/object_detection/images/test/3079.xml  \n","  inflating: ./models/research/object_detection/images/test/3060.jpg  \n","  inflating: ./models/research/object_detection/images/test/3333.jpg  \n","  inflating: ./models/research/object_detection/images/test/3181.jpg  \n","  inflating: ./models/research/object_detection/images/test/3208.xml  \n","  inflating: ./models/research/object_detection/images/test/3405.jpg  \n","  inflating: ./models/research/object_detection/images/test/3276.xml  \n","  inflating: ./models/research/object_detection/images/test/3256.jpg  \n","  inflating: ./models/research/object_detection/images/test/3408.xml  \n","  inflating: ./models/research/object_detection/images/test/3303.xml  \n","  inflating: ./models/research/object_detection/images/test/3132.xml  \n","  inflating: ./models/research/object_detection/images/test/3221.jpg  \n","  inflating: ./models/research/object_detection/images/test/3198.jpg  \n","  inflating: ./models/research/object_detection/images/test/3026.xml  \n","  inflating: ./models/research/object_detection/images/test/3211.xml  \n","  inflating: ./models/research/object_detection/images/test/3268.jpg  \n","  inflating: ./models/research/object_detection/images/test/3137.xml  \n","  inflating: ./models/research/object_detection/images/test/3170.xml  \n","  inflating: ./models/research/object_detection/images/test/3024.jpg  \n","  inflating: ./models/research/object_detection/images/test/3174.jpg  \n","  inflating: ./models/research/object_detection/images/test/3166.jpg  \n","  inflating: ./models/research/object_detection/images/test/3350.xml  \n","  inflating: ./models/research/object_detection/images/test/3404.xml  \n","  inflating: ./models/research/object_detection/images/test/3132.jpg  \n","  inflating: ./models/research/object_detection/images/test/3058.xml  \n","  inflating: ./models/research/object_detection/images/test/3325.jpg  \n","  inflating: ./models/research/object_detection/images/test/3297.xml  \n","  inflating: ./models/research/object_detection/images/test/3057.xml  \n","  inflating: ./models/research/object_detection/images/test/3247.jpg  \n","  inflating: ./models/research/object_detection/images/test/3345.xml  \n","  inflating: ./models/research/object_detection/images/test/3059.jpg  \n","  inflating: ./models/research/object_detection/images/test/3143.jpg  \n","  inflating: ./models/research/object_detection/images/test/3130.xml  \n","  inflating: ./models/research/object_detection/images/test/3261.xml  \n","  inflating: ./models/research/object_detection/images/test/3114.jpg  \n","  inflating: ./models/research/object_detection/images/test/3205.jpg  \n","  inflating: ./models/research/object_detection/images/test/3327.xml  \n","  inflating: ./models/research/object_detection/images/test/3101.xml  \n","  inflating: ./models/research/object_detection/images/test/3169.xml  \n","  inflating: ./models/research/object_detection/images/test/3269.jpg  \n","  inflating: ./models/research/object_detection/images/test/3388.xml  \n","  inflating: ./models/research/object_detection/images/test/3144.xml  \n","  inflating: ./models/research/object_detection/images/test/3216.xml  \n","  inflating: ./models/research/object_detection/images/test/3183.jpg  \n","  inflating: ./models/research/object_detection/images/test/3129.jpg  \n","  inflating: ./models/research/object_detection/images/test/3093.jpg  \n","  inflating: ./models/research/object_detection/images/test/3355.xml  \n","  inflating: ./models/research/object_detection/images/test/3227.xml  \n","  inflating: ./models/research/object_detection/images/test/3113.xml  \n","  inflating: ./models/research/object_detection/images/test/3135.jpg  \n","  inflating: ./models/research/object_detection/images/test/3373.jpg  \n","  inflating: ./models/research/object_detection/images/test/3401.jpg  \n","  inflating: ./models/research/object_detection/images/test/3339.jpg  \n","  inflating: ./models/research/object_detection/images/test/3134.xml  \n","  inflating: ./models/research/object_detection/images/test/3103.jpg  \n","  inflating: ./models/research/object_detection/images/test/3138.jpg  \n","  inflating: ./models/research/object_detection/images/test/3079.jpg  \n","  inflating: ./models/research/object_detection/images/test/3225.jpg  \n","  inflating: ./models/research/object_detection/images/test/3283.xml  \n","  inflating: ./models/research/object_detection/images/test/3104.xml  \n","  inflating: ./models/research/object_detection/images/test/3331.jpg  \n","  inflating: ./models/research/object_detection/images/test/3377.xml  \n","  inflating: ./models/research/object_detection/images/test/3045.jpg  \n","  inflating: ./models/research/object_detection/images/test/3357.xml  \n","  inflating: ./models/research/object_detection/images/test/3174.xml  \n","  inflating: ./models/research/object_detection/images/test/3254.xml  \n","  inflating: ./models/research/object_detection/images/test/3149.xml  \n","  inflating: ./models/research/object_detection/images/test/3243.jpg  \n","  inflating: ./models/research/object_detection/images/test/3305.xml  \n","  inflating: ./models/research/object_detection/images/test/3083.xml  \n","  inflating: ./models/research/object_detection/images/test/3045.xml  \n","  inflating: ./models/research/object_detection/images/test/3135.xml  \n","  inflating: ./models/research/object_detection/images/test/3277.xml  \n","  inflating: ./models/research/object_detection/images/test/3235.jpg  \n","  inflating: ./models/research/object_detection/images/test/3219.jpg  \n","  inflating: ./models/research/object_detection/images/test/3235.xml  \n","  inflating: ./models/research/object_detection/images/test/3293.jpg  \n","  inflating: ./models/research/object_detection/images/test/3232.jpg  \n","  inflating: ./models/research/object_detection/images/test/3163.jpg  \n","  inflating: ./models/research/object_detection/images/test/3128.xml  \n","  inflating: ./models/research/object_detection/images/test/3036.jpg  \n","  inflating: ./models/research/object_detection/images/test/3353.jpg  \n","  inflating: ./models/research/object_detection/images/test/3343.jpg  \n","  inflating: ./models/research/object_detection/images/test/3096.jpg  \n","  inflating: ./models/research/object_detection/images/test/3349.jpg  \n","  inflating: ./models/research/object_detection/images/test/3170.jpg  \n","  inflating: ./models/research/object_detection/images/test/3287.jpg  \n","  inflating: ./models/research/object_detection/images/test/3248.xml  \n","  inflating: ./models/research/object_detection/images/test/3384.xml  \n","  inflating: ./models/research/object_detection/images/test/3153.xml  \n","  inflating: ./models/research/object_detection/images/test/3073.xml  \n","  inflating: ./models/research/object_detection/images/test/3227.jpg  \n","  inflating: ./models/research/object_detection/images/test/3159.jpg  \n","  inflating: ./models/research/object_detection/images/test/3172.jpg  \n","  inflating: ./models/research/object_detection/images/test/3356.xml  \n","  inflating: ./models/research/object_detection/images/test/3317.jpg  \n","  inflating: ./models/research/object_detection/images/test/3179.xml  \n","  inflating: ./models/research/object_detection/images/test/3337.xml  \n","  inflating: ./models/research/object_detection/images/test/3375.xml  \n","  inflating: ./models/research/object_detection/images/test/3237.jpg  \n","  inflating: ./models/research/object_detection/images/test/3251.jpg  \n","  inflating: ./models/research/object_detection/images/test/3179.jpg  \n","  inflating: ./models/research/object_detection/images/test/3312.xml  \n","  inflating: ./models/research/object_detection/images/test/3175.jpg  \n","  inflating: ./models/research/object_detection/images/test/3043.xml  \n","  inflating: ./models/research/object_detection/images/test/3115.xml  \n","  inflating: ./models/research/object_detection/images/test/3410.jpg  \n","  inflating: ./models/research/object_detection/images/test/3176.jpg  \n","  inflating: ./models/research/object_detection/images/test/3229.xml  \n","  inflating: ./models/research/object_detection/images/test/3013.xml  \n","  inflating: ./models/research/object_detection/images/test/3187.jpg  \n","  inflating: ./models/research/object_detection/images/test/3396.jpg  \n","  inflating: ./models/research/object_detection/images/test/3081.xml  \n","  inflating: ./models/research/object_detection/images/test/3292.xml  \n","  inflating: ./models/research/object_detection/images/test/3100.jpg  \n","  inflating: ./models/research/object_detection/images/test/3330.xml  \n","  inflating: ./models/research/object_detection/images/test/3222.xml  \n","  inflating: ./models/research/object_detection/images/test/3095.jpg  \n","  inflating: ./models/research/object_detection/images/test/3400.jpg  \n","  inflating: ./models/research/object_detection/images/test/3375.jpg  \n","  inflating: ./models/research/object_detection/images/test/3098.xml  \n","  inflating: ./models/research/object_detection/images/test/3313.xml  \n","  inflating: ./models/research/object_detection/images/test/3116.jpg  \n","  inflating: ./models/research/object_detection/images/test/3328.xml  \n","  inflating: ./models/research/object_detection/images/test/3285.jpg  \n","  inflating: ./models/research/object_detection/images/test/3034.xml  \n","  inflating: ./models/research/object_detection/images/test/3406.xml  \n","  inflating: ./models/research/object_detection/images/test/3356.jpg  \n","  inflating: ./models/research/object_detection/images/test/3387.xml  \n","  inflating: ./models/research/object_detection/images/test/3407.xml  \n","  inflating: ./models/research/object_detection/images/test/3349.xml  \n","  inflating: ./models/research/object_detection/images/test/3053.jpg  \n","  inflating: ./models/research/object_detection/images/test/3317.xml  \n","  inflating: ./models/research/object_detection/images/test/3273.jpg  \n","  inflating: ./models/research/object_detection/images/test/3275.jpg  \n","  inflating: ./models/research/object_detection/images/test/3190.xml  \n","  inflating: ./models/research/object_detection/images/test/3323.jpg  \n","  inflating: ./models/research/object_detection/images/test/3165.xml  \n","  inflating: ./models/research/object_detection/images/test/3240.jpg  \n","  inflating: ./models/research/object_detection/images/test/3341.xml  \n","  inflating: ./models/research/object_detection/images/test/3097.jpg  \n","  inflating: ./models/research/object_detection/images/test/3021.xml  \n","  inflating: ./models/research/object_detection/images/test/3282.jpg  \n","  inflating: ./models/research/object_detection/images/test/3266.xml  \n","  inflating: ./models/research/object_detection/images/test/3022.jpg  \n","  inflating: ./models/research/object_detection/images/test/3403.jpg  \n","  inflating: ./models/research/object_detection/images/test/3345.jpg  \n","  inflating: ./models/research/object_detection/images/test/3184.xml  \n","  inflating: ./models/research/object_detection/images/test/3319.xml  \n","  inflating: ./models/research/object_detection/images/test/3112.xml  \n","  inflating: ./models/research/object_detection/images/test/3110.jpg  \n","  inflating: ./models/research/object_detection/images/test/3015.jpg  \n","  inflating: ./models/research/object_detection/images/test/3107.jpg  \n","  inflating: ./models/research/object_detection/images/test/3098.jpg  \n","  inflating: ./models/research/object_detection/images/test/3033.jpg  \n","  inflating: ./models/research/object_detection/images/test/3196.jpg  \n","  inflating: ./models/research/object_detection/images/test/3149.jpg  \n","  inflating: ./models/research/object_detection/images/test/3025.xml  \n","  inflating: ./models/research/object_detection/images/test/3238.jpg  \n","  inflating: ./models/research/object_detection/images/test/3189.jpg  \n","  inflating: ./models/research/object_detection/images/test/3256.xml  \n","  inflating: ./models/research/object_detection/images/test/3064.xml  \n","  inflating: ./models/research/object_detection/images/test/3214.xml  \n","  inflating: ./models/research/object_detection/images/test/3328.jpg  \n","  inflating: ./models/research/object_detection/images/test/3382.jpg  \n","  inflating: ./models/research/object_detection/images/test/3160.jpg  \n","  inflating: ./models/research/object_detection/images/test/3038.xml  \n","  inflating: ./models/research/object_detection/images/test/3023.jpg  \n","  inflating: ./models/research/object_detection/images/test/3344.jpg  \n","  inflating: ./models/research/object_detection/images/test/3352.xml  \n","  inflating: ./models/research/object_detection/images/test/3156.jpg  \n","  inflating: ./models/research/object_detection/images/test/3335.jpg  \n","  inflating: ./models/research/object_detection/images/test/3131.jpg  \n","  inflating: ./models/research/object_detection/images/test/3032.jpg  \n","  inflating: ./models/research/object_detection/images/test/3203.xml  \n","  inflating: ./models/research/object_detection/images/test/3056.jpg  \n","  inflating: ./models/research/object_detection/images/test/3044.xml  \n","  inflating: ./models/research/object_detection/images/test/3137.jpg  \n","  inflating: ./models/research/object_detection/images/test/3265.jpg  \n","  inflating: ./models/research/object_detection/images/test/3398.xml  \n","  inflating: ./models/research/object_detection/images/test/3336.xml  \n","  inflating: ./models/research/object_detection/images/test/3193.xml  \n","  inflating: ./models/research/object_detection/images/test/3055.jpg  \n","  inflating: ./models/research/object_detection/images/test/3188.xml  \n","  inflating: ./models/research/object_detection/images/test/3390.jpg  \n","  inflating: ./models/research/object_detection/images/test/3287.xml  \n","  inflating: ./models/research/object_detection/images/test/3220.xml  \n","  inflating: ./models/research/object_detection/images/test/3362.xml  \n","  inflating: ./models/research/object_detection/images/test/3067.xml  \n","  inflating: ./models/research/object_detection/images/test/3191.jpg  \n","  inflating: ./models/research/object_detection/images/test/3130.jpg  \n","  inflating: ./models/research/object_detection/images/test/3015.xml  \n","  inflating: ./models/research/object_detection/images/test/3117.jpg  \n","  inflating: ./models/research/object_detection/images/test/3233.xml  \n","  inflating: ./models/research/object_detection/images/test/3192.xml  \n","  inflating: ./models/research/object_detection/images/test/3360.xml  \n","  inflating: ./models/research/object_detection/images/test/3271.jpg  \n","  inflating: ./models/research/object_detection/images/test/3253.jpg  \n","  inflating: ./models/research/object_detection/images/test/3162.xml  \n","  inflating: ./models/research/object_detection/images/test/3203.jpg  \n","  inflating: ./models/research/object_detection/images/test/3125.xml  \n","  inflating: ./models/research/object_detection/images/test/3124.xml  \n","  inflating: ./models/research/object_detection/images/test/3054.jpg  \n","  inflating: ./models/research/object_detection/images/test/3405.xml  \n","  inflating: ./models/research/object_detection/images/test/3371.xml  \n","  inflating: ./models/research/object_detection/images/test/3238.xml  \n","  inflating: ./models/research/object_detection/images/test/3196.xml  \n","  inflating: ./models/research/object_detection/images/test/3019.xml  \n","  inflating: ./models/research/object_detection/images/test/3237.xml  \n","  inflating: ./models/research/object_detection/images/test/3400.xml  \n","  inflating: ./models/research/object_detection/images/test/3027.jpg  \n","  inflating: ./models/research/object_detection/images/test/3100.xml  \n","  inflating: ./models/research/object_detection/images/test/3126.xml  \n","  inflating: ./models/research/object_detection/images/test/3075.xml  \n","  inflating: ./models/research/object_detection/images/test/3199.jpg  \n","  inflating: ./models/research/object_detection/images/test/3281.xml  \n","  inflating: ./models/research/object_detection/images/test/3177.jpg  \n","  inflating: ./models/research/object_detection/images/test/3318.jpg  \n","  inflating: ./models/research/object_detection/images/test/3133.xml  \n","  inflating: ./models/research/object_detection/images/test/3334.jpg  \n","  inflating: ./models/research/object_detection/images/test/3035.jpg  \n","  inflating: ./models/research/object_detection/images/test/3372.jpg  \n","  inflating: ./models/research/object_detection/images/test/3392.jpg  \n","  inflating: ./models/research/object_detection/images/test/3088.jpg  \n","  inflating: ./models/research/object_detection/images/test/3032.xml  \n","  inflating: ./models/research/object_detection/images/test/3384.jpg  \n","  inflating: ./models/research/object_detection/images/test/3097.xml  \n","  inflating: ./models/research/object_detection/images/test/3409.jpg  \n","  inflating: ./models/research/object_detection/images/test/3182.xml  \n","  inflating: ./models/research/object_detection/images/test/3092.jpg  \n","  inflating: ./models/research/object_detection/images/test/3319.jpg  \n","  inflating: ./models/research/object_detection/images/test/3070.xml  \n","  inflating: ./models/research/object_detection/images/test/3381.jpg  \n","  inflating: ./models/research/object_detection/images/test/3228.xml  \n","  inflating: ./models/research/object_detection/images/test/3106.xml  \n","  inflating: ./models/research/object_detection/images/test/3255.jpg  \n","  inflating: ./models/research/object_detection/images/test/3074.xml  \n","  inflating: ./models/research/object_detection/images/test/3075.jpg  \n","  inflating: ./models/research/object_detection/images/test/3039.xml  \n","  inflating: ./models/research/object_detection/images/test/3070.jpg  \n","  inflating: ./models/research/object_detection/images/test/3391.xml  \n","  inflating: ./models/research/object_detection/images/test/3381.xml  \n","  inflating: ./models/research/object_detection/images/test/3290.jpg  \n","  inflating: ./models/research/object_detection/images/test/3377.jpg  \n","  inflating: ./models/research/object_detection/images/test/3254.jpg  \n","  inflating: ./models/research/object_detection/images/test/3087.jpg  \n","  inflating: ./models/research/object_detection/images/test/3197.jpg  \n","  inflating: ./models/research/object_detection/images/test/3340.jpg  \n","  inflating: ./models/research/object_detection/images/test/3083.jpg  \n","  inflating: ./models/research/object_detection/images/test/3361.jpg  \n","  inflating: ./models/research/object_detection/images/test/3114.xml  \n","  inflating: ./models/research/object_detection/images/test/3071.xml  \n","  inflating: ./models/research/object_detection/images/test/3323.xml  \n","  inflating: ./models/research/object_detection/images/test/3225.xml  \n","  inflating: ./models/research/object_detection/images/test/3289.jpg  \n","  inflating: ./models/research/object_detection/images/test/3311.xml  \n","  inflating: ./models/research/object_detection/images/test/3310.jpg  \n","  inflating: ./models/research/object_detection/images/test/3177.xml  \n","  inflating: ./models/research/object_detection/images/test/3316.xml  \n","  inflating: ./models/research/object_detection/images/test/3173.jpg  \n","  inflating: ./models/research/object_detection/images/test/3321.xml  \n","  inflating: ./models/research/object_detection/images/test/3280.xml  \n","  inflating: ./models/research/object_detection/images/test/3095.xml  \n","  inflating: ./models/research/object_detection/images/test/3364.xml  \n","  inflating: ./models/research/object_detection/images/test/3299.xml  \n","  inflating: ./models/research/object_detection/images/test/3244.xml  \n","  inflating: ./models/research/object_detection/images/test/3214.jpg  \n","  inflating: ./models/research/object_detection/images/test/3304.xml  \n","  inflating: ./models/research/object_detection/images/test/3102.jpg  \n","  inflating: ./models/research/object_detection/images/test/3156.xml  \n","  inflating: ./models/research/object_detection/images/test/3212.jpg  \n","  inflating: ./models/research/object_detection/images/test/3139.jpg  \n","  inflating: ./models/research/object_detection/images/test/3250.jpg  \n","  inflating: ./models/research/object_detection/images/test/3248.jpg  \n","  inflating: ./models/research/object_detection/images/test/3274.xml  \n","  inflating: ./models/research/object_detection/images/test/3218.xml  \n","  inflating: ./models/research/object_detection/images/test/3320.xml  \n","  inflating: ./models/research/object_detection/images/test/3087.xml  \n","  inflating: ./models/research/object_detection/images/test/3020.xml  \n","  inflating: ./models/research/object_detection/images/test/3259.jpg  \n","  inflating: ./models/research/object_detection/images/test/3285.xml  \n","  inflating: ./models/research/object_detection/images/test/3131.xml  \n","  inflating: ./models/research/object_detection/images/test/3291.xml  \n","  inflating: ./models/research/object_detection/images/test/3136.jpg  \n","  inflating: ./models/research/object_detection/images/test/3363.xml  \n","  inflating: ./models/research/object_detection/images/test/3292.jpg  \n","  inflating: ./models/research/object_detection/images/test/3263.xml  \n","  inflating: ./models/research/object_detection/images/test/3278.xml  \n","  inflating: ./models/research/object_detection/images/test/3268.xml  \n","  inflating: ./models/research/object_detection/images/test/3182.jpg  \n","  inflating: ./models/research/object_detection/images/test/3380.xml  \n","  inflating: ./models/research/object_detection/images/test/3057.jpg  \n","  inflating: ./models/research/object_detection/images/test/3143.xml  \n","  inflating: ./models/research/object_detection/images/test/3397.jpg  \n","  inflating: ./models/research/object_detection/images/test/3296.jpg  \n","  inflating: ./models/research/object_detection/images/test/3195.jpg  \n","  inflating: ./models/research/object_detection/images/test/3325.xml  \n","  inflating: ./models/research/object_detection/images/test/3178.xml  \n","  inflating: ./models/research/object_detection/images/test/3228.jpg  \n","  inflating: ./models/research/object_detection/images/test/3262.jpg  \n","  inflating: ./models/research/object_detection/images/test/3298.jpg  \n","  inflating: ./models/research/object_detection/images/test/3162.jpg  \n","  inflating: ./models/research/object_detection/images/test/3074.jpg  \n","  inflating: ./models/research/object_detection/images/test/3313.jpg  \n","  inflating: ./models/research/object_detection/images/test/3148.jpg  \n","  inflating: ./models/research/object_detection/images/test/3069.xml  \n","  inflating: ./models/research/object_detection/images/test/3394.jpg  \n","  inflating: ./models/research/object_detection/images/test/3142.xml  \n","  inflating: ./models/research/object_detection/images/test/3037.jpg  \n","  inflating: ./models/research/object_detection/images/test/3090.jpg  \n","  inflating: ./models/research/object_detection/images/test/3233.jpg  \n","  inflating: ./models/research/object_detection/images/test/3058.jpg  \n","  inflating: ./models/research/object_detection/images/test/3224.jpg  \n","  inflating: ./models/research/object_detection/images/test/3257.jpg  \n","  inflating: ./models/research/object_detection/images/test/3267.jpg  \n","  inflating: ./models/research/object_detection/images/test/3094.xml  \n","  inflating: ./models/research/object_detection/images/test/3302.xml  \n","  inflating: ./models/research/object_detection/images/test/3398.jpg  \n","  inflating: ./models/research/object_detection/images/test/3265.xml  \n","  inflating: ./models/research/object_detection/images/test/3332.jpg  \n","  inflating: ./models/research/object_detection/images/test/3258.xml  \n","  inflating: ./models/research/object_detection/images/test/3202.jpg  \n","  inflating: ./models/research/object_detection/images/test/3331.xml  \n","  inflating: ./models/research/object_detection/images/test/3367.jpg  \n","  inflating: ./models/research/object_detection/images/test/3300.jpg  \n","  inflating: ./models/research/object_detection/images/test/3262.xml  \n","  inflating: ./models/research/object_detection/images/test/3207.jpg  \n","  inflating: ./models/research/object_detection/images/test/3269.xml  \n","  inflating: ./models/research/object_detection/images/test/3072.xml  \n","  inflating: ./models/research/object_detection/images/test/3236.xml  \n","  inflating: ./models/research/object_detection/images/test/3272.xml  \n","  inflating: ./models/research/object_detection/images/test/3061.xml  \n","  inflating: ./models/research/object_detection/images/test/3353.xml  \n","  inflating: ./models/research/object_detection/images/test/3146.xml  \n","  inflating: ./models/research/object_detection/images/test/3181.xml  \n","  inflating: ./models/research/object_detection/images/test/3321.jpg  \n","  inflating: ./models/research/object_detection/images/test/3160.xml  \n","  inflating: ./models/research/object_detection/images/test/3388.jpg  \n","  inflating: ./models/research/object_detection/images/test/3359.jpg  \n","  inflating: ./models/research/object_detection/images/test/3022.xml  \n","  inflating: ./models/research/object_detection/images/test/3365.xml  \n","  inflating: ./models/research/object_detection/images/test/3231.jpg  \n","  inflating: ./models/research/object_detection/images/test/3091.xml  \n","  inflating: ./models/research/object_detection/images/test/3216.jpg  \n","  inflating: ./models/research/object_detection/images/test/3046.xml  \n","  inflating: ./models/research/object_detection/images/test/3245.xml  \n","  inflating: ./models/research/object_detection/images/test/3047.xml  \n","  inflating: ./models/research/object_detection/images/test/3194.xml  \n","  inflating: ./models/research/object_detection/images/test/3335.xml  \n","  inflating: ./models/research/object_detection/images/test/3147.xml  \n","  inflating: ./models/research/object_detection/images/test/3290.xml  \n","  inflating: ./models/research/object_detection/images/test/3260.xml  \n","  inflating: ./models/research/object_detection/images/test/3147.jpg  \n","  inflating: ./models/research/object_detection/images/test/3288.jpg  \n","  inflating: ./models/research/object_detection/images/test/3380.jpg  \n","  inflating: ./models/research/object_detection/images/test/3297.jpg  \n","  inflating: ./models/research/object_detection/images/test/3298.xml  \n","  inflating: ./models/research/object_detection/images/test/3270.xml  \n","  inflating: ./models/research/object_detection/images/test/3299.jpg  \n","  inflating: ./models/research/object_detection/images/test/3302.jpg  \n","  inflating: ./models/research/object_detection/images/test/3091.jpg  \n","  inflating: ./models/research/object_detection/images/test/3089.xml  \n","  inflating: ./models/research/object_detection/images/test/3306.jpg  \n","  inflating: ./models/research/object_detection/images/test/3276.jpg  \n","  inflating: ./models/research/object_detection/images/test/3151.xml  \n","  inflating: ./models/research/object_detection/images/test/3376.jpg  \n","  inflating: ./models/research/object_detection/images/test/3350.jpg  \n","  inflating: ./models/research/object_detection/images/test/3063.xml  \n","  inflating: ./models/research/object_detection/images/test/3164.jpg  \n","  inflating: ./models/research/object_detection/images/test/3139.xml  \n","  inflating: ./models/research/object_detection/images/test/3157.xml  \n","  inflating: ./models/research/object_detection/images/test/3202.xml  \n","  inflating: ./models/research/object_detection/images/test/3066.xml  \n","  inflating: ./models/research/object_detection/images/test/3028.xml  \n","  inflating: ./models/research/object_detection/images/test/3106.jpg  \n","  inflating: ./models/research/object_detection/images/test/3047.jpg  \n","  inflating: ./models/research/object_detection/images/test/3084.xml  \n","  inflating: ./models/research/object_detection/images/test/3115.jpg  \n","  inflating: ./models/research/object_detection/images/test/3014.xml  \n","  inflating: ./models/research/object_detection/images/test/3138.xml  \n","  inflating: ./models/research/object_detection/images/test/3150.xml  \n","  inflating: ./models/research/object_detection/images/test/3294.jpg  \n","  inflating: ./models/research/object_detection/images/test/3351.xml  \n","  inflating: ./models/research/object_detection/images/test/3378.xml  \n","  inflating: ./models/research/object_detection/images/test/3279.jpg  \n","  inflating: ./models/research/object_detection/images/test/3230.jpg  \n","  inflating: ./models/research/object_detection/images/test/3117.xml  \n","  inflating: ./models/research/object_detection/images/test/3127.jpg  \n","  inflating: ./models/research/object_detection/images/test/3258.jpg  \n","  inflating: ./models/research/object_detection/images/test/3296.xml  \n","  inflating: ./models/research/object_detection/images/test/3240.xml  \n","  inflating: ./models/research/object_detection/images/test/3041.jpg  \n","  inflating: ./models/research/object_detection/images/test/3110.xml  \n","  inflating: ./models/research/object_detection/images/test/3030.jpg  \n","  inflating: ./models/research/object_detection/images/test/3065.xml  \n","  inflating: ./models/research/object_detection/images/test/3204.xml  \n","  inflating: ./models/research/object_detection/images/test/3108.jpg  \n","  inflating: ./models/research/object_detection/images/test/3326.xml  \n","  inflating: ./models/research/object_detection/images/test/3029.jpg  \n","  inflating: ./models/research/object_detection/images/test/3261.jpg  \n","  inflating: ./models/research/object_detection/images/test/3092.xml  \n","  inflating: ./models/research/object_detection/images/test/3141.jpg  \n","  inflating: ./models/research/object_detection/images/test/3128.jpg  \n","  inflating: ./models/research/object_detection/images/test/3245.jpg  \n","  inflating: ./models/research/object_detection/images/test/3368.jpg  \n","  inflating: ./models/research/object_detection/images/test/3232.xml  \n","  inflating: ./models/research/object_detection/images/test/3226.xml  \n","  inflating: ./models/research/object_detection/images/test/3039.jpg  \n","  inflating: ./models/research/object_detection/images/test/3205.xml  \n","  inflating: ./models/research/object_detection/images/test/3399.xml  \n","  inflating: ./models/research/object_detection/images/test/3342.jpg  \n","  inflating: ./models/research/object_detection/images/test/3295.jpg  \n","  inflating: ./models/research/object_detection/images/test/3036.xml  \n","  inflating: ./models/research/object_detection/images/test/3267.xml  \n","  inflating: ./models/research/object_detection/images/test/3021.jpg  \n","  inflating: ./models/research/object_detection/images/test/3206.jpg  \n","  inflating: ./models/research/object_detection/images/test/3260.jpg  \n","  inflating: ./models/research/object_detection/images/test/3357.jpg  \n","  inflating: ./models/research/object_detection/images/test/3301.jpg  \n","  inflating: ./models/research/object_detection/images/test/3311.jpg  \n","  inflating: ./models/research/object_detection/images/test/3123.jpg  \n","  inflating: ./models/research/object_detection/images/test/3369.xml  \n","  inflating: ./models/research/object_detection/images/test/3306.xml  \n","  inflating: ./models/research/object_detection/images/test/3278.jpg  \n","  inflating: ./models/research/object_detection/images/test/3314.xml  \n","  inflating: ./models/research/object_detection/images/test/3044.jpg  \n","  inflating: ./models/research/object_detection/images/test/3295.xml  \n","  inflating: ./models/research/object_detection/images/test/3033.xml  \n","  inflating: ./models/research/object_detection/images/test/3309.jpg  \n","  inflating: ./models/research/object_detection/images/test/3249.xml  \n","  inflating: ./models/research/object_detection/images/test/3361.xml  \n","  inflating: ./models/research/object_detection/images/test/3223.xml  \n","  inflating: ./models/research/object_detection/images/test/3364.jpg  \n","  inflating: ./models/research/object_detection/images/test/3168.xml  \n","  inflating: ./models/research/object_detection/images/test/3073.jpg  \n","  inflating: ./models/research/object_detection/images/test/3210.jpg  \n","  inflating: ./models/research/object_detection/images/test/3180.xml  \n","  inflating: ./models/research/object_detection/images/test/3389.xml  \n","  inflating: ./models/research/object_detection/images/test/3113.jpg  \n","  inflating: ./models/research/object_detection/images/test/3082.xml  \n","  inflating: ./models/research/object_detection/images/test/3054.xml  \n","  inflating: ./models/research/object_detection/images/test/3347.xml  \n","  inflating: ./models/research/object_detection/images/test/3052.jpg  \n","  inflating: ./models/research/object_detection/images/test/3183.xml  \n","  inflating: ./models/research/object_detection/images/test/3226.jpg  \n","  inflating: ./models/research/object_detection/images/test/3322.xml  \n","  inflating: ./models/research/object_detection/images/test/3264.xml  \n","  inflating: ./models/research/object_detection/images/test/3352.jpg  \n","  inflating: ./models/research/object_detection/images/test/3069.jpg  \n","  inflating: ./models/research/object_detection/images/test/3281.jpg  \n","  inflating: ./models/research/object_detection/images/test/3408.jpg  \n","  inflating: ./models/research/object_detection/images/test/3145.xml  \n","  inflating: ./models/research/object_detection/images/test/3340.xml  \n","  inflating: ./models/research/object_detection/images/test/3223.jpg  \n","  inflating: ./models/research/object_detection/images/test/3275.xml  \n","  inflating: ./models/research/object_detection/images/test/3099.jpg  \n","  inflating: ./models/research/object_detection/images/test/3376.xml  \n","  inflating: ./models/research/object_detection/images/test/3273.xml  \n","  inflating: ./models/research/object_detection/images/test/3365.jpg  \n","  inflating: ./models/research/object_detection/images/test/3133.jpg  \n","  inflating: ./models/research/object_detection/images/test/3167.jpg  \n","  inflating: ./models/research/object_detection/images/test/3180.jpg  \n","  inflating: ./models/research/object_detection/images/test/3251.xml  \n","  inflating: ./models/research/object_detection/images/test/3190.jpg  \n","  inflating: ./models/research/object_detection/images/test/3320.jpg  \n","  inflating: ./models/research/object_detection/images/test/3294.xml  \n","  inflating: ./models/research/object_detection/images/test/3347.jpg  \n","  inflating: ./models/research/object_detection/images/test/3333.xml  \n","  inflating: ./models/research/object_detection/images/test/3169.jpg  \n","  inflating: ./models/research/object_detection/images/test/3080.jpg  \n","  inflating: ./models/research/object_detection/images/test/3065.jpg  \n","  inflating: ./models/research/object_detection/images/test/3382.xml  \n","  inflating: ./models/research/object_detection/images/test/3184.jpg  \n","  inflating: ./models/research/object_detection/images/test/3188.jpg  \n","  inflating: ./models/research/object_detection/images/test/3071.jpg  \n","  inflating: ./models/research/object_detection/images/test/3172.xml  \n","  inflating: ./models/research/object_detection/images/test/3171.jpg  \n","  inflating: ./models/research/object_detection/images/test/3407.jpg  \n","  inflating: ./models/research/object_detection/images/test/3307.xml  \n","  inflating: ./models/research/object_detection/images/test/3105.xml  \n","  inflating: ./models/research/object_detection/images/test/3049.xml  \n","  inflating: ./models/research/object_detection/images/test/3354.jpg  \n","  inflating: ./models/research/object_detection/images/test/3030.xml  \n","  inflating: ./models/research/object_detection/images/test/3126.jpg  \n","  inflating: ./models/research/object_detection/images/test/3038.jpg  \n","  inflating: ./models/research/object_detection/images/test/3322.jpg  \n","  inflating: ./models/research/object_detection/images/test/3395.xml  \n","   creating: ./models/research/object_detection/images/.ipynb_checkpoints/\n","   creating: ./models/research/object_detection/utils/\n","  inflating: ./models/research/object_detection/utils/np_box_list_ops_test.py  \n","  inflating: ./models/research/object_detection/utils/ops_test.py  \n","  inflating: ./models/research/object_detection/utils/test_utils.py  \n","  inflating: ./models/research/object_detection/utils/patch_ops_test.py  \n","  inflating: ./models/research/object_detection/utils/np_box_ops.py  \n","  inflating: ./models/research/object_detection/utils/metrics.py  \n","  inflating: ./models/research/object_detection/utils/np_box_mask_list_test.py  \n","  inflating: ./models/research/object_detection/utils/context_manager_test.py  \n","  inflating: ./models/research/object_detection/utils/np_box_ops_test.py  \n","  inflating: ./models/research/object_detection/utils/np_box_mask_list.py  \n","  inflating: ./models/research/object_detection/utils/np_mask_ops_test.py  \n","  inflating: ./models/research/object_detection/utils/context_manager.py  \n","  inflating: ./models/research/object_detection/utils/test_utils_test.py  \n","  inflating: ./models/research/object_detection/utils/np_box_mask_list_ops_test.py  \n","  inflating: ./models/research/object_detection/utils/variables_helper_test.py  \n","   creating: ./models/research/object_detection/utils/__pycache__/\n","  inflating: ./models/research/object_detection/utils/__pycache__/spatial_transform_ops.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/label_map_util.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/model_util.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/dataset_util.cpython-37.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/ops.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/static_shape.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/variables_helper.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/context_manager.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/learning_schedules.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/shape_utils.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/visualization_utils.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/learning_schedules.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/__init__.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/patch_ops.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/patch_ops.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/label_map_util.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/autoaugment_utils.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/ops.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/static_shape.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/__init__.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/shape_utils.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/model_util.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/autoaugment_utils.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/__init__.cpython-37.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/dataset_util.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/spatial_transform_ops.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/context_manager.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/config_util.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/config_util.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/visualization_utils.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/utils/__pycache__/variables_helper.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/utils/learning_schedules.py  \n","  inflating: ./models/research/object_detection/utils/test_case.py  \n","  inflating: ./models/research/object_detection/utils/vrd_evaluation.py  \n","  inflating: ./models/research/object_detection/utils/shape_utils_test.py  \n","  inflating: ./models/research/object_detection/utils/spatial_transform_ops_test.py  \n","  inflating: ./models/research/object_detection/utils/per_image_vrd_evaluation.py  \n","  inflating: ./models/research/object_detection/utils/np_box_list_ops.py  \n","  inflating: ./models/research/object_detection/utils/object_detection_evaluation.py  \n","  inflating: ./models/research/object_detection/utils/json_utils.py  \n","  inflating: ./models/research/object_detection/utils/label_map_util.py  \n","  inflating: ./models/research/object_detection/utils/visualization_utils.py  \n","  inflating: ./models/research/object_detection/utils/config_util.py  \n","  inflating: ./models/research/object_detection/utils/spatial_transform_ops.py  \n","  inflating: ./models/research/object_detection/utils/variables_helper.py  \n","  inflating: ./models/research/object_detection/utils/dataset_util_test.py  \n","  inflating: ./models/research/object_detection/utils/patch_ops.py  \n","  inflating: ./models/research/object_detection/utils/np_box_list_test.py  \n","  inflating: ./models/research/object_detection/utils/model_util.py  \n","  inflating: ./models/research/object_detection/utils/np_box_mask_list_ops.py  \n","  inflating: ./models/research/object_detection/utils/label_map_util_test.py  \n","  inflating: ./models/research/object_detection/utils/np_box_list.py  \n","  inflating: ./models/research/object_detection/utils/static_shape.py  \n","  inflating: ./models/research/object_detection/utils/per_image_evaluation.py  \n","  inflating: ./models/research/object_detection/utils/autoaugment_utils.py  \n","  inflating: ./models/research/object_detection/utils/dataset_util.py  \n","  inflating: ./models/research/object_detection/utils/per_image_evaluation_test.py  \n","  inflating: ./models/research/object_detection/utils/category_util_test.py  \n"," extracting: ./models/research/object_detection/utils/__init__.py  \n","  inflating: ./models/research/object_detection/utils/json_utils_test.py  \n","  inflating: ./models/research/object_detection/utils/model_util_test.py  \n","  inflating: ./models/research/object_detection/utils/category_util.py  \n","  inflating: ./models/research/object_detection/utils/visualization_utils_test.py  \n","  inflating: ./models/research/object_detection/utils/metrics_test.py  \n","  inflating: ./models/research/object_detection/utils/learning_schedules_test.py  \n","  inflating: ./models/research/object_detection/utils/shape_utils.py  \n","  inflating: ./models/research/object_detection/utils/object_detection_evaluation_test.py  \n","  inflating: ./models/research/object_detection/utils/vrd_evaluation_test.py  \n","  inflating: ./models/research/object_detection/utils/static_shape_test.py  \n","  inflating: ./models/research/object_detection/utils/config_util_test.py  \n","  inflating: ./models/research/object_detection/utils/ops.py  \n","  inflating: ./models/research/object_detection/utils/np_mask_ops.py  \n","  inflating: ./models/research/object_detection/utils/per_image_vrd_evaluation_test.py  \n","   creating: ./models/research/object_detection/legacy/\n","  inflating: ./models/research/object_detection/legacy/train.py  \n","  inflating: ./models/research/object_detection/legacy/trainer_test.py  \n","  inflating: ./models/research/object_detection/legacy/evaluator.py  \n","  inflating: ./models/research/object_detection/legacy/eval.py  \n","   creating: ./models/research/object_detection/legacy/__pycache__/\n","  inflating: ./models/research/object_detection/legacy/__pycache__/trainer.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/legacy/__pycache__/__init__.cpython-36.pyc  \n","  inflating: ./models/research/object_detection/legacy/__pycache__/__init__.cpython-35.pyc  \n","  inflating: ./models/research/object_detection/legacy/__pycache__/trainer.cpython-36.pyc  \n"," extracting: ./models/research/object_detection/legacy/__init__.py  \n","  inflating: ./models/research/object_detection/legacy/trainer.py  \n","  inflating: ./models/research/object_detection/model_lib_v2_test.py  \n","   creating: ./models/research/object_detection/data/\n","  inflating: ./models/research/object_detection/data/pascal_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/mscoco_minival_ids.txt  \n","  inflating: ./models/research/object_detection/data/oid_v4_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/ava_label_map_v2.1.pbtxt  \n","  inflating: ./models/research/object_detection/data/kitti_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/mscoco_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/fgvc_2854_classes_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/face_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/pet_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/mscoco_complete_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt  \n","  inflating: ./models/research/object_detection/model_lib_test.py  \n","  inflating: ./models/research/object_detection/export_tflite_ssd_graph_lib_test.py  \n","   creating: ./models/research/slim/\n","   creating: ./models/research/slim/scripts/\n","  inflating: ./models/research/slim/scripts/finetune_inception_v3_on_flowers.sh  \n","  inflating: ./models/research/slim/scripts/finetune_inception_resnet_v2_on_flowers.sh  \n","  inflating: ./models/research/slim/scripts/train_lenet_on_mnist.sh  \n","  inflating: ./models/research/slim/scripts/finetune_resnet_v1_50_on_flowers.sh  \n","  inflating: ./models/research/slim/scripts/export_mobilenet.sh  \n","  inflating: ./models/research/slim/scripts/train_cifarnet_on_cifar10.sh  \n","  inflating: ./models/research/slim/scripts/finetune_inception_v1_on_flowers.sh  \n","   creating: ./models/research/slim/preprocessing/\n","  inflating: ./models/research/slim/preprocessing/inception_preprocessing.py  \n","  inflating: ./models/research/slim/preprocessing/preprocessing_factory.py  \n","  inflating: ./models/research/slim/preprocessing/lenet_preprocessing.py  \n"," extracting: ./models/research/slim/preprocessing/__init__.py  \n","  inflating: ./models/research/slim/preprocessing/cifarnet_preprocessing.py  \n","  inflating: ./models/research/slim/preprocessing/vgg_preprocessing.py  \n","   creating: ./models/research/slim/deployment/\n","  inflating: ./models/research/slim/deployment/model_deploy.py  \n","   creating: ./models/research/slim/deployment/__pycache__/\n","  inflating: ./models/research/slim/deployment/__pycache__/model_deploy.cpython-35.pyc  \n","  inflating: ./models/research/slim/deployment/__pycache__/model_deploy.cpython-36.pyc  \n","  inflating: ./models/research/slim/deployment/__pycache__/__init__.cpython-36.pyc  \n","  inflating: ./models/research/slim/deployment/__pycache__/__init__.cpython-35.pyc  \n","  inflating: ./models/research/slim/deployment/model_deploy_test.py  \n"," extracting: ./models/research/slim/deployment/__init__.py  \n","  inflating: ./models/research/slim/BUILD  \n","  inflating: ./models/research/slim/export_inference_graph.py  \n","  inflating: ./models/research/slim/export_inference_graph_test.py  \n","  inflating: ./models/research/slim/eval_image_classifier.py  \n","   creating: ./models/research/slim/nets/\n","  inflating: ./models/research/slim/nets/inception_v2.py  \n","  inflating: ./models/research/slim/nets/overfeat.py  \n","  inflating: ./models/research/slim/nets/inception_resnet_v2.py  \n","  inflating: ./models/research/slim/nets/mobilenet_v1.py  \n","  inflating: ./models/research/slim/nets/inception_v1_test.py  \n","  inflating: ./models/research/slim/nets/cyclegan_test.py  \n","  inflating: ./models/research/slim/nets/post_training_quantization.py  \n","  inflating: ./models/research/slim/nets/cifarnet.py  \n","  inflating: ./models/research/slim/nets/i3d_utils.py  \n","  inflating: ./models/research/slim/nets/nets_factory_test.py  \n","  inflating: ./models/research/slim/nets/i3d.py  \n","  inflating: ./models/research/slim/nets/s3dg_test.py  \n","  inflating: ./models/research/slim/nets/resnet_v1_test.py  \n","  inflating: ./models/research/slim/nets/alexnet.py  \n","  inflating: ./models/research/slim/nets/dcgan.py  \n","  inflating: ./models/research/slim/nets/vgg_test.py  \n","   creating: ./models/research/slim/nets/__pycache__/\n","  inflating: ./models/research/slim/nets/__pycache__/inception_resnet_v2.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/inception_v2.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/resnet_v1.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/inception_utils.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/inception_v3.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/resnet_utils.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/resnet_v1.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/inception_utils.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/mobilenet_v1.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/__init__.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/inception_v3.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/inception_resnet_v2.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/__init__.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/mobilenet_v1.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/inception_v2.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/__pycache__/resnet_utils.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet_v1_test.py  \n","  inflating: ./models/research/slim/nets/nets_factory.py  \n","  inflating: ./models/research/slim/nets/mobilenet_v1_eval.py  \n","  inflating: ./models/research/slim/nets/inception_v2_test.py  \n","  inflating: ./models/research/slim/nets/resnet_v2_test.py  \n","  inflating: ./models/research/slim/nets/overfeat_test.py  \n","  inflating: ./models/research/slim/nets/mobilenet_v1_train.py  \n","  inflating: ./models/research/slim/nets/pix2pix_test.py  \n","  inflating: ./models/research/slim/nets/alexnet_test.py  \n","  inflating: ./models/research/slim/nets/inception_v4_test.py  \n","  inflating: ./models/research/slim/nets/lenet.py  \n","  inflating: ./models/research/slim/nets/resnet_utils.py  \n","  inflating: ./models/research/slim/nets/inception.py  \n","  inflating: ./models/research/slim/nets/inception_v1.py  \n","  inflating: ./models/research/slim/nets/resnet_v1.py  \n","  inflating: ./models/research/slim/nets/i3d_test.py  \n","  inflating: ./models/research/slim/nets/dcgan_test.py  \n","  inflating: ./models/research/slim/nets/mobilenet_v1.png  \n","  inflating: ./models/research/slim/nets/cyclegan.py  \n","  inflating: ./models/research/slim/nets/resnet_v2.py  \n","   creating: ./models/research/slim/nets/nasnet/\n","  inflating: ./models/research/slim/nets/nasnet/pnasnet_test.py  \n","  inflating: ./models/research/slim/nets/nasnet/nasnet_utils_test.py  \n","   creating: ./models/research/slim/nets/nasnet/__pycache__/\n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/nasnet.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/nasnet.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/pnasnet.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/__init__.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/pnasnet.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/__init__.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/nasnet_utils.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/__pycache__/nasnet_utils.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/nasnet/nasnet_utils.py  \n","  inflating: ./models/research/slim/nets/nasnet/README.md  \n","  inflating: ./models/research/slim/nets/nasnet/pnasnet.py  \n","  inflating: ./models/research/slim/nets/nasnet/nasnet_test.py  \n"," extracting: ./models/research/slim/nets/nasnet/__init__.py  \n","  inflating: ./models/research/slim/nets/nasnet/nasnet.py  \n"," extracting: ./models/research/slim/nets/__init__.py  \n","  inflating: ./models/research/slim/nets/inception_utils.py  \n","  inflating: ./models/research/slim/nets/mobilenet_v1.md  \n","  inflating: ./models/research/slim/nets/inception_v3_test.py  \n","  inflating: ./models/research/slim/nets/inception_v3.py  \n","  inflating: ./models/research/slim/nets/inception_resnet_v2_test.py  \n","  inflating: ./models/research/slim/nets/s3dg.py  \n","  inflating: ./models/research/slim/nets/inception_v4.py  \n","  inflating: ./models/research/slim/nets/vgg.py  \n","   creating: ./models/research/slim/nets/mobilenet/\n","  inflating: ./models/research/slim/nets/mobilenet/mobilenet_v3_test.py  \n","  inflating: ./models/research/slim/nets/mobilenet/mobilenet_v2.py  \n","   creating: ./models/research/slim/nets/mobilenet/g3doc/\n","  inflating: ./models/research/slim/nets/mobilenet/g3doc/edgetpu_latency.png  \n","  inflating: ./models/research/slim/nets/mobilenet/g3doc/latency_pixel1.png  \n","  inflating: ./models/research/slim/nets/mobilenet/g3doc/madds_top1_accuracy.png  \n","  inflating: ./models/research/slim/nets/mobilenet/mobilenet_v3.py  \n","  inflating: ./models/research/slim/nets/mobilenet/mobilenet_v2_test.py  \n","  inflating: ./models/research/slim/nets/mobilenet/conv_blocks.py  \n","   creating: ./models/research/slim/nets/mobilenet/__pycache__/\n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/mobilenet.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/mobilenet_v2.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/conv_blocks.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/__init__.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/conv_blocks.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/__init__.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/mobilenet.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/mobilenet_v3.cpython-36.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/mobilenet_v3.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/__pycache__/mobilenet_v2.cpython-35.pyc  \n","  inflating: ./models/research/slim/nets/mobilenet/README.md  \n","  inflating: ./models/research/slim/nets/mobilenet/mobilenet_example.ipynb  \n"," extracting: ./models/research/slim/nets/mobilenet/__init__.py  \n","  inflating: ./models/research/slim/nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png  \n","  inflating: ./models/research/slim/nets/mobilenet/mobilenet.py  \n","  inflating: ./models/research/slim/nets/pix2pix.py  \n","  inflating: ./models/research/slim/download_and_convert_data.py  \n","  inflating: ./models/research/slim/README.md  \n","   creating: ./models/research/slim/datasets/\n","  inflating: ./models/research/slim/datasets/preprocess_imagenet_validation_data.py  \n","  inflating: ./models/research/slim/datasets/flowers.py  \n","  inflating: ./models/research/slim/datasets/download_and_convert_imagenet.sh  \n","  inflating: ./models/research/slim/datasets/download_and_convert_visualwakewords_lib.py  \n","  inflating: ./models/research/slim/datasets/download_and_convert_flowers.py  \n","  inflating: ./models/research/slim/datasets/imagenet_metadata.txt  \n","  inflating: ./models/research/slim/datasets/download_and_convert_mnist.py  \n","  inflating: ./models/research/slim/datasets/process_bounding_boxes.py  \n","  inflating: ./models/research/slim/datasets/download_and_convert_visualwakewords.py  \n","  inflating: ./models/research/slim/datasets/build_imagenet_data.py  \n","  inflating: ./models/research/slim/datasets/visualwakewords.py  \n","  inflating: ./models/research/slim/datasets/mnist.py  \n","  inflating: ./models/research/slim/datasets/imagenet.py  \n","  inflating: ./models/research/slim/datasets/dataset_factory.py  \n","  inflating: ./models/research/slim/datasets/imagenet_2012_validation_synset_labels.txt  \n","  inflating: ./models/research/slim/datasets/download_and_convert_cifar10.py  \n"," extracting: ./models/research/slim/datasets/__init__.py  \n","  inflating: ./models/research/slim/datasets/download_imagenet.sh  \n","  inflating: ./models/research/slim/datasets/cifar10.py  \n","  inflating: ./models/research/slim/datasets/imagenet_lsvrc_2015_synsets.txt  \n","  inflating: ./models/research/slim/datasets/dataset_utils.py  \n","  inflating: ./models/research/slim/train_image_classifier.py  \n"," extracting: ./models/research/slim/__init__.py  \n","  inflating: ./models/research/slim/slim_walkthrough.ipynb  \n"," extracting: ./models/research/slim/WORKSPACE  \n","  inflating: ./models/research/slim/setup.py  \n","   creating: ./models/research/inception/\n","   creating: ./models/research/inception/inception/\n","  inflating: ./models/research/inception/inception/imagenet_data.py  \n","   creating: ./models/research/inception/inception/slim/\n","  inflating: ./models/research/inception/inception/slim/ops_test.py  \n","  inflating: ./models/research/inception/inception/slim/variables_test.py  \n","  inflating: ./models/research/inception/inception/slim/inception_test.py  \n","  inflating: ./models/research/inception/inception/slim/BUILD  \n","  inflating: ./models/research/inception/inception/slim/README.md  \n","  inflating: ./models/research/inception/inception/slim/collections_test.py  \n","  inflating: ./models/research/inception/inception/slim/slim.py  \n","  inflating: ./models/research/inception/inception/slim/inception_model.py  \n","  inflating: ./models/research/inception/inception/slim/scopes_test.py  \n","  inflating: ./models/research/inception/inception/slim/scopes.py  \n","  inflating: ./models/research/inception/inception/slim/variables.py  \n","  inflating: ./models/research/inception/inception/slim/losses_test.py  \n","  inflating: ./models/research/inception/inception/slim/ops.py  \n","  inflating: ./models/research/inception/inception/slim/losses.py  \n","  inflating: ./models/research/inception/inception/dataset.py  \n","  inflating: ./models/research/inception/inception/imagenet_eval.py  \n","  inflating: ./models/research/inception/inception/inception_distributed_train.py  \n","  inflating: ./models/research/inception/inception/BUILD  \n","  inflating: ./models/research/inception/inception/imagenet_distributed_train.py  \n","  inflating: ./models/research/inception/inception/flowers_data.py  \n","  inflating: ./models/research/inception/inception/image_processing.py  \n","  inflating: ./models/research/inception/inception/inception_model.py  \n","  inflating: ./models/research/inception/inception/flowers_eval.py  \n","  inflating: ./models/research/inception/inception/inception_train.py  \n","  inflating: ./models/research/inception/inception/imagenet_train.py  \n","  inflating: ./models/research/inception/inception/flowers_train.py  \n","  inflating: ./models/research/inception/inception/inception_eval.py  \n","   creating: ./models/research/inception/inception/data/\n","  inflating: ./models/research/inception/inception/data/build_image_data.py  \n","  inflating: ./models/research/inception/inception/data/preprocess_imagenet_validation_data.py  \n","  inflating: ./models/research/inception/inception/data/imagenet_metadata.txt  \n","  inflating: ./models/research/inception/inception/data/process_bounding_boxes.py  \n","  inflating: ./models/research/inception/inception/data/build_imagenet_data.py  \n","  inflating: ./models/research/inception/inception/data/download_and_preprocess_imagenet.sh  \n","  inflating: ./models/research/inception/inception/data/imagenet_2012_validation_synset_labels.txt  \n","  inflating: ./models/research/inception/inception/data/download_and_preprocess_flowers_mac.sh  \n","  inflating: ./models/research/inception/inception/data/download_and_preprocess_flowers.sh  \n","  inflating: ./models/research/inception/inception/data/download_imagenet.sh  \n","  inflating: ./models/research/inception/inception/data/imagenet_lsvrc_2015_synsets.txt  \n","   creating: ./models/research/inception/g3doc/\n","  inflating: ./models/research/inception/g3doc/inception_v3_architecture.png  \n","  inflating: ./models/research/inception/README.md  \n"," extracting: ./models/research/inception/WORKSPACE  \n","  inflating: ./models/research/inception/.gitignore  \n","   creating: ./models/research/lfads/\n","  inflating: ./models/research/lfads/run_lfads.py  \n","   creating: ./models/research/lfads/synth_data/\n","  inflating: ./models/research/lfads/synth_data/generate_labeled_rnn_data.py  \n","  inflating: ./models/research/lfads/synth_data/generate_chaotic_rnn_data.py  \n","  inflating: ./models/research/lfads/synth_data/synthetic_data_utils.py  \n","  inflating: ./models/research/lfads/synth_data/generate_itb_data.py  \n","   creating: ./models/research/lfads/synth_data/trained_itb/\n","  inflating: ./models/research/lfads/synth_data/trained_itb/model-65000.index  \n","  inflating: ./models/research/lfads/synth_data/trained_itb/model-65000.data-00000-of-00001  \n","  inflating: ./models/research/lfads/synth_data/trained_itb/model-65000.meta  \n","  inflating: ./models/research/lfads/synth_data/run_generate_synth_data.sh  \n","  inflating: ./models/research/lfads/README.md  \n","  inflating: ./models/research/lfads/distributions.py  \n","  inflating: ./models/research/lfads/lfads.py  \n","  inflating: ./models/research/lfads/plot_lfads.py  \n","  inflating: ./models/research/lfads/utils.py  \n","   creating: ./models/research/dist/\n","  inflating: ./models/research/dist/object_detection-0.1-py3.6.egg  \n","  inflating: ./models/research/dist/object_detection-0.1-py3.5.egg  \n","   creating: ./models/research/keypointnet/\n","  inflating: ./models/research/keypointnet/main.py  \n","   creating: ./models/research/keypointnet/tools/\n","  inflating: ./models/research/keypointnet/tools/render.py  \n","  inflating: ./models/research/keypointnet/tools/gen_tfrecords.py  \n","  inflating: ./models/research/keypointnet/LICENSE  \n","  inflating: ./models/research/keypointnet/README.md  \n","  inflating: ./models/research/keypointnet/utils.py  \n","  inflating: ./models/research/keypointnet/CONTRIBUTING.md  \n","   creating: ./models/research/compression/\n","   creating: ./models/research/compression/image_encoder/\n","  inflating: ./models/research/compression/image_encoder/msssim.py  \n","  inflating: ./models/research/compression/image_encoder/README.md  \n","  inflating: ./models/research/compression/image_encoder/encoder.py  \n","  inflating: ./models/research/compression/image_encoder/decoder.py  \n","  inflating: ./models/research/compression/image_encoder/example.png  \n","  inflating: ./models/research/compression/README.md  \n","   creating: ./models/research/compression/entropy_coder/\n","   creating: ./models/research/compression/entropy_coder/lib/\n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_entropy_coding_test.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_lstm.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_std_test.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_std.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_binarizer.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_entropy_coding.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_masked_conv2d_test.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/block_base.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/block_util.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_operator.py  \n"," extracting: ./models/research/compression/entropy_coder/lib/__init__.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_lstm_test.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_masked_conv2d.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_masked_conv2d_lstm.py  \n","  inflating: ./models/research/compression/entropy_coder/lib/blocks_operator_test.py  \n","   creating: ./models/research/compression/entropy_coder/all_models/\n","  inflating: ./models/research/compression/entropy_coder/all_models/all_models_test.py  \n","  inflating: ./models/research/compression/entropy_coder/all_models/all_models.py  \n"," extracting: ./models/research/compression/entropy_coder/all_models/__init__.py  \n","  inflating: ./models/research/compression/entropy_coder/README.md  \n","   creating: ./models/research/compression/entropy_coder/configs/\n","   creating: ./models/research/compression/entropy_coder/configs/gru_prime3/\n","  inflating: ./models/research/compression/entropy_coder/configs/gru_prime3/model_config.json  \n","   creating: ./models/research/compression/entropy_coder/configs/synthetic/\n","  inflating: ./models/research/compression/entropy_coder/configs/synthetic/model_config.json  \n","  inflating: ./models/research/compression/entropy_coder/configs/synthetic/train_config.json  \n","  inflating: ./models/research/compression/entropy_coder/configs/synthetic/input_config.json  \n","   creating: ./models/research/compression/entropy_coder/dataset/\n","  inflating: ./models/research/compression/entropy_coder/dataset/synthetic_model.py  \n","  inflating: ./models/research/compression/entropy_coder/dataset/gen_synthetic_dataset.py  \n","  inflating: ./models/research/compression/entropy_coder/dataset/gen_synthetic_single.py  \n"," extracting: ./models/research/compression/entropy_coder/__init__.py  \n","   creating: ./models/research/compression/entropy_coder/progressive/\n","  inflating: ./models/research/compression/entropy_coder/progressive/progressive.py  \n"," extracting: ./models/research/compression/entropy_coder/progressive/__init__.py  \n","   creating: ./models/research/compression/entropy_coder/model/\n","  inflating: ./models/research/compression/entropy_coder/model/model_factory.py  \n","  inflating: ./models/research/compression/entropy_coder/model/entropy_coder_model.py  \n"," extracting: ./models/research/compression/entropy_coder/model/__init__.py  \n","   creating: ./models/research/compression/entropy_coder/core/\n","  inflating: ./models/research/compression/entropy_coder/core/code_loader.py  \n","  inflating: ./models/research/compression/entropy_coder/core/entropy_coder_train.py  \n","  inflating: ./models/research/compression/entropy_coder/core/entropy_coder_single.py  \n","  inflating: ./models/research/compression/entropy_coder/core/config_helper.py  \n","   creating: ./models/research/audioset/\n","   creating: ./models/research/audioset/vggish/\n","  inflating: ./models/research/audioset/vggish/vggish_inference_demo.py  \n","  inflating: ./models/research/audioset/vggish/vggish_slim.py  \n","  inflating: ./models/research/audioset/vggish/README.md  \n","  inflating: ./models/research/audioset/vggish/mel_features.py  \n","  inflating: ./models/research/audioset/vggish/vggish_postprocess.py  \n","  inflating: ./models/research/audioset/vggish/vggish_smoke_test.py  \n","  inflating: ./models/research/audioset/vggish/vggish_input.py  \n","  inflating: ./models/research/audioset/vggish/vggish_train_demo.py  \n","  inflating: ./models/research/audioset/vggish/vggish_params.py  \n","  inflating: ./models/research/audioset/README.md  \n","   creating: ./models/research/audioset/yamnet/\n","  inflating: ./models/research/audioset/yamnet/params.py  \n","  inflating: ./models/research/audioset/yamnet/yamnet_test.py  \n","  inflating: ./models/research/audioset/yamnet/yamnet_visualization.ipynb  \n","  inflating: ./models/research/audioset/yamnet/README.md  \n","  inflating: ./models/research/audioset/yamnet/inference.py  \n","  inflating: ./models/research/audioset/yamnet/yamnet_class_map.csv  \n","  inflating: ./models/research/audioset/yamnet/yamnet.py  \n","  inflating: ./models/research/audioset/yamnet/features.py  \n","   creating: ./models/research/marco/\n","  inflating: ./models/research/marco/Automated_Marco.py  \n","  inflating: ./models/research/marco/jpeg2json.py  \n","  inflating: ./models/research/marco/README.md  \n","  inflating: ./models/research/marco/request.json  \n","   creating: ./models/research/ptn/\n","  inflating: ./models/research/ptn/pretrain_rotator.py  \n","  inflating: ./models/research/ptn/metrics.py  \n","  inflating: ./models/research/ptn/model_voxel_generation.py  \n","  inflating: ./models/research/ptn/BUILD  \n","   creating: ./models/research/ptn/nets/\n","  inflating: ./models/research/ptn/nets/perspective_transform.py  \n","  inflating: ./models/research/ptn/nets/BUILD  \n","  inflating: ./models/research/ptn/nets/ptn_vox_decoder.py  \n","  inflating: ./models/research/ptn/nets/im2vox_factory.py  \n","  inflating: ./models/research/ptn/nets/deeprotator_factory.py  \n","  inflating: ./models/research/ptn/nets/ptn_encoder.py  \n","  inflating: ./models/research/ptn/nets/perspective_projector.py  \n","  inflating: ./models/research/ptn/nets/ptn_rotator.py  \n","  inflating: ./models/research/ptn/nets/ptn_im_decoder.py  \n","  inflating: ./models/research/ptn/README.md  \n","  inflating: ./models/research/ptn/model_rotator.py  \n","  inflating: ./models/research/ptn/model_ptn.py  \n","  inflating: ./models/research/ptn/train_ptn.py  \n","  inflating: ./models/research/ptn/eval_rotator.py  \n","  inflating: ./models/research/ptn/utils.py  \n","  inflating: ./models/research/ptn/eval_ptn.py  \n"," extracting: ./models/research/ptn/WORKSPACE  \n","  inflating: ./models/research/ptn/input_generator.py  \n","  inflating: ./models/research/ptn/.gitignore  \n","  inflating: ./models/research/ptn/losses.py  \n","   creating: ./models/research/struct2depth/\n","  inflating: ./models/research/struct2depth/nets.py  \n","  inflating: ./models/research/struct2depth/train.py  \n","  inflating: ./models/research/struct2depth/BUILD  \n","  inflating: ./models/research/struct2depth/util.py  \n","  inflating: ./models/research/struct2depth/alignment.py  \n","  inflating: ./models/research/struct2depth/model.py  \n","  inflating: ./models/research/struct2depth/README.md  \n","  inflating: ./models/research/struct2depth/optimize.py  \n","  inflating: ./models/research/struct2depth/gen_data_kitti.py  \n","  inflating: ./models/research/struct2depth/reader.py  \n","  inflating: ./models/research/struct2depth/inference.py  \n","  inflating: ./models/research/struct2depth/project.py  \n","  inflating: ./models/research/struct2depth/gen_data_city.py  \n","   creating: ./models/research/cvt_text/\n","  inflating: ./models/research/cvt_text/preprocessing.py  \n","   creating: ./models/research/cvt_text/task_specific/\n","  inflating: ./models/research/cvt_text/task_specific/task_definitions.py  \n","   creating: ./models/research/cvt_text/task_specific/word_level/\n","  inflating: ./models/research/cvt_text/task_specific/word_level/word_level_scorer.py  \n","  inflating: ./models/research/cvt_text/task_specific/word_level/tagging_utils.py  \n","  inflating: ./models/research/cvt_text/task_specific/word_level/depparse_scorer.py  \n","  inflating: ./models/research/cvt_text/task_specific/word_level/word_level_data.py  \n","  inflating: ./models/research/cvt_text/task_specific/word_level/depparse_module.py  \n","  inflating: ./models/research/cvt_text/task_specific/word_level/tagging_module.py  \n"," extracting: ./models/research/cvt_text/task_specific/word_level/__init__.py  \n","  inflating: ./models/research/cvt_text/task_specific/word_level/tagging_scorers.py  \n"," extracting: ./models/research/cvt_text/task_specific/__init__.py  \n","  inflating: ./models/research/cvt_text/fetch_data.sh  \n","  inflating: ./models/research/cvt_text/README.md  \n","   creating: ./models/research/cvt_text/corpus_processing/\n","  inflating: ./models/research/cvt_text/corpus_processing/scorer.py  \n","  inflating: ./models/research/cvt_text/corpus_processing/minibatching.py  \n"," extracting: ./models/research/cvt_text/corpus_processing/__init__.py  \n","  inflating: ./models/research/cvt_text/corpus_processing/example.py  \n","  inflating: ./models/research/cvt_text/corpus_processing/unlabeled_data.py  \n","   creating: ./models/research/cvt_text/base/\n","  inflating: ./models/research/cvt_text/base/configure.py  \n"," extracting: ./models/research/cvt_text/base/__init__.py  \n","  inflating: ./models/research/cvt_text/base/utils.py  \n","  inflating: ./models/research/cvt_text/base/embeddings.py  \n","   creating: ./models/research/cvt_text/training/\n"," extracting: ./models/research/cvt_text/training/__init__.py  \n","  inflating: ./models/research/cvt_text/training/trainer.py  \n","  inflating: ./models/research/cvt_text/training/training_progress.py  \n"," extracting: ./models/research/cvt_text/__init__.py  \n","   creating: ./models/research/cvt_text/model/\n","  inflating: ./models/research/cvt_text/model/shared_inputs.py  \n","  inflating: ./models/research/cvt_text/model/encoder.py  \n"," extracting: ./models/research/cvt_text/model/__init__.py  \n","  inflating: ./models/research/cvt_text/model/model_helpers.py  \n","  inflating: ./models/research/cvt_text/model/task_module.py  \n","  inflating: ./models/research/cvt_text/model/multitask_model.py  \n","  inflating: ./models/research/cvt_text/cvt.py  \n","   creating: ./models/research/namignizer/\n","  inflating: ./models/research/namignizer/names.py  \n","  inflating: ./models/research/namignizer/data_utils.py  \n","  inflating: ./models/research/namignizer/model.py  \n","  inflating: ./models/research/namignizer/README.md  \n","  inflating: ./models/research/namignizer/.gitignore  \n","   creating: ./models/research/delf/\n","   creating: ./models/research/delf/delf/\n","   creating: ./models/research/delf/delf/protos/\n","  inflating: ./models/research/delf/delf/protos/datum.proto  \n","  inflating: ./models/research/delf/delf/protos/feature.proto  \n","  inflating: ./models/research/delf/delf/protos/delf_config.proto  \n","  inflating: ./models/research/delf/delf/protos/box.proto  \n","  inflating: ./models/research/delf/delf/protos/aggregation_config.proto  \n"," extracting: ./models/research/delf/delf/protos/__init__.py  \n","  inflating: ./models/research/delf/delf/__init__.py  \n","   creating: ./models/research/delf/delf/python/\n","  inflating: ./models/research/delf/delf/python/feature_io_test.py  \n","  inflating: ./models/research/delf/delf/python/feature_io.py  \n","  inflating: ./models/research/delf/delf/python/box_io.py  \n","  inflating: ./models/research/delf/delf/python/delf_v1.py  \n","  inflating: ./models/research/delf/delf/python/feature_aggregation_extractor.py  \n","  inflating: ./models/research/delf/delf/python/datum_io_test.py  \n","   creating: ./models/research/delf/delf/python/detect_to_retrieve/\n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/cluster_delf_features.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/extract_index_boxes_and_features.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/perform_retrieval.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/extract_aggregation.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/dataset.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/boxes_and_features_extraction.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/aggregation_extraction.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/DETECT_TO_RETRIEVE_INSTRUCTIONS.md  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/dataset_test.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/query_aggregation_config.pbtxt  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/__init__.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/extract_query_features.py  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/index_aggregation_config.pbtxt  \n","  inflating: ./models/research/delf/delf/python/detect_to_retrieve/delf_gld_config.pbtxt  \n","   creating: ./models/research/delf/delf/python/examples/\n","  inflating: ./models/research/delf/delf/python/examples/extractor.py  \n","  inflating: ./models/research/delf/delf/python/examples/extract_boxes.py  \n","  inflating: ./models/research/delf/delf/python/examples/match_images.py  \n","  inflating: ./models/research/delf/delf/python/examples/extractor_test.py  \n","  inflating: ./models/research/delf/delf/python/examples/detection_example_1.jpg  \n","  inflating: ./models/research/delf/delf/python/examples/detector.py  \n","  inflating: ./models/research/delf/delf/python/examples/detection_example_2.jpg  \n"," extracting: ./models/research/delf/delf/python/examples/__init__.py  \n","  inflating: ./models/research/delf/delf/python/examples/delf_config_example.pbtxt  \n","  inflating: ./models/research/delf/delf/python/examples/matched_images_example.jpg  \n","  inflating: ./models/research/delf/delf/python/examples/extract_features.py  \n"," extracting: ./models/research/delf/delf/python/__init__.py  \n","  inflating: ./models/research/delf/delf/python/feature_aggregation_similarity_test.py  \n","  inflating: ./models/research/delf/delf/python/feature_extractor_test.py  \n","   creating: ./models/research/delf/delf/python/google_landmarks_dataset/\n","  inflating: ./models/research/delf/delf/python/google_landmarks_dataset/dataset_file_io.py  \n","  inflating: ./models/research/delf/delf/python/google_landmarks_dataset/metrics.py  \n","  inflating: ./models/research/delf/delf/python/google_landmarks_dataset/compute_retrieval_metrics.py  \n","  inflating: ./models/research/delf/delf/python/google_landmarks_dataset/compute_recognition_metrics.py  \n","  inflating: ./models/research/delf/delf/python/google_landmarks_dataset/dataset_file_io_test.py  \n","  inflating: ./models/research/delf/delf/python/google_landmarks_dataset/metrics_test.py  \n","  inflating: ./models/research/delf/delf/python/datum_io.py  \n","  inflating: ./models/research/delf/delf/python/feature_aggregation_similarity.py  \n","  inflating: ./models/research/delf/delf/python/box_io_test.py  \n","  inflating: ./models/research/delf/delf/python/feature_aggregation_extractor_test.py  \n","  inflating: ./models/research/delf/delf/python/feature_extractor.py  \n","  inflating: ./models/research/delf/DETECTION.md  \n","  inflating: ./models/research/delf/README.md  \n","  inflating: ./models/research/delf/INSTALL_INSTRUCTIONS.md  \n","  inflating: ./models/research/delf/.gitignore  \n","  inflating: ./models/research/delf/EXTRACTION_MATCHING.md  \n","  inflating: ./models/research/delf/setup.py  \n","   creating: ./models/research/transformer/\n","  inflating: ./models/research/transformer/spatial_transformer.py  \n","  inflating: ./models/research/transformer/README.md  \n","  inflating: ./models/research/transformer/example.py  \n","  inflating: ./models/research/transformer/cluttered_mnist.py  \n","  inflating: ./models/research/transformer/tf_utils.py  \n","   creating: ./models/research/transformer/data/\n","  inflating: ./models/research/transformer/data/README.md  \n","   creating: ./models/research/global_objectives/\n","  inflating: ./models/research/global_objectives/util_test.py  \n","  inflating: ./models/research/global_objectives/test_all.py  \n","  inflating: ./models/research/global_objectives/loss_layers_test.py  \n","  inflating: ./models/research/global_objectives/util.py  \n","  inflating: ./models/research/global_objectives/loss_layers_example.py  \n","  inflating: ./models/research/global_objectives/README.md  \n","  inflating: ./models/research/global_objectives/loss_layers.py  \n","   creating: ./models/research/maskgan/\n","   creating: ./models/research/maskgan/models/\n","  inflating: ./models/research/maskgan/models/seq2seq.py  \n","  inflating: ./models/research/maskgan/models/feedforward.py  \n","  inflating: ./models/research/maskgan/models/critic_vd.py  \n","  inflating: ./models/research/maskgan/models/rollout.py  \n","  inflating: ./models/research/maskgan/models/bidirectional.py  \n","  inflating: ./models/research/maskgan/models/seq2seq_nas.py  \n","  inflating: ./models/research/maskgan/models/rnn_vd.py  \n","  inflating: ./models/research/maskgan/models/rnn_zaremba.py  \n","  inflating: ./models/research/maskgan/models/cnn.py  \n","  inflating: ./models/research/maskgan/models/rnn_nas.py  \n","  inflating: ./models/research/maskgan/models/bidirectional_zaremba.py  \n","  inflating: ./models/research/maskgan/models/bidirectional_vd.py  \n","  inflating: ./models/research/maskgan/models/seq2seq_vd.py  \n","  inflating: ./models/research/maskgan/models/rnn.py  \n","  inflating: ./models/research/maskgan/models/seq2seq_zaremba.py  \n","  inflating: ./models/research/maskgan/models/evaluation_utils.py  \n"," extracting: ./models/research/maskgan/models/__init__.py  \n","  inflating: ./models/research/maskgan/models/attention_utils.py  \n","  inflating: ./models/research/maskgan/pretrain_mask_gan.py  \n","  inflating: ./models/research/maskgan/generate_samples.py  \n","   creating: ./models/research/maskgan/losses/\n"," extracting: ./models/research/maskgan/losses/__init__.py  \n","  inflating: ./models/research/maskgan/losses/losses.py  \n","  inflating: ./models/research/maskgan/README.md  \n","  inflating: ./models/research/maskgan/sample_shuffler.py  \n","   creating: ./models/research/maskgan/nas_utils/\n","  inflating: ./models/research/maskgan/nas_utils/configs.py  \n"," extracting: ./models/research/maskgan/nas_utils/__init__.py  \n","  inflating: ./models/research/maskgan/nas_utils/variational_dropout.py  \n","  inflating: ./models/research/maskgan/nas_utils/custom_cell.py  \n","  inflating: ./models/research/maskgan/train_mask_gan.py  \n","   creating: ./models/research/maskgan/regularization/\n","  inflating: ./models/research/maskgan/regularization/zoneout.py  \n"," extracting: ./models/research/maskgan/regularization/__init__.py  \n","  inflating: ./models/research/maskgan/regularization/variational_dropout.py  \n","   creating: ./models/research/maskgan/model_utils/\n","  inflating: ./models/research/maskgan/model_utils/model_losses.py  \n","  inflating: ./models/research/maskgan/model_utils/model_optimization.py  \n"," extracting: ./models/research/maskgan/model_utils/__init__.py  \n","  inflating: ./models/research/maskgan/model_utils/model_utils.py  \n","  inflating: ./models/research/maskgan/model_utils/model_construction.py  \n","  inflating: ./models/research/maskgan/model_utils/n_gram.py  \n","  inflating: ./models/research/maskgan/model_utils/helper.py  \n","  inflating: ./models/research/maskgan/model_utils/variable_mapping.py  \n","   creating: ./models/research/maskgan/data/\n","  inflating: ./models/research/maskgan/data/ptb_loader.py  \n","  inflating: ./models/research/maskgan/data/imdb_loader.py  \n"," extracting: ./models/research/maskgan/data/__init__.py  \n","  inflating: ./models/research/protoc.exe  \n","   creating: ./models/research/object_detection.egg-info/\n","  inflating: ./models/research/object_detection.egg-info/PKG-INFO  \n"," extracting: ./models/research/object_detection.egg-info/requires.txt  \n"," extracting: ./models/research/object_detection.egg-info/top_level.txt  \n"," extracting: ./models/research/object_detection.egg-info/dependency_links.txt  \n","  inflating: ./models/research/object_detection.egg-info/SOURCES.txt  \n","   creating: ./models/research/pcl_rl/\n","  inflating: ./models/research/pcl_rl/controller.py  \n","  inflating: ./models/research/pcl_rl/full_episode_objective.py  \n","  inflating: ./models/research/pcl_rl/baseline.py  \n","  inflating: ./models/research/pcl_rl/gym_wrapper.py  \n","  inflating: ./models/research/pcl_rl/model.py  \n","  inflating: ./models/research/pcl_rl/replay_buffer.py  \n","  inflating: ./models/research/pcl_rl/policy.py  \n","  inflating: ./models/research/pcl_rl/README.md  \n","  inflating: ./models/research/pcl_rl/optimizers.py  \n","  inflating: ./models/research/pcl_rl/env_spec.py  \n","  inflating: ./models/research/pcl_rl/objective.py  \n","  inflating: ./models/research/pcl_rl/trainer.py  \n","  inflating: ./models/research/pcl_rl/expert_paths.py  \n","  inflating: ./models/research/pcl_rl/trust_region.py  \n","   creating: ./models/research/deep_contextual_bandits/\n","   creating: ./models/research/deep_contextual_bandits/bandits/\n","   creating: ./models/research/deep_contextual_bandits/bandits/algorithms/\n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/linear_full_posterior_sampling.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/variational_neural_bandit_model.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/multitask_gp.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/neural_bandit_model.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/bb_alpha_divergence_model.py  \n","   creating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/\n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/variational_neural_bandit_model.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/posterior_bnn_sampling.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/neural_linear_sampling.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/linear_full_posterior_sampling.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/multitask_gp.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/bf_variational_neural_bandit_model.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/uniform_sampling.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/neural_bandit_model.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/bb_alpha_divergence_model.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/parameter_noise_sampling.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/fixed_policy_sampling.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/__pycache__/bootstrapped_bnn_sampling.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/neural_linear_sampling.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/parameter_noise_sampling.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/bootstrapped_bnn_sampling.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/bf_variational_neural_bandit_model.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/posterior_bnn_sampling.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/fixed_policy_sampling.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/algorithms/uniform_sampling.py  \n","   creating: ./models/research/deep_contextual_bandits/bandits/core/\n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/bandit_algorithm.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/contextual_dataset.py  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/contextual_bandit.py  \n","   creating: ./models/research/deep_contextual_bandits/bandits/core/__pycache__/\n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/__pycache__/bayesian_nn.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/__pycache__/contextual_dataset.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/__pycache__/bandit_algorithm.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/__pycache__/contextual_bandit.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/core/bayesian_nn.py  \n","   creating: ./models/research/deep_contextual_bandits/bandits/data/\n","  inflating: ./models/research/deep_contextual_bandits/bandits/data/data_sampler.py  \n","   creating: ./models/research/deep_contextual_bandits/bandits/data/__pycache__/\n","  inflating: ./models/research/deep_contextual_bandits/bandits/data/__pycache__/data_sampler.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/data/__pycache__/synthetic_data_sampler.cpython-36.pyc  \n","  inflating: ./models/research/deep_contextual_bandits/bandits/data/synthetic_data_sampler.py  \n","  inflating: ./models/research/deep_contextual_bandits/README.md  \n","  inflating: ./models/research/deep_contextual_bandits/example_main.py  \n","   creating: ./models/research/swivel/\n","  inflating: ./models/research/swivel/wordsim.py  \n","  inflating: ./models/research/swivel/distributed.sh  \n","  inflating: ./models/research/swivel/fastprep.mk  \n","  inflating: ./models/research/swivel/text2bin.py  \n","  inflating: ./models/research/swivel/vecs.py  \n","  inflating: ./models/research/swivel/README.md  \n","  inflating: ./models/research/swivel/eval.mk  \n","  inflating: ./models/research/swivel/glove_to_shards.py  \n","  inflating: ./models/research/swivel/analogy.cc  \n","  inflating: ./models/research/swivel/swivel.py  \n","  inflating: ./models/research/swivel/nearest.py  \n","  inflating: ./models/research/swivel/fastprep.cc  \n","  inflating: ./models/research/swivel/prep.py  \n","  inflating: ./models/research/swivel/.gitignore  \n","   creating: ./models/research/street/\n","   creating: ./models/research/street/g3doc/\n","  inflating: ./models/research/street/g3doc/vgslspecs.md  \n","  inflating: ./models/research/street/g3doc/avdessapins.png  \n","  inflating: ./models/research/street/README.md  \n","   creating: ./models/research/street/testdata/\n"," extracting: ./models/research/street/testdata/charset_size_10.txt  \n","  inflating: ./models/research/street/testdata/numbers-16-tiny  \n","  inflating: ./models/research/street/testdata/numbers.charset_size=12.txt  \n","  inflating: ./models/research/street/testdata/charset_size=134.txt  \n","  inflating: ./models/research/street/testdata/mnist-tiny  \n","  inflating: ./models/research/street/testdata/arial-32-tiny  \n","  inflating: ./models/research/street/testdata/arial.charset_size=105.txt  \n","   creating: ./models/research/street/cc/\n","  inflating: ./models/research/street/cc/rnn_ops.cc  \n","   creating: ./models/research/street/python/\n","  inflating: ./models/research/street/python/decoder_test.py  \n","  inflating: ./models/research/street/python/vgsl_train.py  \n","  inflating: ./models/research/street/python/shapes.py  \n","  inflating: ./models/research/street/python/vgsl_model.py  \n","  inflating: ./models/research/street/python/errorcounter.py  \n","  inflating: ./models/research/street/python/vgslspecs_test.py  \n","  inflating: ./models/research/street/python/vgslspecs.py  \n","  inflating: ./models/research/street/python/nn_ops.py  \n","  inflating: ./models/research/street/python/fsns_urls.py  \n","  inflating: ./models/research/street/python/vgsl_input.py  \n","  inflating: ./models/research/street/python/decoder.py  \n","  inflating: ./models/research/street/python/vgsl_model_test.py  \n","  inflating: ./models/research/street/python/fsns_urls.txt  \n","  inflating: ./models/research/street/python/errorcounter_test.py  \n","  inflating: ./models/research/street/python/shapes_test.py  \n","  inflating: ./models/research/street/python/vgsl_eval.py  \n","   creating: ./models/research/neural_programmer/\n","  inflating: ./models/research/neural_programmer/data_utils.py  \n","  inflating: ./models/research/neural_programmer/parameters.py  \n","  inflating: ./models/research/neural_programmer/wiki_data.py  \n","  inflating: ./models/research/neural_programmer/nn_utils.py  \n","  inflating: ./models/research/neural_programmer/model.py  \n","  inflating: ./models/research/neural_programmer/README.md  \n","  inflating: ./models/research/neural_programmer/neural_programmer.py  \n","   creating: ./models/research/deeplab/\n","  inflating: ./models/research/deeplab/common_test.py  \n","  inflating: ./models/research/deeplab/train.py  \n","  inflating: ./models/research/deeplab/model_test.py  \n","   creating: ./models/research/deeplab/deprecated/\n","  inflating: ./models/research/deeplab/deprecated/segmentation_dataset.py  \n"," extracting: ./models/research/deeplab/deprecated/__init__.py  \n","  inflating: ./models/research/deeplab/local_test.sh  \n","   creating: ./models/research/deeplab/g3doc/\n","  inflating: ./models/research/deeplab/g3doc/installation.md  \n","  inflating: ./models/research/deeplab/g3doc/pascal.md  \n","  inflating: ./models/research/deeplab/g3doc/ade20k.md  \n","   creating: ./models/research/deeplab/g3doc/img/\n","  inflating: ./models/research/deeplab/g3doc/img/vis2.png  \n","  inflating: ./models/research/deeplab/g3doc/img/image_info.txt  \n","  inflating: ./models/research/deeplab/g3doc/img/vis1.png  \n","  inflating: ./models/research/deeplab/g3doc/img/image1.jpg  \n","  inflating: ./models/research/deeplab/g3doc/img/image2.jpg  \n","  inflating: ./models/research/deeplab/g3doc/img/vis3.png  \n","  inflating: ./models/research/deeplab/g3doc/img/image3.jpg  \n","  inflating: ./models/research/deeplab/g3doc/quantize.md  \n","  inflating: ./models/research/deeplab/g3doc/cityscapes.md  \n","  inflating: ./models/research/deeplab/g3doc/faq.md  \n","  inflating: ./models/research/deeplab/g3doc/model_zoo.md  \n","  inflating: ./models/research/deeplab/g3doc/export_model.md  \n","  inflating: ./models/research/deeplab/input_preprocess.py  \n","  inflating: ./models/research/deeplab/local_test_mobilenetv2.sh  \n","  inflating: ./models/research/deeplab/eval.py  \n","   creating: ./models/research/deeplab/testing/\n","   creating: ./models/research/deeplab/testing/pascal_voc_seg/\n","  inflating: ./models/research/deeplab/testing/pascal_voc_seg/val-00000-of-00001.tfrecord  \n","  inflating: ./models/research/deeplab/testing/info.md  \n","  inflating: ./models/research/deeplab/vis.py  \n","  inflating: ./models/research/deeplab/model.py  \n","  inflating: ./models/research/deeplab/README.md  \n","   creating: ./models/research/deeplab/datasets/\n","  inflating: ./models/research/deeplab/datasets/download_and_convert_ade20k.sh  \n","  inflating: ./models/research/deeplab/datasets/build_cityscapes_data.py  \n","  inflating: ./models/research/deeplab/datasets/convert_cityscapes.sh  \n","  inflating: ./models/research/deeplab/datasets/remove_gt_colormap.py  \n","  inflating: ./models/research/deeplab/datasets/build_ade20k_data.py  \n"," extracting: ./models/research/deeplab/datasets/__init__.py  \n","  inflating: ./models/research/deeplab/datasets/data_generator.py  \n","  inflating: ./models/research/deeplab/datasets/data_generator_test.py  \n","  inflating: ./models/research/deeplab/datasets/download_and_convert_voc2012.sh  \n","  inflating: ./models/research/deeplab/datasets/build_data.py  \n","  inflating: ./models/research/deeplab/datasets/build_voc2012_data.py  \n","  inflating: ./models/research/deeplab/common.py  \n"," extracting: ./models/research/deeplab/__init__.py  \n","   creating: ./models/research/deeplab/evaluation/\n","  inflating: ./models/research/deeplab/evaluation/test_utils.py  \n","  inflating: ./models/research/deeplab/evaluation/base_metric.py  \n","   creating: ./models/research/deeplab/evaluation/g3doc/\n","   creating: ./models/research/deeplab/evaluation/g3doc/img/\n","  inflating: ./models/research/deeplab/evaluation/g3doc/img/equation_pq.png  \n","  inflating: ./models/research/deeplab/evaluation/g3doc/img/equation_pc.png  \n","  inflating: ./models/research/deeplab/evaluation/parsing_covering.py  \n","  inflating: ./models/research/deeplab/evaluation/test_utils_test.py  \n","  inflating: ./models/research/deeplab/evaluation/streaming_metrics_test.py  \n","  inflating: ./models/research/deeplab/evaluation/README.md  \n","  inflating: ./models/research/deeplab/evaluation/panoptic_quality.py  \n","  inflating: ./models/research/deeplab/evaluation/streaming_metrics.py  \n","  inflating: ./models/research/deeplab/evaluation/panoptic_quality_test.py  \n","   creating: ./models/research/deeplab/evaluation/testdata/\n","  inflating: ./models/research/deeplab/evaluation/testdata/cat_pred_class.png  \n"," extracting: ./models/research/deeplab/evaluation/testdata/bird_gt.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/team_gt_instance.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/team_pred_class.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/team_pred_instance.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/README.md  \n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_gt.json  \n","  inflating: ./models/research/deeplab/evaluation/testdata/cat_pred_instance.png  \n","   creating: ./models/research/deeplab/evaluation/testdata/coco_gt/\n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_gt/congress.png  \n"," extracting: ./models/research/deeplab/evaluation/testdata/coco_gt/team.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_gt/bird.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_gt/cat.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/bird_pred_instance.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/bird_pred_class.png  \n","   creating: ./models/research/deeplab/evaluation/testdata/coco_pred/\n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_pred/congress.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_pred/team.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_pred/bird.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_pred/cat.png  \n","  inflating: ./models/research/deeplab/evaluation/testdata/coco_pred.json  \n","  inflating: ./models/research/deeplab/evaluation/testdata/cat_gt.png  \n","  inflating: ./models/research/deeplab/evaluation/eval_coco_format_test.py  \n"," extracting: ./models/research/deeplab/evaluation/__init__.py  \n","  inflating: ./models/research/deeplab/evaluation/parsing_covering_test.py  \n","  inflating: ./models/research/deeplab/evaluation/eval_coco_format.py  \n","  inflating: ./models/research/deeplab/export_model.py  \n","  inflating: ./models/research/deeplab/deeplab_demo.ipynb  \n","   creating: ./models/research/deeplab/core/\n","  inflating: ./models/research/deeplab/core/dense_prediction_cell.py  \n","  inflating: ./models/research/deeplab/core/xception.py  \n","  inflating: ./models/research/deeplab/core/preprocess_utils_test.py  \n","  inflating: ./models/research/deeplab/core/conv2d_ws.py  \n","  inflating: ./models/research/deeplab/core/resnet_v1_beta_test.py  \n","  inflating: ./models/research/deeplab/core/conv2d_ws_test.py  \n","  inflating: ./models/research/deeplab/core/preprocess_utils.py  \n","  inflating: ./models/research/deeplab/core/nas_genotypes.py  \n","  inflating: ./models/research/deeplab/core/resnet_v1_beta.py  \n","  inflating: ./models/research/deeplab/core/dense_prediction_cell_test.py  \n","  inflating: ./models/research/deeplab/core/nas_network.py  \n","  inflating: ./models/research/deeplab/core/nas_network_test.py  \n","  inflating: ./models/research/deeplab/core/utils_test.py  \n","  inflating: ./models/research/deeplab/core/nas_cell.py  \n","  inflating: ./models/research/deeplab/core/dense_prediction_cell_branch5_top1_cityscapes.json  \n"," extracting: ./models/research/deeplab/core/__init__.py  \n","  inflating: ./models/research/deeplab/core/xception_test.py  \n","  inflating: ./models/research/deeplab/core/utils.py  \n","  inflating: ./models/research/deeplab/core/feature_extractor.py  \n","   creating: ./models/research/deeplab/utils/\n","  inflating: ./models/research/deeplab/utils/get_dataset_colormap_test.py  \n","  inflating: ./models/research/deeplab/utils/train_utils.py  \n"," extracting: ./models/research/deeplab/utils/__init__.py  \n","  inflating: ./models/research/deeplab/utils/get_dataset_colormap.py  \n","  inflating: ./models/research/deeplab/utils/save_annotation.py  \n","   creating: ./models/research/autoencoder/\n","  inflating: ./models/research/autoencoder/AdditiveGaussianNoiseAutoencoderRunner.py  \n","  inflating: ./models/research/autoencoder/VariationalAutoencoderRunner.py  \n","   creating: ./models/research/autoencoder/autoencoder_models/\n","  inflating: ./models/research/autoencoder/autoencoder_models/Autoencoder.py  \n","  inflating: ./models/research/autoencoder/autoencoder_models/DenoisingAutoencoder.py  \n"," extracting: ./models/research/autoencoder/autoencoder_models/__init__.py  \n","  inflating: ./models/research/autoencoder/autoencoder_models/VariationalAutoencoder.py  \n"," extracting: ./models/research/autoencoder/__init__.py  \n","  inflating: ./models/research/autoencoder/MaskingNoiseAutoencoderRunner.py  \n","  inflating: ./models/research/autoencoder/AutoencoderRunner.py  \n","   creating: ./models/research/adv_imagenet_models/\n","  inflating: ./models/research/adv_imagenet_models/inception_resnet_v2.py  \n","  inflating: ./models/research/adv_imagenet_models/README.md  \n","  inflating: ./models/research/adv_imagenet_models/imagenet.py  \n","  inflating: ./models/research/adv_imagenet_models/eval_on_adversarial.py  \n","  inflating: ./models/research/README.md  \n","   creating: ./models/research/textsum/\n","  inflating: ./models/research/textsum/seq2seq_attention_decode.py  \n","  inflating: ./models/research/textsum/seq2seq_attention.py  \n","  inflating: ./models/research/textsum/BUILD  \n","  inflating: ./models/research/textsum/README.md  \n","  inflating: ./models/research/textsum/data.py  \n","  inflating: ./models/research/textsum/batch_reader.py  \n","  inflating: ./models/research/textsum/seq2seq_lib.py  \n","  inflating: ./models/research/textsum/beam_search.py  \n","  inflating: ./models/research/textsum/data_convert_example.py  \n","  inflating: ./models/research/textsum/seq2seq_attention_model.py  \n","   creating: ./models/research/textsum/data/\n","  inflating: ./models/research/textsum/data/vocab  \n","  inflating: ./models/research/textsum/data/data  \n","   creating: ./models/research/feelvos/\n","  inflating: ./models/research/feelvos/train.py  \n","  inflating: ./models/research/feelvos/eval.sh  \n","  inflating: ./models/research/feelvos/LICENSE  \n","  inflating: ./models/research/feelvos/input_preprocess.py  \n","   creating: ./models/research/feelvos/correlation_cost/\n","  inflating: ./models/research/feelvos/correlation_cost/build.sh  \n","  inflating: ./models/research/feelvos/correlation_cost/fix_code.sh  \n","  inflating: ./models/research/feelvos/correlation_cost/get_code.sh  \n","  inflating: ./models/research/feelvos/correlation_cost/README.md  \n","  inflating: ./models/research/feelvos/correlation_cost/compile.sh  \n","  inflating: ./models/research/feelvos/correlation_cost/clone_dependencies.sh  \n","  inflating: ./models/research/feelvos/model.py  \n","  inflating: ./models/research/feelvos/README.md  \n","   creating: ./models/research/feelvos/datasets/\n","  inflating: ./models/research/feelvos/datasets/video_dataset.py  \n","  inflating: ./models/research/feelvos/datasets/download_and_convert_davis17.sh  \n","  inflating: ./models/research/feelvos/datasets/build_davis2017_data.py  \n","  inflating: ./models/research/feelvos/datasets/tfsequence_example_decoder.py  \n","  inflating: ./models/research/feelvos/datasets/__init__.py  \n","  inflating: ./models/research/feelvos/common.py  \n","  inflating: ./models/research/feelvos/__init__.py  \n","  inflating: ./models/research/feelvos/CONTRIBUTING.md  \n","   creating: ./models/research/feelvos/utils/\n","  inflating: ./models/research/feelvos/utils/mask_damaging.py  \n","  inflating: ./models/research/feelvos/utils/video_input_generator.py  \n","  inflating: ./models/research/feelvos/utils/train_utils.py  \n","  inflating: ./models/research/feelvos/utils/embedding_utils.py  \n","  inflating: ./models/research/feelvos/utils/eval_utils.py  \n","  inflating: ./models/research/feelvos/utils/embedding_utils_test.py  \n","  inflating: ./models/research/feelvos/utils/__init__.py  \n","  inflating: ./models/research/feelvos/train.sh  \n","  inflating: ./models/research/feelvos/vis_video.py  \n","   creating: ./models/research/rebar/\n","  inflating: ./models/research/rebar/rebar.py  \n","  inflating: ./models/research/rebar/download_data.py  \n","  inflating: ./models/research/rebar/README.md  \n","  inflating: ./models/research/rebar/rebar_train.py  \n","  inflating: ./models/research/rebar/datasets.py  \n","  inflating: ./models/research/rebar/logger.py  \n","  inflating: ./models/research/rebar/utils.py  \n","  inflating: ./models/research/rebar/config.py  \n","   creating: ./models/research/lstm_object_detection/\n","  inflating: ./models/research/lstm_object_detection/train.py  \n","   creating: ./models/research/lstm_object_detection/meta_architectures/\n","  inflating: ./models/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch.py  \n","  inflating: ./models/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch_test.py  \n"," extracting: ./models/research/lstm_object_detection/meta_architectures/__init__.py  \n","   creating: ./models/research/lstm_object_detection/models/\n","  inflating: ./models/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor.py  \n","  inflating: ./models/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor.py  \n","  inflating: ./models/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor_test.py  \n","  inflating: ./models/research/lstm_object_detection/models/mobilenet_defs_test.py  \n","  inflating: ./models/research/lstm_object_detection/models/mobilenet_defs.py  \n"," extracting: ./models/research/lstm_object_detection/models/__init__.py  \n","  inflating: ./models/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor_test.py  \n","  inflating: ./models/research/lstm_object_detection/evaluator.py  \n","   creating: ./models/research/lstm_object_detection/protos/\n","  inflating: ./models/research/lstm_object_detection/protos/quant_overrides.proto  \n","  inflating: ./models/research/lstm_object_detection/protos/input_reader_google.proto  \n"," extracting: ./models/research/lstm_object_detection/protos/__init__.py  \n","  inflating: ./models/research/lstm_object_detection/protos/pipeline.proto  \n","   creating: ./models/research/lstm_object_detection/builders/\n","  inflating: ./models/research/lstm_object_detection/builders/graph_rewriter_builder.py  \n","  inflating: ./models/research/lstm_object_detection/builders/graph_rewriter_builder_test.py  \n"," extracting: ./models/research/lstm_object_detection/builders/__init__.py  \n","   creating: ./models/research/lstm_object_detection/g3doc/\n","  inflating: ./models/research/lstm_object_detection/g3doc/lstm_ssd_intro.png  \n","  inflating: ./models/research/lstm_object_detection/g3doc/exporting_models.md  \n","  inflating: ./models/research/lstm_object_detection/g3doc/Interleaved_Intro.png  \n","  inflating: ./models/research/lstm_object_detection/eval.py  \n","  inflating: ./models/research/lstm_object_detection/export_tflite_lstd_graph.py  \n","  inflating: ./models/research/lstm_object_detection/README.md  \n","  inflating: ./models/research/lstm_object_detection/export_tflite_lstd_graph_lib.py  \n","   creating: ./models/research/lstm_object_detection/configs/\n","  inflating: ./models/research/lstm_object_detection/configs/lstm_ssd_interleaved_mobilenet_v2_imagenet.config  \n","  inflating: ./models/research/lstm_object_detection/configs/lstm_ssd_mobilenet_v1_imagenet.config  \n","   creating: ./models/research/lstm_object_detection/tflite/\n","   creating: ./models/research/lstm_object_detection/tflite/protos/\n","  inflating: ./models/research/lstm_object_detection/tflite/protos/labelmap.proto  \n","  inflating: ./models/research/lstm_object_detection/tflite/protos/box_encodings.proto  \n","  inflating: ./models/research/lstm_object_detection/tflite/protos/detections.proto  \n","  inflating: ./models/research/lstm_object_detection/tflite/protos/anchor_generation_options.proto  \n","  inflating: ./models/research/lstm_object_detection/tflite/protos/BUILD  \n","  inflating: ./models/research/lstm_object_detection/tflite/protos/mobile_ssd_client_options.proto  \n","  inflating: ./models/research/lstm_object_detection/tflite/protos/proto_config.asciipb  \n","  inflating: ./models/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.cc  \n","  inflating: ./models/research/lstm_object_detection/tflite/BUILD  \n","  inflating: ./models/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.h  \n","  inflating: ./models/research/lstm_object_detection/tflite/mobile_ssd_client.h  \n","  inflating: ./models/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.h  \n","  inflating: ./models/research/lstm_object_detection/tflite/mobile_ssd_client.cc  \n","  inflating: ./models/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.cc  \n","  inflating: ./models/research/lstm_object_detection/tflite/WORKSPACE  \n","   creating: ./models/research/lstm_object_detection/tflite/utils/\n","  inflating: ./models/research/lstm_object_detection/tflite/utils/conversion_utils.cc  \n","  inflating: ./models/research/lstm_object_detection/tflite/utils/file_utils.cc  \n","  inflating: ./models/research/lstm_object_detection/tflite/utils/BUILD  \n","  inflating: ./models/research/lstm_object_detection/tflite/utils/ssd_utils.cc  \n","  inflating: ./models/research/lstm_object_detection/tflite/utils/file_utils.h  \n","  inflating: ./models/research/lstm_object_detection/tflite/utils/conversion_utils_test.cc  \n","  inflating: ./models/research/lstm_object_detection/tflite/utils/ssd_utils.h  \n","  inflating: ./models/research/lstm_object_detection/tflite/utils/conversion_utils.h  \n","   creating: ./models/research/lstm_object_detection/lstm/\n","  inflating: ./models/research/lstm_object_detection/lstm/rnn_decoder_test.py  \n","  inflating: ./models/research/lstm_object_detection/lstm/rnn_decoder.py  \n","  inflating: ./models/research/lstm_object_detection/lstm/utils_test.py  \n"," extracting: ./models/research/lstm_object_detection/lstm/__init__.py  \n","  inflating: ./models/research/lstm_object_detection/lstm/utils.py  \n","  inflating: ./models/research/lstm_object_detection/lstm/lstm_cells.py  \n","  inflating: ./models/research/lstm_object_detection/lstm/lstm_cells_test.py  \n","   creating: ./models/research/lstm_object_detection/inputs/\n","  inflating: ./models/research/lstm_object_detection/inputs/seq_dataset_builder.py  \n","  inflating: ./models/research/lstm_object_detection/inputs/tf_sequence_example_decoder_test.py  \n"," extracting: ./models/research/lstm_object_detection/inputs/__init__.py  \n","  inflating: ./models/research/lstm_object_detection/inputs/tf_sequence_example_decoder.py  \n","  inflating: ./models/research/lstm_object_detection/inputs/seq_dataset_builder_test.py  \n","  inflating: ./models/research/lstm_object_detection/export_tflite_lstd_model.py  \n","   creating: ./models/research/lstm_object_detection/metrics/\n","  inflating: ./models/research/lstm_object_detection/metrics/coco_evaluation_all_frames.py  \n","  inflating: ./models/research/lstm_object_detection/metrics/coco_evaluation_all_frames_test.py  \n"," extracting: ./models/research/lstm_object_detection/metrics/__init__.py  \n","  inflating: ./models/research/lstm_object_detection/model_builder.py  \n"," extracting: ./models/research/lstm_object_detection/__init__.py  \n","  inflating: ./models/research/lstm_object_detection/trainer.py  \n","   creating: ./models/research/lstm_object_detection/utils/\n","  inflating: ./models/research/lstm_object_detection/utils/config_util.py  \n"," extracting: ./models/research/lstm_object_detection/utils/__init__.py  \n","  inflating: ./models/research/lstm_object_detection/utils/config_util_test.py  \n","  inflating: ./models/research/lstm_object_detection/model_builder_test.py  \n","  inflating: ./models/research/lstm_object_detection/test_tflite_model.py  \n","   creating: ./models/research/im2txt/\n","   creating: ./models/research/im2txt/g3doc/\n","  inflating: ./models/research/im2txt/g3doc/show_and_tell_architecture.png  \n","  inflating: ./models/research/im2txt/g3doc/COCO_val2014_000000224477.jpg  \n","  inflating: ./models/research/im2txt/g3doc/example_captions.jpg  \n","   creating: ./models/research/im2txt/conda-env/\n","  inflating: ./models/research/im2txt/conda-env/ubuntu-18-04-environment.yaml  \n","  inflating: ./models/research/im2txt/README.md  \n","   creating: ./models/research/im2txt/im2txt/\n","  inflating: ./models/research/im2txt/im2txt/train.py  \n","  inflating: ./models/research/im2txt/im2txt/show_and_tell_model_test.py  \n","  inflating: ./models/research/im2txt/im2txt/BUILD  \n","   creating: ./models/research/im2txt/im2txt/ops/\n","  inflating: ./models/research/im2txt/im2txt/ops/BUILD  \n","  inflating: ./models/research/im2txt/im2txt/ops/image_embedding_test.py  \n","  inflating: ./models/research/im2txt/im2txt/ops/image_embedding.py  \n","  inflating: ./models/research/im2txt/im2txt/ops/image_processing.py  \n","  inflating: ./models/research/im2txt/im2txt/ops/inputs.py  \n","  inflating: ./models/research/im2txt/im2txt/run_inference.py  \n","   creating: ./models/research/im2txt/im2txt/inference_utils/\n","  inflating: ./models/research/im2txt/im2txt/inference_utils/BUILD  \n","  inflating: ./models/research/im2txt/im2txt/inference_utils/vocabulary.py  \n","  inflating: ./models/research/im2txt/im2txt/inference_utils/caption_generator_test.py  \n","  inflating: ./models/research/im2txt/im2txt/inference_utils/inference_wrapper_base.py  \n","  inflating: ./models/research/im2txt/im2txt/inference_utils/caption_generator.py  \n","  inflating: ./models/research/im2txt/im2txt/inference_wrapper.py  \n","  inflating: ./models/research/im2txt/im2txt/evaluate.py  \n","  inflating: ./models/research/im2txt/im2txt/show_and_tell_model.py  \n","  inflating: ./models/research/im2txt/im2txt/configuration.py  \n","   creating: ./models/research/im2txt/im2txt/data/\n","  inflating: ./models/research/im2txt/im2txt/data/build_mscoco_data.py  \n","  inflating: ./models/research/im2txt/im2txt/data/download_and_preprocess_mscoco.sh  \n"," extracting: ./models/research/im2txt/WORKSPACE  \n","  inflating: ./models/research/im2txt/.gitignore  \n","   creating: ./models/research/astronet/\n","  inflating: ./models/research/astronet/README.md  \n","   creating: ./models/research/cognitive_mapping_and_planning/\n","   creating: ./models/research/cognitive_mapping_and_planning/scripts/\n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_preprocess_annoations_S3DIS.sh  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_distill.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_env_vis.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_preprocess_annoations_S3DIS.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_test_pretrained_models.sh  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_nav_agent_release.py  \n"," extracting: ./models/research/cognitive_mapping_and_planning/scripts/__init__.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_download_init_models.sh  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_preprocess_meshes_S3DIS.sh  \n","  inflating: ./models/research/cognitive_mapping_and_planning/scripts/script_plot_trajectory.py  \n","   creating: ./models/research/cognitive_mapping_and_planning/output/\n","  inflating: ./models/research/cognitive_mapping_and_planning/output/README.md  \n"," extracting: ./models/research/cognitive_mapping_and_planning/output/.gitignore  \n","  inflating: ./models/research/cognitive_mapping_and_planning/matplotlibrc  \n","   creating: ./models/research/cognitive_mapping_and_planning/src/\n","  inflating: ./models/research/cognitive_mapping_and_planning/src/depth_utils.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/src/graph_utils.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/src/file_utils.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/src/rotation_utils.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/src/map_utils.py  \n"," extracting: ./models/research/cognitive_mapping_and_planning/src/__init__.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/src/utils.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/requirements.txt  \n","   creating: ./models/research/cognitive_mapping_and_planning/patches/\n","  inflating: ./models/research/cognitive_mapping_and_planning/patches/GLES2_2_0.py.patch  \n","  inflating: ./models/research/cognitive_mapping_and_planning/patches/ctypesloader.py.patch  \n","  inflating: ./models/research/cognitive_mapping_and_planning/patches/apply_patches.sh  \n","   creating: ./models/research/cognitive_mapping_and_planning/tfcode/\n","  inflating: ./models/research/cognitive_mapping_and_planning/tfcode/cmp.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/tfcode/vision_baseline_lstm.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/tfcode/cmp_utils.py  \n"," extracting: ./models/research/cognitive_mapping_and_planning/tfcode/__init__.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/tfcode/cmp_summary.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/tfcode/tf_utils.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/tfcode/nav_utils.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/README.md  \n","   creating: ./models/research/cognitive_mapping_and_planning/datasets/\n","  inflating: ./models/research/cognitive_mapping_and_planning/datasets/nav_env_config.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/datasets/nav_env.py  \n"," extracting: ./models/research/cognitive_mapping_and_planning/datasets/__init__.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/datasets/factory.py  \n","   creating: ./models/research/cognitive_mapping_and_planning/render/\n","  inflating: ./models/research/cognitive_mapping_and_planning/render/depth_rgb_encoded.vp  \n","  inflating: ./models/research/cognitive_mapping_and_planning/render/depth_rgb_encoded.fp  \n","  inflating: ./models/research/cognitive_mapping_and_planning/render/swiftshader_renderer.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/render/rgb_flat_color.vp  \n"," extracting: ./models/research/cognitive_mapping_and_planning/render/__init__.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/render/rgb_flat_color.fp  \n"," extracting: ./models/research/cognitive_mapping_and_planning/__init__.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/.gitignore  \n","   creating: ./models/research/cognitive_mapping_and_planning/cfgs/\n","  inflating: ./models/research/cognitive_mapping_and_planning/cfgs/config_cmp.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/cfgs/config_vision_baseline.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/cfgs/config_distill.py  \n"," extracting: ./models/research/cognitive_mapping_and_planning/cfgs/__init__.py  \n","  inflating: ./models/research/cognitive_mapping_and_planning/cfgs/config_common.py  \n","   creating: ./models/research/cognitive_mapping_and_planning/data/\n","  inflating: ./models/research/cognitive_mapping_and_planning/data/README.md  \n","  inflating: ./models/research/cognitive_mapping_and_planning/data/.gitignore  \n","   creating: ./models/research/domain_adaptation/\n","  inflating: ./models/research/domain_adaptation/README.md  \n","   creating: ./models/research/domain_adaptation/datasets/\n","  inflating: ./models/research/domain_adaptation/datasets/mnist_m.py  \n","  inflating: ./models/research/domain_adaptation/datasets/BUILD  \n","  inflating: ./models/research/domain_adaptation/datasets/dataset_factory.py  \n","  inflating: ./models/research/domain_adaptation/datasets/download_and_convert_mnist_m.py  \n"," extracting: ./models/research/domain_adaptation/datasets/__init__.py  \n"," extracting: ./models/research/domain_adaptation/__init__.py  \n","   creating: ./models/research/domain_adaptation/domain_separation/\n","  inflating: ./models/research/domain_adaptation/domain_separation/models.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/grl_op_shapes.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/dsn.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/models_test.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/grl_op_kernels.cc  \n","  inflating: ./models/research/domain_adaptation/domain_separation/BUILD  \n","  inflating: ./models/research/domain_adaptation/domain_separation/grl_ops.cc  \n","  inflating: ./models/research/domain_adaptation/domain_separation/dsn_train.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/grl_op_grads.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/dsn_eval.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/_grl_ops.so  \n","  inflating: ./models/research/domain_adaptation/domain_separation/grl_ops.py  \n"," extracting: ./models/research/domain_adaptation/domain_separation/__init__.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/utils.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/dsn_test.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/losses_test.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/grl_ops_test.py  \n","  inflating: ./models/research/domain_adaptation/domain_separation/losses.py  \n","   creating: ./models/research/domain_adaptation/pixel_domain_adaptation/\n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_preprocess_test.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_train.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/BUILD  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_task_towers.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_utils.py  \n"," extracting: ./models/research/domain_adaptation/pixel_domain_adaptation/README.md  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_eval.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_losses.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/hparams.py  \n","   creating: ./models/research/domain_adaptation/pixel_domain_adaptation/baselines/\n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/baselines/BUILD  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/baselines/baseline_train.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/baselines/README.md  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/baselines/baseline_eval.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_model.py  \n","  inflating: ./models/research/domain_adaptation/pixel_domain_adaptation/pixelda_preprocess.py  \n"," extracting: ./models/research/domain_adaptation/WORKSPACE  \n","   creating: ./models/research/nst_blogpost/\n","  inflating: ./models/research/nst_blogpost/Green_Sea_Turtle_grazing_seagrass.jpg  \n","  inflating: ./models/research/nst_blogpost/wave_turtle.png  \n","  inflating: ./models/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb  \n","  inflating: ./models/research/nst_blogpost/The_Great_Wave_off_Kanagawa.jpg  \n","   creating: ./models/research/steve/\n","  inflating: ./models/research/steve/replay.py  \n","  inflating: ./models/research/steve/valuerl_learner.py  \n","  inflating: ./models/research/steve/envwrap.py  \n","  inflating: ./models/research/steve/master.py  \n","  inflating: ./models/research/steve/util.py  \n","  inflating: ./models/research/steve/README.md  \n","  inflating: ./models/research/steve/visualizer.py  \n","  inflating: ./models/research/steve/worldmodel.py  \n","  inflating: ./models/research/steve/toy_demo.py  \n","  inflating: ./models/research/steve/valuerl.py  \n","  inflating: ./models/research/steve/worldmodel_learner.py  \n","  inflating: ./models/research/steve/learner.py  \n","  inflating: ./models/research/steve/agent.py  \n","   creating: ./models/research/steve/config/\n","   creating: ./models/research/steve/config/algos/\n","  inflating: ./models/research/steve/config/algos/mve_mean.json  \n","  inflating: ./models/research/steve/config/algos/steve.json  \n"," extracting: ./models/research/steve/config/algos/ddpg.json  \n","  inflating: ./models/research/steve/config/algos/steve_cov.json  \n","  inflating: ./models/research/steve/config/algos/mve_tdk.json  \n","  inflating: ./models/research/steve/config/algos/mve_tdlambda.json  \n","   creating: ./models/research/steve/config/experiments/\n","   creating: ./models/research/steve/config/experiments/speedruns/\n","   creating: ./models/research/steve/config/experiments/speedruns/humanoid/\n","  inflating: ./models/research/steve/config/experiments/speedruns/humanoid/speedy_ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/humanoid/speedy_ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/humanoid/speedy_steve1.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/humanoid/speedy_mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/humanoid/speedy_mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/humanoid/speedy_steve0.json  \n","   creating: ./models/research/steve/config/experiments/speedruns/flagrun/\n","  inflating: ./models/research/steve/config/experiments/speedruns/flagrun/speedy_ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/flagrun/speedy_ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/flagrun/speedy_steve1.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/flagrun/speedy_mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/flagrun/speedy_mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/speedruns/flagrun/speedy_steve0.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/\n","   creating: ./models/research/steve/config/experiments/goodruns/halfcheetah/\n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/halfcheetah/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/hopper/\n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hopper/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/swimmer/\n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/swimmer/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/walker2d/\n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/walker2d/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/hardcore/\n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/hardcore/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/rshum/\n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/rshum/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/humanoid/\n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/humanoid/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/goodruns/flagrun/\n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/mve_tdk3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/steve2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/ddpg1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/ddpg2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/steve1.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/steve0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/ddpg0.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/steve3.json  \n","  inflating: ./models/research/steve/config/experiments/goodruns/flagrun/ddpg3.json  \n","   creating: ./models/research/steve/config/experiments/ablations/\n","   creating: ./models/research/steve/config/experiments/ablations/horizons/\n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_1h2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_5h2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_2h1.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_1h1.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_1h0.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_2h2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_5h0.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_2h0.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/horizons/steve_5h1.json  \n","   creating: ./models/research/steve/config/experiments/ablations/baselines/\n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_meank1.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_25tdlambda1.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/ensemble_mve_tdk1.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/ensemble_mve_tdk0.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/steve_cov2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/ensemble_mve_tdk2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_meank0.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_75tdlambda0.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_75tdlambda1.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_25tdlambda2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/steve_cov1.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_75tdlambda2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_meank2.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/mve_25tdlambda0.json  \n","  inflating: ./models/research/steve/config/experiments/ablations/baselines/steve_cov0.json  \n","   creating: ./models/research/steve/config/envs/\n","  inflating: ./models/research/steve/config/envs/hardcore.json  \n","  inflating: ./models/research/steve/config/envs/walker2d.json  \n","  inflating: ./models/research/steve/config/envs/rshum.json  \n","  inflating: ./models/research/steve/config/envs/humanoid.json  \n","  inflating: ./models/research/steve/config/envs/swimmer.json  \n","  inflating: ./models/research/steve/config/envs/hopper.json  \n","  inflating: ./models/research/steve/config/envs/halfcheetah.json  \n","  inflating: ./models/research/steve/config/envs/flagrun.json  \n","   creating: ./models/research/steve/config/core/\n","  inflating: ./models/research/steve/config/core/basic.json  \n","  inflating: ./models/research/steve/config/core/model.json  \n","  inflating: ./models/research/steve/config/core/bayesian.json  \n","   creating: ./models/research/steve/config/experimental_setups/\n","  inflating: ./models/research/steve/config/experimental_setups/speedrun.json  \n","  inflating: ./models/research/steve/nn.py  \n","  inflating: ./models/research/steve/config.py  \n","   creating: ./models/research/qa_kg/\n","   creating: ./models/research/qa_kg/model_n2nmn/\n","  inflating: ./models/research/qa_kg/model_n2nmn/model.py  \n","  inflating: ./models/research/qa_kg/model_n2nmn/modules.py  \n","  inflating: ./models/research/qa_kg/model_n2nmn/assembler.py  \n","  inflating: ./models/research/qa_kg/model_n2nmn/netgen_att.py  \n"," extracting: ./models/research/qa_kg/model_n2nmn/__init__.py  \n","   creating: ./models/research/qa_kg/exp_1_hop/\n","  inflating: ./models/research/qa_kg/exp_1_hop/train_gt_layout.py  \n","  inflating: ./models/research/qa_kg/exp_1_hop/test.py  \n","  inflating: ./models/research/qa_kg/exp_1_hop/config.py  \n","  inflating: ./models/research/qa_kg/README.md  \n","   creating: ./models/research/qa_kg/util/\n","  inflating: ./models/research/qa_kg/util/misc.py  \n","  inflating: ./models/research/qa_kg/util/data_reader.py  \n"," extracting: ./models/research/qa_kg/util/__init__.py  \n","  inflating: ./models/research/qa_kg/util/nn.py  \n","   creating: ./models/research/tensorrt/\n","  inflating: ./models/research/tensorrt/README.md  \n","   creating: ./models/research/build/\n","   creating: ./models/research/build/lib/\n","   creating: ./models/research/build/lib/object_detection/\n","  inflating: ./models/research/build/lib/object_detection/export_tflite_ssd_graph_lib.py  \n","  inflating: ./models/research/build/lib/object_detection/train.py  \n","   creating: ./models/research/build/lib/object_detection/anchor_generators/\n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py  \n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py  \n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py  \n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/grid_anchor_generator.py  \n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py  \n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py  \n"," extracting: ./models/research/build/lib/object_detection/anchor_generators/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py  \n","  inflating: ./models/research/build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py  \n","   creating: ./models/research/build/lib/object_detection/meta_architectures/\n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py  \n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/rfcn_meta_arch.py  \n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py  \n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/ssd_meta_arch.py  \n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py  \n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py  \n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py  \n","  inflating: ./models/research/build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py  \n"," extracting: ./models/research/build/lib/object_detection/meta_architectures/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/model_tpu_main.py  \n","   creating: ./models/research/build/lib/object_detection/models/\n","  inflating: ./models/research/build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py  \n","  inflating: ./models/research/build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_inception_v3_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_inception_v2_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/feature_map_generators_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py  \n","   creating: ./models/research/build/lib/object_detection/models/keras_models/\n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/inception_resnet_v2.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/test_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/mobilenet_v1.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/mobilenet_v2.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/resnet_v1_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/mobilenet_v2_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/mobilenet_v1_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/resnet_v1.py  \n"," extracting: ./models/research/build/lib/object_detection/models/keras_models/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/model_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/models/keras_models/inception_resnet_v2_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/feature_map_generators.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_feature_extractor_test.py  \n"," extracting: ./models/research/build/lib/object_detection/models/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_pnasnet_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py  \n","  inflating: ./models/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/Object_detection_webcam.py  \n","   creating: ./models/research/build/lib/object_detection/protos/\n","  inflating: ./models/research/build/lib/object_detection/protos/box_predictor_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/matcher_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/graph_rewriter_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/optimizer_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/model_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/image_resizer_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/train_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/ssd_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/pipeline_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/square_box_coder_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/argmax_matcher_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/hyperparams_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/post_processing_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/string_int_label_map_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/eval_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/input_reader_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/box_coder_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/calibration_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/losses_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/ssd_anchor_generator_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/target_assigner_pb2.py  \n"," extracting: ./models/research/build/lib/object_detection/protos/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/grid_anchor_generator_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/region_similarity_calculator_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/keypoint_box_coder_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/faster_rcnn_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/bipartite_matcher_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/preprocessor_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/anchor_generator_pb2.py  \n","  inflating: ./models/research/build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py  \n","   creating: ./models/research/build/lib/object_detection/predictors/\n","  inflating: ./models/research/build/lib/object_detection/predictors/rfcn_box_predictor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/convolutional_box_predictor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/mask_rcnn_box_predictor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/rfcn_keras_box_predictor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/convolutional_keras_box_predictor.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/convolutional_box_predictor.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/convolutional_keras_box_predictor_test.py  \n","   creating: ./models/research/build/lib/object_detection/predictors/heads/\n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/box_head_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/class_head.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/mask_head.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keypoint_head_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keras_mask_head.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keras_class_head.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/class_head_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/head.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keypoint_head.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keras_box_head_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/mask_head_test.py  \n"," extracting: ./models/research/build/lib/object_detection/predictors/heads/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keras_box_head.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keras_class_head_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/keras_mask_head_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/heads/box_head.py  \n"," extracting: ./models/research/build/lib/object_detection/predictors/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/mask_rcnn_box_predictor.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/rfcn_box_predictor.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/rfcn_keras_box_predictor.py  \n","  inflating: ./models/research/build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py  \n","   creating: ./models/research/build/lib/object_detection/builders/\n","  inflating: ./models/research/build/lib/object_detection/builders/anchor_generator_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/input_reader_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/region_similarity_calculator_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/anchor_generator_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/hyperparams_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/hyperparams_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/image_resizer_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/preprocessor_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/matcher_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/post_processing_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/input_reader_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/calibration_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/box_coder_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/graph_rewriter_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/box_coder_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/losses_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/dataset_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/optimizer_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/graph_rewriter_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/preprocessor_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/image_resizer_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/matcher_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/target_assigner_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/target_assigner_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/box_predictor_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/dataset_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/calibration_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/model_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/region_similarity_calculator_builder_test.py  \n"," extracting: ./models/research/build/lib/object_detection/builders/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/optimizer_builder.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/post_processing_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/losses_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/box_predictor_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/builders/model_builder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/export_tflite_ssd_graph.py  \n","  inflating: ./models/research/build/lib/object_detection/export_inference_graph.py  \n","   creating: ./models/research/build/lib/object_detection/tpu_exporters/\n","  inflating: ./models/research/build/lib/object_detection/tpu_exporters/faster_rcnn.py  \n","  inflating: ./models/research/build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py  \n","   creating: ./models/research/build/lib/object_detection/tpu_exporters/testdata/\n"," extracting: ./models/research/build/lib/object_detection/tpu_exporters/testdata/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/tpu_exporters/ssd.py  \n","  inflating: ./models/research/build/lib/object_detection/tpu_exporters/utils_test.py  \n"," extracting: ./models/research/build/lib/object_detection/tpu_exporters/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/tpu_exporters/utils.py  \n","  inflating: ./models/research/build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py  \n","  inflating: ./models/research/build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py  \n","   creating: ./models/research/build/lib/object_detection/matchers/\n","  inflating: ./models/research/build/lib/object_detection/matchers/bipartite_matcher_test.py  \n","  inflating: ./models/research/build/lib/object_detection/matchers/bipartite_matcher.py  \n","  inflating: ./models/research/build/lib/object_detection/matchers/argmax_matcher.py  \n","  inflating: ./models/research/build/lib/object_detection/matchers/argmax_matcher_test.py  \n"," extracting: ./models/research/build/lib/object_detection/matchers/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/generate_tfrecord.py  \n","  inflating: ./models/research/build/lib/object_detection/resizer.py  \n","  inflating: ./models/research/build/lib/object_detection/Object_detection_video.py  \n","   creating: ./models/research/build/lib/object_detection/data_decoders/\n","  inflating: ./models/research/build/lib/object_detection/data_decoders/tf_example_decoder_test.py  \n"," extracting: ./models/research/build/lib/object_detection/data_decoders/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/data_decoders/tf_example_decoder.py  \n","  inflating: ./models/research/build/lib/object_detection/eval_util_test.py  \n","  inflating: ./models/research/build/lib/object_detection/exporter.py  \n","  inflating: ./models/research/build/lib/object_detection/exporter_test.py  \n","  inflating: ./models/research/build/lib/object_detection/model_lib_v2.py  \n","   creating: ./models/research/build/lib/object_detection/dataset_tools/\n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/tf_record_creation_util.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_kitti_tf_record.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_pet_tf_record.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_coco_tf_record.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_pascal_tf_record.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_oid_tf_record.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py  \n"," extracting: ./models/research/build/lib/object_detection/dataset_tools/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py  \n","   creating: ./models/research/build/lib/object_detection/inference/\n","  inflating: ./models/research/build/lib/object_detection/inference/detection_inference.py  \n","  inflating: ./models/research/build/lib/object_detection/inference/infer_detections.py  \n","  inflating: ./models/research/build/lib/object_detection/inference/detection_inference_test.py  \n"," extracting: ./models/research/build/lib/object_detection/inference/__init__.py  \n","   creating: ./models/research/build/lib/object_detection/box_coders/\n","  inflating: ./models/research/build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/box_coders/faster_rcnn_box_coder.py  \n","  inflating: ./models/research/build/lib/object_detection/box_coders/square_box_coder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/box_coders/mean_stddev_box_coder.py  \n","  inflating: ./models/research/build/lib/object_detection/box_coders/keypoint_box_coder_test.py  \n","  inflating: ./models/research/build/lib/object_detection/box_coders/keypoint_box_coder.py  \n"," extracting: ./models/research/build/lib/object_detection/box_coders/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/box_coders/square_box_coder.py  \n","  inflating: ./models/research/build/lib/object_detection/model_lib.py  \n","   creating: ./models/research/build/lib/object_detection/metrics/\n","  inflating: ./models/research/build/lib/object_detection/metrics/oid_challenge_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/tf_example_parser.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/coco_tools.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/tf_example_parser_test.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/offline_eval_map_corloc_test.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/offline_eval_map_corloc.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/calibration_evaluation_test.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/calibration_metrics_test.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/coco_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/calibration_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/io_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/calibration_metrics.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/coco_tools_test.py  \n"," extracting: ./models/research/build/lib/object_detection/metrics/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/metrics/coco_evaluation_test.py  \n","  inflating: ./models/research/build/lib/object_detection/model_main.py  \n"," extracting: ./models/research/build/lib/object_detection/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/inputs_test.py  \n","  inflating: ./models/research/build/lib/object_detection/model_hparams.py  \n","  inflating: ./models/research/build/lib/object_detection/eval_util.py  \n","  inflating: ./models/research/build/lib/object_detection/inputs.py  \n","   creating: ./models/research/build/lib/object_detection/core/\n","  inflating: ./models/research/build/lib/object_detection/core/batcher.py  \n","  inflating: ./models/research/build/lib/object_detection/core/box_list.py  \n","  inflating: ./models/research/build/lib/object_detection/core/balanced_positive_negative_sampler_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/box_coder.py  \n","  inflating: ./models/research/build/lib/object_detection/core/box_list_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/matcher.py  \n","  inflating: ./models/research/build/lib/object_detection/core/region_similarity_calculator.py  \n","  inflating: ./models/research/build/lib/object_detection/core/box_list_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/core/anchor_generator.py  \n","  inflating: ./models/research/build/lib/object_detection/core/multiclass_nms_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/preprocessor_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/matcher_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/class_agnostic_nms_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/target_assigner_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/model.py  \n","  inflating: ./models/research/build/lib/object_detection/core/standard_fields.py  \n","  inflating: ./models/research/build/lib/object_detection/core/keypoint_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/freezable_batch_norm.py  \n","  inflating: ./models/research/build/lib/object_detection/core/prefetcher_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/post_processing.py  \n","  inflating: ./models/research/build/lib/object_detection/core/freezable_batch_norm_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/balanced_positive_negative_sampler.py  \n","  inflating: ./models/research/build/lib/object_detection/core/box_predictor.py  \n","  inflating: ./models/research/build/lib/object_detection/core/box_coder_test.py  \n"," extracting: ./models/research/build/lib/object_detection/core/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/core/batch_multiclass_nms_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/region_similarity_calculator_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/preprocessor.py  \n","  inflating: ./models/research/build/lib/object_detection/core/prefetcher.py  \n","  inflating: ./models/research/build/lib/object_detection/core/batcher_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/losses_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/preprocessor_cache.py  \n","  inflating: ./models/research/build/lib/object_detection/core/data_parser.py  \n","  inflating: ./models/research/build/lib/object_detection/core/target_assigner.py  \n","  inflating: ./models/research/build/lib/object_detection/core/keypoint_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/core/minibatch_sampler.py  \n","  inflating: ./models/research/build/lib/object_detection/core/data_decoder.py  \n","  inflating: ./models/research/build/lib/object_detection/core/minibatch_sampler_test.py  \n","  inflating: ./models/research/build/lib/object_detection/core/losses.py  \n","  inflating: ./models/research/build/lib/object_detection/core/box_list_test.py  \n","  inflating: ./models/research/build/lib/object_detection/xml_to_csv.py  \n","  inflating: ./models/research/build/lib/object_detection/Object_detection_image.py  \n","   creating: ./models/research/build/lib/object_detection/utils/\n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_list_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/test_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/patch_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/metrics.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_mask_list_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/context_manager_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_mask_list.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_mask_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/context_manager.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/test_utils_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_mask_list_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/variables_helper_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/learning_schedules.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/test_case.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/vrd_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/shape_utils_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/spatial_transform_ops_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/per_image_vrd_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_list_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/object_detection_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/json_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/label_map_util.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/visualization_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/config_util.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/spatial_transform_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/variables_helper.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/dataset_util_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/patch_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_list_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/model_util.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_mask_list_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/label_map_util_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_box_list.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/static_shape.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/per_image_evaluation.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/autoaugment_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/dataset_util.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/per_image_evaluation_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/category_util_test.py  \n"," extracting: ./models/research/build/lib/object_detection/utils/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/json_utils_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/model_util_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/category_util.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/visualization_utils_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/metrics_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/learning_schedules_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/shape_utils.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/object_detection_evaluation_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/vrd_evaluation_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/static_shape_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/config_util_test.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/ops.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/np_mask_ops.py  \n","  inflating: ./models/research/build/lib/object_detection/utils/per_image_vrd_evaluation_test.py  \n","   creating: ./models/research/build/lib/object_detection/legacy/\n","  inflating: ./models/research/build/lib/object_detection/legacy/train.py  \n","  inflating: ./models/research/build/lib/object_detection/legacy/trainer_test.py  \n","  inflating: ./models/research/build/lib/object_detection/legacy/evaluator.py  \n","  inflating: ./models/research/build/lib/object_detection/legacy/eval.py  \n"," extracting: ./models/research/build/lib/object_detection/legacy/__init__.py  \n","  inflating: ./models/research/build/lib/object_detection/legacy/trainer.py  \n","  inflating: ./models/research/build/lib/object_detection/model_lib_v2_test.py  \n","  inflating: ./models/research/build/lib/object_detection/model_lib_test.py  \n","  inflating: ./models/research/build/lib/object_detection/export_tflite_ssd_graph_lib_test.py  \n","   creating: ./models/research/build/bdist.linux-x86_64/\n","   creating: ./models/research/build/bdist.win-amd64/\n","   creating: ./models/research/video_prediction/\n","  inflating: ./models/research/video_prediction/lstm_ops.py  \n","  inflating: ./models/research/video_prediction/download_data.sh  \n","  inflating: ./models/research/video_prediction/prediction_train.py  \n","  inflating: ./models/research/video_prediction/prediction_input.py  \n","  inflating: ./models/research/video_prediction/README.md  \n","  inflating: ./models/research/video_prediction/push_datafiles.txt  \n","  inflating: ./models/research/video_prediction/prediction_model.py  \n","   creating: ./models/research/deep_speech/\n","  inflating: ./models/research/deep_speech/deep_speech_model.py  \n","  inflating: ./models/research/deep_speech/requirements.txt  \n","  inflating: ./models/research/deep_speech/README.md  \n","  inflating: ./models/research/deep_speech/decoder.py  \n","  inflating: ./models/research/deep_speech/run_deep_speech.sh  \n"," extracting: ./models/research/deep_speech/__init__.py  \n","   creating: ./models/research/deep_speech/data/\n","  inflating: ./models/research/deep_speech/data/dataset.py  \n","  inflating: ./models/research/deep_speech/data/download.py  \n","  inflating: ./models/research/deep_speech/data/featurizer.py  \n"," extracting: ./models/research/deep_speech/data/__init__.py  \n","  inflating: ./models/research/deep_speech/data/vocabulary.txt  \n","  inflating: ./models/research/deep_speech/deep_speech.py  \n","   creating: ./models/research/skip_thoughts/\n","  inflating: ./models/research/skip_thoughts/README.md  \n","   creating: ./models/research/skip_thoughts/skip_thoughts/\n","  inflating: ./models/research/skip_thoughts/skip_thoughts/train.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/track_perplexity.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/BUILD  \n","   creating: ./models/research/skip_thoughts/skip_thoughts/ops/\n","  inflating: ./models/research/skip_thoughts/skip_thoughts/ops/BUILD  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/ops/input_ops.py  \n"," extracting: ./models/research/skip_thoughts/skip_thoughts/ops/__init__.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/ops/gru_cell.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/skip_thoughts_encoder.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/skip_thoughts_model.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/skip_thoughts_model_test.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/encoder_manager.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/vocabulary_expansion.py  \n"," extracting: ./models/research/skip_thoughts/skip_thoughts/__init__.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/evaluate.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/configuration.py  \n","   creating: ./models/research/skip_thoughts/skip_thoughts/data/\n","  inflating: ./models/research/skip_thoughts/skip_thoughts/data/BUILD  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/data/special_words.py  \n","  inflating: ./models/research/skip_thoughts/skip_thoughts/data/preprocess_dataset.py  \n"," extracting: ./models/research/skip_thoughts/skip_thoughts/data/__init__.py  \n"," extracting: ./models/research/skip_thoughts/WORKSPACE  \n","  inflating: ./models/research/skip_thoughts/.gitignore  \n","   creating: ./models/research/sentiment_analysis/\n","  inflating: ./models/research/sentiment_analysis/README.md  \n","  inflating: ./models/research/sentiment_analysis/sentiment_model.py  \n"," extracting: ./models/research/sentiment_analysis/__init__.py  \n","  inflating: ./models/research/sentiment_analysis/sentiment_main.py  \n","   creating: ./models/research/sentiment_analysis/data/\n","  inflating: ./models/research/sentiment_analysis/data/dataset.py  \n","  inflating: ./models/research/sentiment_analysis/data/imdb.py  \n","  inflating: ./models/research/sentiment_analysis/data/util.py  \n"," extracting: ./models/research/sentiment_analysis/data/__init__.py  \n","   creating: ./models/research/brain_coder/\n","   creating: ./models/research/brain_coder/single_task/\n","  inflating: ./models/research/brain_coder/single_task/aggregate_tuning_results.py  \n","  inflating: ./models/research/brain_coder/single_task/defaults.py  \n","  inflating: ./models/research/brain_coder/single_task/tune.py  \n","  inflating: ./models/research/brain_coder/single_task/misc.py  \n","  inflating: ./models/research/brain_coder/single_task/ga_train_test.py  \n","  inflating: ./models/research/brain_coder/single_task/results_lib_test.py  \n","  inflating: ./models/research/brain_coder/single_task/BUILD  \n","  inflating: ./models/research/brain_coder/single_task/ga_lib.py  \n","  inflating: ./models/research/brain_coder/single_task/run_eval_tasks.py  \n","  inflating: ./models/research/brain_coder/single_task/pg_train.py  \n","  inflating: ./models/research/brain_coder/single_task/code_tasks_test.py  \n","  inflating: ./models/research/brain_coder/single_task/launch_training.sh  \n","  inflating: ./models/research/brain_coder/single_task/test_tasks.py  \n","  inflating: ./models/research/brain_coder/single_task/code_tasks.py  \n","  inflating: ./models/research/brain_coder/single_task/run.py  \n","  inflating: ./models/research/brain_coder/single_task/aggregate_experiment_results.py  \n","  inflating: ./models/research/brain_coder/single_task/launch_tuning.sh  \n","  inflating: ./models/research/brain_coder/single_task/README.md  \n","  inflating: ./models/research/brain_coder/single_task/data.py  \n","  inflating: ./models/research/brain_coder/single_task/test_tasks_test.py  \n","  inflating: ./models/research/brain_coder/single_task/pg_train_test.py  \n","  inflating: ./models/research/brain_coder/single_task/pg_agent_test.py  \n","  inflating: ./models/research/brain_coder/single_task/ga_train.py  \n","  inflating: ./models/research/brain_coder/single_task/pg_agent.py  \n","  inflating: ./models/research/brain_coder/single_task/results_lib.py  \n","  inflating: ./models/research/brain_coder/README.md  \n","   creating: ./models/research/brain_coder/common/\n","  inflating: ./models/research/brain_coder/common/schedules_test.py  \n","  inflating: ./models/research/brain_coder/common/rollout_test.py  \n","  inflating: ./models/research/brain_coder/common/schedules.py  \n","  inflating: ./models/research/brain_coder/common/BUILD  \n","  inflating: ./models/research/brain_coder/common/bf.py  \n","  inflating: ./models/research/brain_coder/common/rollout.py  \n","  inflating: ./models/research/brain_coder/common/bf_test.py  \n","  inflating: ./models/research/brain_coder/common/config_lib_test.py  \n","  inflating: ./models/research/brain_coder/common/utils_test.py  \n","  inflating: ./models/research/brain_coder/common/utils.py  \n","  inflating: ./models/research/brain_coder/common/config_lib.py  \n","  inflating: ./models/research/brain_coder/common/reward.py  \n","  inflating: ./models/research/brain_coder/common/reward_test.py  \n","  inflating: ./models/research/brain_coder/WORKSPACE  \n","   creating: ./models/research/fivo/\n","  inflating: ./models/research/fivo/.gitattributes  \n","  inflating: ./models/research/fivo/README.md  \n","   creating: ./models/research/fivo/experimental/\n","  inflating: ./models/research/fivo/experimental/train.py  \n","  inflating: ./models/research/fivo/experimental/models.py  \n","  inflating: ./models/research/fivo/experimental/summary_utils.py  \n","  inflating: ./models/research/fivo/experimental/README.md  \n","  inflating: ./models/research/fivo/experimental/data.py  \n","  inflating: ./models/research/fivo/experimental/bounds.py  \n","  inflating: ./models/research/fivo/experimental/run.sh  \n","   creating: ./models/research/fivo/bin/\n","  inflating: ./models/research/fivo/bin/run_tests.sh  \n","  inflating: ./models/research/fivo/bin/download_pianorolls.sh  \n","  inflating: ./models/research/fivo/bin/run_train.sh  \n","  inflating: ./models/research/fivo/bin/run_eval.sh  \n","  inflating: ./models/research/fivo/bin/run_sample.sh  \n","   creating: ./models/research/fivo/fivo/\n","  inflating: ./models/research/fivo/fivo/test_utils.py  \n","  inflating: ./models/research/fivo/fivo/bounds_test.py  \n","   creating: ./models/research/fivo/fivo/models/\n","  inflating: ./models/research/fivo/fivo/models/ghmm.py  \n","  inflating: ./models/research/fivo/fivo/models/base.py  \n","  inflating: ./models/research/fivo/fivo/models/srnn_test.py  \n","  inflating: ./models/research/fivo/fivo/models/srnn.py  \n","  inflating: ./models/research/fivo/fivo/models/vrnn.py  \n"," extracting: ./models/research/fivo/fivo/models/__init__.py  \n","  inflating: ./models/research/fivo/fivo/models/vrnn_test.py  \n","  inflating: ./models/research/fivo/fivo/models/ghmm_test.py  \n","  inflating: ./models/research/fivo/fivo/ghmm_runners_test.py  \n","  inflating: ./models/research/fivo/fivo/smc.py  \n","  inflating: ./models/research/fivo/fivo/runners_test.py  \n","  inflating: ./models/research/fivo/fivo/smc_test.py  \n","  inflating: ./models/research/fivo/fivo/nested_utils_test.py  \n","  inflating: ./models/research/fivo/fivo/bounds.py  \n","  inflating: ./models/research/fivo/fivo/nested_utils.py  \n"," extracting: ./models/research/fivo/fivo/__init__.py  \n","  inflating: ./models/research/fivo/fivo/runners.py  \n","   creating: ./models/research/fivo/fivo/test_data/\n","  inflating: ./models/research/fivo/fivo/test_data/tiny_pianoroll.pkl  \n","  inflating: ./models/research/fivo/fivo/test_data/tiny_speech_dataset.tfrecord  \n","   creating: ./models/research/fivo/fivo/data/\n","  inflating: ./models/research/fivo/fivo/data/datasets_test.py  \n","  inflating: ./models/research/fivo/fivo/data/calculate_pianoroll_mean.py  \n","  inflating: ./models/research/fivo/fivo/data/create_timit_dataset.py  \n","  inflating: ./models/research/fivo/fivo/data/datasets.py  \n"," extracting: ./models/research/fivo/fivo/data/__init__.py  \n","  inflating: ./models/research/fivo/fivo/ghmm_runners.py  \n","  inflating: ./models/research/fivo/run_fivo.py  \n","  inflating: ./models/research/fivo/.gitignore  \n","   creating: ./models/research/lm_1b/\n","  inflating: ./models/research/lm_1b/BUILD  \n","  inflating: ./models/research/lm_1b/data_utils.py  \n","  inflating: ./models/research/lm_1b/lm_1b_eval.py  \n","  inflating: ./models/research/lm_1b/README.md  \n","   creating: ./models/research/learned_optimizer/\n","  inflating: ./models/research/learned_optimizer/BUILD  \n","   creating: ./models/research/learned_optimizer/problems/\n","  inflating: ./models/research/learned_optimizer/problems/problem_spec.py  \n","  inflating: ./models/research/learned_optimizer/problems/problem_sets.py  \n","  inflating: ./models/research/learned_optimizer/problems/model_adapter.py  \n","  inflating: ./models/research/learned_optimizer/problems/BUILD  \n","  inflating: ./models/research/learned_optimizer/problems/problem_generator.py  \n","  inflating: ./models/research/learned_optimizer/problems/datasets.py  \n","   creating: ./models/research/learned_optimizer/optimizer/\n","  inflating: ./models/research/learned_optimizer/optimizer/trainable_optimizer.py  \n","  inflating: ./models/research/learned_optimizer/optimizer/trainable_adam.py  \n","  inflating: ./models/research/learned_optimizer/optimizer/BUILD  \n","  inflating: ./models/research/learned_optimizer/optimizer/hierarchical_rnn.py  \n","  inflating: ./models/research/learned_optimizer/optimizer/coordinatewise_rnn.py  \n","  inflating: ./models/research/learned_optimizer/optimizer/rnn_cells.py  \n","  inflating: ./models/research/learned_optimizer/optimizer/utils.py  \n","  inflating: ./models/research/learned_optimizer/optimizer/learning_rate_schedule.py  \n","  inflating: ./models/research/learned_optimizer/optimizer/global_learning_rate.py  \n","  inflating: ./models/research/learned_optimizer/README.md  \n"," extracting: ./models/research/learned_optimizer/.gitignore  \n","  inflating: ./models/research/learned_optimizer/metarun.py  \n","  inflating: ./models/research/learned_optimizer/metaopt.py  \n","   creating: ./models/research/learning_to_remember_rare_events/\n","  inflating: ./models/research/learning_to_remember_rare_events/train.py  \n","  inflating: ./models/research/learning_to_remember_rare_events/memory.py  \n","  inflating: ./models/research/learning_to_remember_rare_events/data_utils.py  \n","  inflating: ./models/research/learning_to_remember_rare_events/model.py  \n","  inflating: ./models/research/learning_to_remember_rare_events/README.md  \n","   creating: ./models/research/efficient-hrl/\n","   creating: ./models/research/efficient-hrl/scripts/\n","  inflating: ./models/research/efficient-hrl/scripts/local_eval.py  \n","  inflating: ./models/research/efficient-hrl/scripts/local_train.py  \n","  inflating: ./models/research/efficient-hrl/train.py  \n","   creating: ./models/research/efficient-hrl/agents/\n","  inflating: ./models/research/efficient-hrl/agents/ddpg_agent.py  \n","  inflating: ./models/research/efficient-hrl/agents/ddpg_networks.py  \n"," extracting: ./models/research/efficient-hrl/agents/__init__.py  \n","  inflating: ./models/research/efficient-hrl/agents/circular_buffer.py  \n","  inflating: ./models/research/efficient-hrl/run_train.py  \n","  inflating: ./models/research/efficient-hrl/cond_fn.py  \n","  inflating: ./models/research/efficient-hrl/eval.py  \n","  inflating: ./models/research/efficient-hrl/run_env.py  \n","  inflating: ./models/research/efficient-hrl/train_utils.py  \n","  inflating: ./models/research/efficient-hrl/README.md  \n","   creating: ./models/research/efficient-hrl/configs/\n","  inflating: ./models/research/efficient-hrl/configs/train_uvf.gin  \n","  inflating: ./models/research/efficient-hrl/configs/eval_uvf.gin  \n","  inflating: ./models/research/efficient-hrl/configs/base_uvf.gin  \n","  inflating: ./models/research/efficient-hrl/run_eval.py  \n","   creating: ./models/research/efficient-hrl/context/\n","  inflating: ./models/research/efficient-hrl/context/context_transition_functions.py  \n","   creating: ./models/research/efficient-hrl/context/configs/\n","  inflating: ./models/research/efficient-hrl/context/configs/hiro_xy.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_maze.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_push_multi.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_block_maze.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/point_maze.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_push_multi_img.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/hiro_orig.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_block.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_push_single.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/default.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_fall_multi.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_fall_multi_img.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_maze_img.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/ant_fall_single.gin  \n","  inflating: ./models/research/efficient-hrl/context/configs/hiro_repr.gin  \n"," extracting: ./models/research/efficient-hrl/context/__init__.py  \n","  inflating: ./models/research/efficient-hrl/context/gin_imports.py  \n","  inflating: ./models/research/efficient-hrl/context/gin_utils.py  \n","  inflating: ./models/research/efficient-hrl/context/samplers.py  \n","  inflating: ./models/research/efficient-hrl/context/rewards_functions.py  \n","  inflating: ./models/research/efficient-hrl/context/context.py  \n","  inflating: ./models/research/efficient-hrl/agent.py  \n","   creating: ./models/research/efficient-hrl/utils/\n","  inflating: ./models/research/efficient-hrl/utils/eval_utils.py  \n"," extracting: ./models/research/efficient-hrl/utils/__init__.py  \n","  inflating: ./models/research/efficient-hrl/utils/utils.py  \n","   creating: ./models/research/efficient-hrl/environments/\n","  inflating: ./models/research/efficient-hrl/environments/ant.py  \n","   creating: ./models/research/efficient-hrl/environments/assets/\n","  inflating: ./models/research/efficient-hrl/environments/assets/ant.xml  \n","  inflating: ./models/research/efficient-hrl/environments/ant_maze_env.py  \n","  inflating: ./models/research/efficient-hrl/environments/point_maze_env.py  \n","  inflating: ./models/research/efficient-hrl/environments/maze_env.py  \n","  inflating: ./models/research/efficient-hrl/environments/point.py  \n"," extracting: ./models/research/efficient-hrl/environments/__init__.py  \n","  inflating: ./models/research/efficient-hrl/environments/create_maze_env.py  \n","  inflating: ./models/research/efficient-hrl/environments/maze_env_utils.py  \n","   creating: ./models/research/neural_gpu/\n","  inflating: ./models/research/neural_gpu/neural_gpu.py  \n","  inflating: ./models/research/neural_gpu/neural_gpu_trainer.py  \n","  inflating: ./models/research/neural_gpu/program_utils.py  \n","  inflating: ./models/research/neural_gpu/data_utils.py  \n","  inflating: ./models/research/neural_gpu/README.md  \n","  inflating: ./models/research/neural_gpu/wmt_utils.py  \n","   creating: ./models/research/autoaugment/\n","  inflating: ./models/research/autoaugment/wrn.py  \n","  inflating: ./models/research/autoaugment/data_utils.py  \n","  inflating: ./models/research/autoaugment/helper_utils.py  \n","  inflating: ./models/research/autoaugment/train_cifar.py  \n","  inflating: ./models/research/autoaugment/custom_ops.py  \n","  inflating: ./models/research/autoaugment/README.md  \n","  inflating: ./models/research/autoaugment/augmentation_transforms.py  \n","  inflating: ./models/research/autoaugment/policies.py  \n","  inflating: ./models/research/autoaugment/shake_shake.py  \n","  inflating: ./models/research/autoaugment/shake_drop.py  \n","   creating: ./models/research/real_nvp/\n","  inflating: ./models/research/real_nvp/lsun_formatting.py  \n","  inflating: ./models/research/real_nvp/real_nvp_utils.py  \n","  inflating: ./models/research/real_nvp/imnet_formatting.py  \n","  inflating: ./models/research/real_nvp/README.md  \n","  inflating: ./models/research/real_nvp/real_nvp_multiscale_dataset.py  \n"," extracting: ./models/research/real_nvp/__init__.py  \n","  inflating: ./models/research/real_nvp/celeba_formatting.py  \n","   creating: ./models/research/cognitive_planning/\n","   creating: ./models/research/cognitive_planning/preprocessing/\n","  inflating: ./models/research/cognitive_planning/preprocessing/inception_preprocessing.py  \n","  inflating: ./models/research/cognitive_planning/preprocessing/preprocessing_factory.py  \n","  inflating: ./models/research/cognitive_planning/preprocessing/lenet_preprocessing.py  \n"," extracting: ./models/research/cognitive_planning/preprocessing/__init__.py  \n","  inflating: ./models/research/cognitive_planning/preprocessing/cifarnet_preprocessing.py  \n","  inflating: ./models/research/cognitive_planning/preprocessing/vgg_preprocessing.py  \n","  inflating: ./models/research/cognitive_planning/embedders.py  \n","  inflating: ./models/research/cognitive_planning/tasks.py  \n","  inflating: ./models/research/cognitive_planning/BUILD  \n","  inflating: ./models/research/cognitive_planning/label_map.txt  \n","  inflating: ./models/research/cognitive_planning/viz_active_vision_dataset_main.py  \n","  inflating: ./models/research/cognitive_planning/label_map_util.py  \n","  inflating: ./models/research/cognitive_planning/visualization_utils.py  \n","  inflating: ./models/research/cognitive_planning/standard_fields.py  \n","  inflating: ./models/research/cognitive_planning/README.md  \n","  inflating: ./models/research/cognitive_planning/string_int_label_map_pb2.py  \n","  inflating: ./models/research/cognitive_planning/train_supervised_active_vision.py  \n"," extracting: ./models/research/cognitive_planning/__init__.py  \n","  inflating: ./models/research/cognitive_planning/policies.py  \n","   creating: ./models/research/cognitive_planning/envs/\n","  inflating: ./models/research/cognitive_planning/envs/active_vision_dataset_env.py  \n","  inflating: ./models/research/cognitive_planning/envs/util.py  \n","  inflating: ./models/research/cognitive_planning/envs/task_env.py  \n","   creating: ./models/research/cognitive_planning/envs/configs/\n","  inflating: ./models/research/cognitive_planning/envs/configs/active_vision_config.gin  \n"," extracting: ./models/research/cognitive_planning/envs/__init__.py  \n","  inflating: ./models/research/cognitive_planning/command  \n","  inflating: ./models/research/cognitive_planning/train_supervised_active_vision.sh  \n","   creating: ./models/research/a3c_blogpost/\n","  inflating: ./models/research/a3c_blogpost/a3c_cartpole.py  \n","  inflating: ./models/research/a3c_blogpost/README.md  \n","   creating: ./models/research/adversarial_text/\n","  inflating: ./models/research/adversarial_text/layers.py  \n","  inflating: ./models/research/adversarial_text/graphs_test.py  \n","  inflating: ./models/research/adversarial_text/adversarial_losses.py  \n","  inflating: ./models/research/adversarial_text/gen_data.py  \n","  inflating: ./models/research/adversarial_text/train_utils.py  \n","  inflating: ./models/research/adversarial_text/README.md  \n","  inflating: ./models/research/adversarial_text/pretrain.py  \n","  inflating: ./models/research/adversarial_text/gen_vocab.py  \n"," extracting: ./models/research/adversarial_text/__init__.py  \n","  inflating: ./models/research/adversarial_text/evaluate.py  \n","  inflating: ./models/research/adversarial_text/inputs.py  \n","  inflating: ./models/research/adversarial_text/train_classifier.py  \n","  inflating: ./models/research/adversarial_text/graphs.py  \n","   creating: ./models/research/adversarial_text/data/\n","  inflating: ./models/research/adversarial_text/data/document_generators.py  \n","  inflating: ./models/research/adversarial_text/data/data_utils.py  \n"," extracting: ./models/research/adversarial_text/data/__init__.py  \n","  inflating: ./models/research/adversarial_text/data/data_utils_test.py  \n","   creating: ./models/research/morph_net/\n","   creating: ./models/research/morph_net/op_regularizers/\n","  inflating: ./models/research/morph_net/op_regularizers/conv_group_lasso_regularizer.py  \n","  inflating: ./models/research/morph_net/op_regularizers/conv_group_lasso_regularizer_test.py  \n","  inflating: ./models/research/morph_net/op_regularizers/gamma_mapper_test.py  \n","  inflating: ./models/research/morph_net/op_regularizers/gamma_mapper.py  \n"," extracting: ./models/research/morph_net/op_regularizers/__init__.py  \n","  inflating: ./models/research/morph_net/op_regularizers/gamma_l1_regularizer.py  \n","   creating: ./models/research/morph_net/g3doc/\n","  inflating: ./models/research/morph_net/g3doc/histogram.png  \n","  inflating: ./models/research/morph_net/g3doc/grouping.png  \n","  inflating: ./models/research/morph_net/g3doc/tensorboard.png  \n","   creating: ./models/research/morph_net/testing/\n","  inflating: ./models/research/morph_net/testing/op_regularizer_stub.py  \n"," extracting: ./models/research/morph_net/testing/__init__.py  \n","  inflating: ./models/research/morph_net/README.md  \n","   creating: ./models/research/morph_net/framework/\n","  inflating: ./models/research/morph_net/framework/concat_and_slice_regularizers.py  \n","  inflating: ./models/research/morph_net/framework/grouping_regularizers.py  \n","  inflating: ./models/research/morph_net/framework/concat_and_slice_regularizers_test.py  \n","  inflating: ./models/research/morph_net/framework/generic_regularizers.py  \n","  inflating: ./models/research/morph_net/framework/grouping_regularizers_test.py  \n","  inflating: ./models/research/morph_net/framework/README.md  \n","  inflating: ./models/research/morph_net/framework/op_regularizer_manager.py  \n"," extracting: ./models/research/morph_net/framework/__init__.py  \n","  inflating: ./models/research/morph_net/framework/op_regularizer_manager_test.py  \n"," extracting: ./models/research/morph_net/__init__.py  \n","   creating: ./models/research/morph_net/network_regularizers/\n","  inflating: ./models/research/morph_net/network_regularizers/bilinear_cost_utils_test.py  \n","  inflating: ./models/research/morph_net/network_regularizers/model_size_regularizer.py  \n","  inflating: ./models/research/morph_net/network_regularizers/flop_regularizer.py  \n","  inflating: ./models/research/morph_net/network_regularizers/flop_regularizer_test.py  \n","  inflating: ./models/research/morph_net/network_regularizers/bilinear_cost_utils.py  \n"," extracting: ./models/research/morph_net/network_regularizers/__init__.py  \n","   creating: ./models/research/syntaxnet/\n","   creating: ./models/research/syntaxnet/tools/\n","  inflating: ./models/research/syntaxnet/tools/bazel.rc  \n","   creating: ./models/research/syntaxnet/docker-devel/\n","  inflating: ./models/research/syntaxnet/docker-devel/README.txt  \n","  inflating: ./models/research/syntaxnet/docker-devel/build_devel.sh  \n","  inflating: ./models/research/syntaxnet/docker-devel/build_wheels.sh  \n","  inflating: ./models/research/syntaxnet/docker-devel/Dockerfile-test  \n","  inflating: ./models/research/syntaxnet/docker-devel/Dockerfile.min  \n","  inflating: ./models/research/syntaxnet/docker-devel/Dockerfile-test-base  \n","   creating: ./models/research/syntaxnet/g3doc/\n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops.md  \n","  inflating: ./models/research/syntaxnet/g3doc/syntaxnet-tutorial.md  \n","   creating: ./models/research/syntaxnet/g3doc/dragnn_ops/\n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/extract_link_features.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/write_annotations.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/attach_data_reader.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/emit_oracle_labels.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/bulk_advance_from_prediction.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/get_session.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/dragnn_embedding_initializer.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/emit_all_final.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/init_component_data.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/bulk_fixed_embeddings.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/emit_annotations.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/advance_from_oracle.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/bulk_advance_from_oracle.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/advance_from_prediction.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/set_tracing.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/tf.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/bulk_fixed_feature_ids.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/get_component_trace.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/bulk_fixed_features.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/batch_size.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/release_session.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn_ops/extract_fixed_features.md  \n","  inflating: ./models/research/syntaxnet/g3doc/unrolled-dragnn.png  \n","   creating: ./models/research/syntaxnet/g3doc/conll2017/\n","  inflating: ./models/research/syntaxnet/g3doc/conll2017/cooking.md  \n","  inflating: ./models/research/syntaxnet/g3doc/conll2017/README.md  \n","  inflating: ./models/research/syntaxnet/g3doc/conll2017/paper.pdf  \n","  inflating: ./models/research/syntaxnet/g3doc/full-trace-image.png  \n","  inflating: ./models/research/syntaxnet/g3doc/structured.md  \n","  inflating: ./models/research/syntaxnet/g3doc/universal.md  \n","   creating: ./models/research/syntaxnet/g3doc/dragnn/\n","  inflating: ./models/research/syntaxnet/g3doc/dragnn/creating_components.md  \n","  inflating: ./models/research/syntaxnet/g3doc/dragnn/cpp_api.md  \n","   creating: ./models/research/syntaxnet/g3doc/images/\n","  inflating: ./models/research/syntaxnet/g3doc/images/dragnn-train-eval.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/tutorial_1.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/sawman.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/hamburger.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/tutorial_2.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/dragnn_tf_overview.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/api_manager.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/dragnn-spec-overview.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/notebook-upload.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/cloudshell2.jpg  \n","  inflating: ./models/research/syntaxnet/g3doc/images/ff_nn_schematic.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/beam_search_training.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/dragnn-unrolling.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/ipython-link.png  \n","  inflating: ./models/research/syntaxnet/g3doc/images/looping-parser.gif  \n","  inflating: ./models/research/syntaxnet/g3doc/CLOUD.md  \n","  inflating: ./models/research/syntaxnet/g3doc/DRAGNN.md  \n"," extracting: ./models/research/syntaxnet/.dockerignore  \n","  inflating: ./models/research/syntaxnet/README.md  \n","  inflating: ./models/research/syntaxnet/Dockerfile  \n","   creating: ./models/research/syntaxnet/third_party/\n","   creating: ./models/research/syntaxnet/third_party/utf/\n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrrchr.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/LICENSE  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utfnlen.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrcpy.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/BUILD  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrncat.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/rune.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utfdef.h  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrcmp.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrecpy.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrncmp.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utf.h  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrchr.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrstr.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utfrune.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrncpy.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrlen.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utfrrune.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrdup.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runetypebody.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utflen.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utfutf.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/utfecpy.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/README  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runetype.c  \n","  inflating: ./models/research/syntaxnet/third_party/utf/runestrcat.c  \n","   creating: ./models/research/syntaxnet/examples/\n","   creating: ./models/research/syntaxnet/examples/dragnn/\n","  inflating: ./models/research/syntaxnet/examples/dragnn/trainer_tutorial.ipynb  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/BUILD  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/test_run_all_tutorials.sh  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/tutorial_2.py  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/tutorial_1.py  \n","   creating: ./models/research/syntaxnet/examples/dragnn/tutorial_data/\n","  inflating: ./models/research/syntaxnet/examples/dragnn/tutorial_data/sentence.prototext  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/interactive_text_analyzer.ipynb  \n","   creating: ./models/research/syntaxnet/examples/dragnn/data/\n","   creating: ./models/research/syntaxnet/examples/dragnn/data/es/\n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/es/es-universal-dev.conll  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/es/es-universal-train.conll  \n","   creating: ./models/research/syntaxnet/examples/dragnn/data/en/\n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/char-ngram-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/word-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/prefix-table  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/char-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/suffix-table  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/tag-to-category  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/parser_spec.textproto  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/tag-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/label-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/lcword-map  \n"," extracting: ./models/research/syntaxnet/examples/dragnn/data/en/category-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/checkpoint  \n","   creating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/\n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/checkpoint.meta  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/char-ngram-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/word-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/prefix-table  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/char-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/suffix-table  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/tag-to-category  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/checkpoint.index  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/spec.textproto  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/tag-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/label-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/lcword-map  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/checkpoint.data-00000-of-00001  \n","  inflating: ./models/research/syntaxnet/examples/dragnn/data/en/segmenter/category-map  \n","   creating: ./models/research/syntaxnet/tensorflow/\n","   creating: ./models/research/syntaxnet/util/\n","   creating: ./models/research/syntaxnet/util/utf8/\n","  inflating: ./models/research/syntaxnet/util/utf8/unicodetext_unittest.cc  \n","  inflating: ./models/research/syntaxnet/util/utf8/unicodetext_main.cc  \n","  inflating: ./models/research/syntaxnet/util/utf8/unilib.h  \n","  inflating: ./models/research/syntaxnet/util/utf8/unicodetext.h  \n","  inflating: ./models/research/syntaxnet/util/utf8/unilib.cc  \n","  inflating: ./models/research/syntaxnet/util/utf8/BUILD  \n","  inflating: ./models/research/syntaxnet/util/utf8/gtest_main.cc  \n","  inflating: ./models/research/syntaxnet/util/utf8/unilib_utf8_utils.h  \n","  inflating: ./models/research/syntaxnet/util/utf8/unicodetext.cc  \n","  inflating: ./models/research/syntaxnet/WORKSPACE  \n","   creating: ./models/research/syntaxnet/dragnn/\n","   creating: ./models/research/syntaxnet/dragnn/tools/\n","  inflating: ./models/research/syntaxnet/dragnn/tools/evaluator.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/parser_trainer.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/segmenter-evaluator.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/oss_notebook_launcher.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/oss_setup.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/build_pip_package.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/model_trainer.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/segmenter_trainer.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py  \n","   creating: ./models/research/syntaxnet/dragnn/tools/testdata/\n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/small.conll  \n","   creating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/\n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/config.txt  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/targets.pbtxt  \n","   creating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/\n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/char-ngram-map  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/word-map  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/prefix-table  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/char-map  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/suffix-table  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/tag-to-category  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/tag-map  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/label-map  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/lcword-map  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/category-map  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/hyperparameters.pbtxt  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/testdata/biaffine.model/master.pbtxt  \n","   creating: ./models/research/syntaxnet/dragnn/tools/benchmarks/\n","  inflating: ./models/research/syntaxnet/dragnn/tools/benchmarks/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/trainer.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/model_trainer_test.sh  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/parse_to_conll.py  \n","  inflating: ./models/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py  \n","   creating: ./models/research/syntaxnet/dragnn/protos/\n","  inflating: ./models/research/syntaxnet/dragnn/protos/data.proto  \n","  inflating: ./models/research/syntaxnet/dragnn/protos/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/protos/cell_trace.proto  \n","  inflating: ./models/research/syntaxnet/dragnn/protos/spec.proto  \n","  inflating: ./models/research/syntaxnet/dragnn/protos/runtime.proto  \n","  inflating: ./models/research/syntaxnet/dragnn/protos/trace.proto  \n","  inflating: ./models/research/syntaxnet/dragnn/protos/export.proto  \n","  inflating: ./models/research/syntaxnet/dragnn/BUILD  \n","   creating: ./models/research/syntaxnet/dragnn/components/\n","   creating: ./models/research/syntaxnet/dragnn/components/util/\n","  inflating: ./models/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h  \n","  inflating: ./models/research/syntaxnet/dragnn/components/util/BUILD  \n","   creating: ./models/research/syntaxnet/dragnn/components/syntaxnet/\n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc  \n","   creating: ./models/research/syntaxnet/dragnn/components/syntaxnet/testdata/\n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.tag-map  \n"," extracting: ./models/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.word-map  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.master-spec  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.label-map  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/testdata/master_spec.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc  \n","   creating: ./models/research/syntaxnet/dragnn/components/stateless/\n","  inflating: ./models/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/components/stateless/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/components/stateless/stateless_component.cc  \n","   creating: ./models/research/syntaxnet/dragnn/conll2017/\n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/conll_parser_trainer.sh  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/make_parser_spec.py  \n","   creating: ./models/research/syntaxnet/dragnn/conll2017/sample/\n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.master_spec  \n","   creating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/\n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/char-ngram-map  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/word-map  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/prefix-table  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/char-map  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/suffix-table  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/tag-to-category  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/tag-map  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/label-map  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/lcword-map  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/category-map  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.checkpoint.data-00000-of-00001  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.checkpoint.index  \n","  inflating: ./models/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.checkpoint.meta  \n","   creating: ./models/research/syntaxnet/dragnn/config_builder/\n"," extracting: ./models/research/syntaxnet/dragnn/config_builder/__init__.py  \n","   creating: ./models/research/syntaxnet/dragnn/io/\n","  inflating: ./models/research/syntaxnet/dragnn/io/sentence_input_batch.h  \n","  inflating: ./models/research/syntaxnet/dragnn/io/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/io/sentence_input_batch.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/io/syntaxnet_sentence.h  \n","  inflating: ./models/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc  \n"," extracting: ./models/research/syntaxnet/dragnn/__init__.py  \n","   creating: ./models/research/syntaxnet/dragnn/viz/\n","  inflating: ./models/research/syntaxnet/dragnn/viz/trace_interaction_handlers.js  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/webpack.config.js  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/interactive_graph.jsx  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/example_with_lookahead.html  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/node_info.jsx  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/dragnn_tutorial_2.html  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/sample_master_state.json  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/README.md  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/Dockerfile  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/develop.sh  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/dragnn_layout.js  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/visualize.js  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/compile-minified.sh  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/index.html  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/package.json  \n","  inflating: ./models/research/syntaxnet/dragnn/viz/viz.min.js.gz  \n","   creating: ./models/research/syntaxnet/dragnn/core/\n","  inflating: ./models/research/syntaxnet/dragnn/core/compute_session.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/compute_session_pool_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/compute_session_pool.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/core/index_translator_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/beam.h  \n","   creating: ./models/research/syntaxnet/dragnn/core/ops/\n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/compute_session_op.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/shape_helpers.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/ops/compute_session_op.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/input_batch_cache_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/index_translator.cc  \n","   creating: ./models/research/syntaxnet/dragnn/core/test/\n","  inflating: ./models/research/syntaxnet/dragnn/core/test/mock_component.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/test/fake_component_base.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/test/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/core/test/generic.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/test/mock_transition_state.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/test/mock_compute_session.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/test/generic.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/resource_container_test.cc  \n","   creating: ./models/research/syntaxnet/dragnn/core/interfaces/\n","  inflating: ./models/research/syntaxnet/dragnn/core/interfaces/transition_state.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/interfaces/component.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/interfaces/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/core/interfaces/transition_state_starter_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/interfaces/input_batch.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/compute_session_impl_test.cc  \n","   creating: ./models/research/syntaxnet/dragnn/core/testdata/\n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/syntaxnet_tagger.tag-map  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/split_tagger_master_spec.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/simple_tagger_lstm_master_spec.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/simple_parser_master_spec.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/ud-hungarian.master-spec  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/repository  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/tagger_parser_master_spec.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/syntaxnet_tagger.label-map  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/simple-tagger.repository  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/brain-parser-model  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/simple_tagger_wrapped_lstm_master_spec.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/simple-tagger.brain-parser-model  \n"," extracting: ./models/research/syntaxnet/dragnn/core/testdata/syntaxnet_tagger.word-map  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/simple-tagger.tag-map  \n","  inflating: ./models/research/syntaxnet/dragnn/core/testdata/simple_tagger_master_spec.textproto  \n","  inflating: ./models/research/syntaxnet/dragnn/core/component_registry.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/input_batch_cache.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/resource_container.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/component_registry.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/index_translator.h  \n","   creating: ./models/research/syntaxnet/dragnn/core/util/\n","  inflating: ./models/research/syntaxnet/dragnn/core/util/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/core/util/label.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/compute_session_impl.h  \n","  inflating: ./models/research/syntaxnet/dragnn/core/compute_session_impl.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/beam_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/core/compute_session_pool.cc  \n","   creating: ./models/research/syntaxnet/dragnn/mst/\n","  inflating: ./models/research/syntaxnet/dragnn/mst/spanning_tree_iterator.h  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/BUILD  \n","   creating: ./models/research/syntaxnet/dragnn/mst/ops/\n","  inflating: ./models/research/syntaxnet/dragnn/mst/ops/mst_op_kernels.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/ops/mst_ops.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/README.md  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/mst_solver_random_comparison_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/spanning_tree_iterator_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/disjoint_set_forest_test.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/mst_solver.h  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/disjoint_set_forest.h  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/spanning_tree_iterator.cc  \n","  inflating: ./models/research/syntaxnet/dragnn/mst/mst_solver_test.cc  \n","   creating: ./models/research/syntaxnet/dragnn/python/\n","  inflating: ./models/research/syntaxnet/dragnn/python/render_spec_with_graphviz.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/component_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/wrapped_units.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/bulk_component.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/bulk_component_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/lexicon_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/digraph_ops_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/dragnn_ops.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/component.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/load_mst_cc_impl.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/runtime_support_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/evaluation.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/BUILD  \n","  inflating: ./models/research/syntaxnet/dragnn/python/graph_builder_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/evaluation_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/trainer_lib.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/biaffine_units_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/transformer_units_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/composite_optimizer_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/visualization.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/composite_optimizer.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/sentence_io.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/load_dragnn_cc_impl.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/mst_ops_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/network_units.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/biaffine_units.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/network_units_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/mst_units.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/dragnn_model_saver.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/trainer_lib_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/spec_builder_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py  \n","   creating: ./models/research/syntaxnet/dragnn/python/testdata/\n","  inflating: ./models/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec  \n","  inflating: ./models/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params  \n","  inflating: ./models/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map  \n","  inflating: ./models/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map  \n","  inflating: ./models/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map  \n","  inflating: ./models/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map  \n","  inflating: ./models/research/syntaxnet/dragnn/python/sentence_io_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/runtime_support.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/render_parse_tree_graphviz.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/visualization_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/render_parse_tree_graphviz_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/transformer_units.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/digraph_ops.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/file_diff_test.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/lexicon.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/graph_builder.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/spec_builder.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/mst_ops.py  \n","  inflating: ./models/research/syntaxnet/dragnn/python/mst_units_test.py  \n","   creating: ./models/research/syntaxnet/syntaxnet/\n","  inflating: ./models/research/syntaxnet/syntaxnet/document_format.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/sentence_features.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_ngram_string_extractor.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_properties.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/segmenter_utils.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/utils.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/workspace.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/affix.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/base.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_properties.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_shift_transitions.h  \n","   creating: ./models/research/syntaxnet/syntaxnet/models/\n","   creating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/\n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/tagger-params  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/word-map  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/prefix-table  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/suffix-table  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/parser-params  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/tag-map  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/fine-to-universal.map  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/label-map  \n","  inflating: ./models/research/syntaxnet/syntaxnet/models/parsey_mcparseface/context.pbtxt  \n","  inflating: ./models/research/syntaxnet/syntaxnet/shift_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/head_transitions.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/arc_standard_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/test_main.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/sentence_batch.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/whole_sentence_features_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/binary_segment_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/label_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_features.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/fml_parser.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/whole_sentence_features.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_ngram_string_extractor.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/document_format.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/reader_ops_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/BUILD  \n","  inflating: ./models/research/syntaxnet/syntaxnet/shared_store.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/graph_builder_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_trainer.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/registry.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/sentence_features_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_features_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/term_frequency_map_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/label_transitions.cc  \n","   creating: ./models/research/syntaxnet/syntaxnet/ops/\n","  inflating: ./models/research/syntaxnet/syntaxnet/ops/parser_ops.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/ops/shape_helpers.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/head_label_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/task_spec.proto  \n","  inflating: ./models/research/syntaxnet/syntaxnet/sentence_batch.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_eval.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/test_flags.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/morpher_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/unpack_sparse_features.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/feature_extractor.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/lexicon_builder_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/conll2tree.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/shared_store.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/registry_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/demo.sh  \n","  inflating: ./models/research/syntaxnet/syntaxnet/sentence_features.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/feature_types.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_shift_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/segmenter_utils_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/proto_io.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/generic_features_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/once_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/fml_parser_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_state.cc  \n","   creating: ./models/research/syntaxnet/syntaxnet/testdata/\n","  inflating: ./models/research/syntaxnet/syntaxnet/testdata/document  \n","  inflating: ./models/research/syntaxnet/syntaxnet/testdata/context.pbtxt  \n"," extracting: ./models/research/syntaxnet/syntaxnet/testdata/hello.txt  \n","  inflating: ./models/research/syntaxnet/syntaxnet/testdata/mini-training-set  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_properties_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/sparse.proto  \n","  inflating: ./models/research/syntaxnet/syntaxnet/dictionary.proto  \n","  inflating: ./models/research/syntaxnet/syntaxnet/load_parser_ops.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/head_label_transitions.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/tagger_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/syntaxnet.bzl  \n","  inflating: ./models/research/syntaxnet/syntaxnet/once_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/morphology_label_set.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/segmenter_utils.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/sentence.proto  \n","  inflating: ./models/research/syntaxnet/syntaxnet/populate_test_inputs.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/head_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/tagger_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_state.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/beam_reader_ops_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/text_formats.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/utils.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/text_formats_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/head_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/structured_graph_builder.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/kbest_syntax.proto  \n","  inflating: ./models/research/syntaxnet/syntaxnet/syntaxnet_ops.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/label_transitions.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/affix.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_features.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/task_context.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/populate_test_inputs.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/binary_segment_state.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/feature_extractor.proto  \n","  inflating: ./models/research/syntaxnet/syntaxnet/generic_features.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/fml_parser.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/head_label_transitions.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/shared_store_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/term_frequency_map.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/document_filters.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/binary_segment_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/context.pbtxt  \n","  inflating: ./models/research/syntaxnet/syntaxnet/binary_segment_state.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/morphology_label_set.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/generic_features.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/binary_segment_state_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/workspace.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_transitions.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/registry.cc  \n","   creating: ./models/research/syntaxnet/syntaxnet/util/\n","  inflating: ./models/research/syntaxnet/syntaxnet/util/check.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/BUILD  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/registry.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/resources_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/check_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/registry_test_base.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/registry_test_impl.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/resources.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/util/registry_test.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/feature_extractor.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/graph_builder.py  \n","  inflating: ./models/research/syntaxnet/syntaxnet/whole_sentence_features.h  \n","  inflating: ./models/research/syntaxnet/syntaxnet/parser_trainer_test.sh  \n","  inflating: ./models/research/syntaxnet/syntaxnet/arc_standard_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/beam_reader_ops.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/morphology_label_set_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/lexicon_builder.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/term_frequency_map.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/char_ngram_string_extractor_test.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/reader_ops.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/task_context.cc  \n","  inflating: ./models/research/syntaxnet/syntaxnet/embedding_feature_extractor.h  \n","  inflating: ./models/research/syntaxnet/.gitignore  \n","   creating: ./models/research/attention_ocr/\n","  inflating: ./models/research/attention_ocr/README.md  \n","   creating: ./models/research/attention_ocr/python/\n","  inflating: ./models/research/attention_ocr/python/train.py  \n","  inflating: ./models/research/attention_ocr/python/data_provider.py  \n","  inflating: ./models/research/attention_ocr/python/model_test.py  \n","  inflating: ./models/research/attention_ocr/python/inception_preprocessing.py  \n","  inflating: ./models/research/attention_ocr/python/metrics.py  \n","  inflating: ./models/research/attention_ocr/python/all_jobs.screenrc  \n","  inflating: ./models/research/attention_ocr/python/sequence_layers_test.py  \n","  inflating: ./models/research/attention_ocr/python/data_provider_test.py  \n","  inflating: ./models/research/attention_ocr/python/eval.py  \n","  inflating: ./models/research/attention_ocr/python/demo_inference.py  \n","  inflating: ./models/research/attention_ocr/python/model.py  \n","   creating: ./models/research/attention_ocr/python/datasets/\n","  inflating: ./models/research/attention_ocr/python/datasets/unittest_utils.py  \n","  inflating: ./models/research/attention_ocr/python/datasets/fsns.py  \n","  inflating: ./models/research/attention_ocr/python/datasets/unittest_utils_test.py  \n","   creating: ./models/research/attention_ocr/python/datasets/testdata/\n","   creating: ./models/research/attention_ocr/python/datasets/testdata/fsns/\n","  inflating: ./models/research/attention_ocr/python/datasets/testdata/fsns/fsns-00000-of-00001  \n","  inflating: ./models/research/attention_ocr/python/datasets/testdata/fsns/charset_size=134.txt  \n","  inflating: ./models/research/attention_ocr/python/datasets/testdata/fsns/links.txt  \n","  inflating: ./models/research/attention_ocr/python/datasets/__init__.py  \n","  inflating: ./models/research/attention_ocr/python/datasets/fsns_test.py  \n","  inflating: ./models/research/attention_ocr/python/common_flags.py  \n","   creating: ./models/research/attention_ocr/python/testdata/\n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_19.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_23.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_21.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_24.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_06.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_17.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_01.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_13.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_04.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_10.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_00.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_16.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_30.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_02.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_29.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_27.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_31.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_26.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_05.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_11.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_12.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_15.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_03.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_28.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_07.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_18.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_14.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_25.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_08.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_20.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_22.png  \n","  inflating: ./models/research/attention_ocr/python/testdata/fsns_train_09.png  \n","  inflating: ./models/research/attention_ocr/python/demo_inference_test.py  \n","  inflating: ./models/research/attention_ocr/python/utils.py  \n","  inflating: ./models/research/attention_ocr/python/sequence_layers.py  \n","  inflating: ./models/research/attention_ocr/python/metrics_test.py  \n","   creating: ./models/research/vid2depth/\n","  inflating: ./models/research/vid2depth/nets.py  \n","  inflating: ./models/research/vid2depth/train.py  \n","  inflating: ./models/research/vid2depth/BUILD  \n","   creating: ./models/research/vid2depth/ops/\n","  inflating: ./models/research/vid2depth/ops/icp_grad_test.py  \n","  inflating: ./models/research/vid2depth/ops/BUILD  \n","  inflating: ./models/research/vid2depth/ops/icp_op_kernel.cc  \n","  inflating: ./models/research/vid2depth/ops/icp_grad.py  \n","  inflating: ./models/research/vid2depth/ops/icp_test.py  \n","   creating: ./models/research/vid2depth/ops/testdata/\n","  inflating: ./models/research/vid2depth/ops/testdata/pointcloud.npy  \n","  inflating: ./models/research/vid2depth/ops/icp_util.py  \n","  inflating: ./models/research/vid2depth/ops/icp_train_demo.py  \n","  inflating: ./models/research/vid2depth/ops/__init__.py  \n","  inflating: ./models/research/vid2depth/ops/pcl_demo.cc  \n","  inflating: ./models/research/vid2depth/ops/icp_op.py  \n","  inflating: ./models/research/vid2depth/util.py  \n","  inflating: ./models/research/vid2depth/model.py  \n","  inflating: ./models/research/vid2depth/README.md  \n","  inflating: ./models/research/vid2depth/repo.bzl  \n","  inflating: ./models/research/vid2depth/reader.py  \n","   creating: ./models/research/vid2depth/third_party/\n","  inflating: ./models/research/vid2depth/third_party/hdf5.BUILD  \n","  inflating: ./models/research/vid2depth/third_party/eigen.BUILD  \n"," extracting: ./models/research/vid2depth/third_party/BUILD  \n","  inflating: ./models/research/vid2depth/third_party/flann.BUILD  \n","  inflating: ./models/research/vid2depth/third_party/pcl.BUILD  \n","  inflating: ./models/research/vid2depth/inference.py  \n","  inflating: ./models/research/vid2depth/project.py  \n","   creating: ./models/research/vid2depth/dataset/\n","  inflating: ./models/research/vid2depth/dataset/gen_data.py  \n","  inflating: ./models/research/vid2depth/dataset/dataset_loader.py  \n","   creating: ./models/research/vid2depth/dataset/kitti/\n","  inflating: ./models/research/vid2depth/dataset/kitti/test_files_stereo.txt  \n","  inflating: ./models/research/vid2depth/dataset/kitti/static_frames.txt  \n","  inflating: ./models/research/vid2depth/dataset/kitti/test_scenes_stereo.txt  \n","  inflating: ./models/research/vid2depth/dataset/kitti/test_scenes_eigen.txt  \n","  inflating: ./models/research/vid2depth/dataset/kitti/test_files_eigen.txt  \n","  inflating: ./models/research/vid2depth/dataset/__init__.py  \n","  inflating: ./models/research/vid2depth/.bazelrc  \n","  inflating: ./models/research/vid2depth/WORKSPACE  \n","  inflating: ./models/research/setup.py  \n","   creating: ./models/research/lm_commonsense/\n","  inflating: ./models/research/lm_commonsense/eval.py  \n","  inflating: ./models/research/lm_commonsense/method.jpg  \n","  inflating: ./models/research/lm_commonsense/README.md  \n","  inflating: ./models/research/lm_commonsense/utils.py  \n","   creating: ./models/research/seq2species/\n","  inflating: ./models/research/seq2species/test_utils.py  \n","  inflating: ./models/research/seq2species/run_training.py  \n","  inflating: ./models/research/seq2species/seq2label_utils.py  \n","  inflating: ./models/research/seq2species/build_model.py  \n","   creating: ./models/research/seq2species/protos/\n","  inflating: ./models/research/seq2species/protos/BUILD  \n","  inflating: ./models/research/seq2species/protos/seq2label.proto  \n"," extracting: ./models/research/seq2species/protos/__init__.py  \n","  inflating: ./models/research/seq2species/run_training_test.py  \n","  inflating: ./models/research/seq2species/README.md  \n","  inflating: ./models/research/seq2species/input.py  \n","  inflating: ./models/research/seq2species/configuration.py  \n","   creating: ./models/research/differential_privacy/\n","  inflating: ./models/research/differential_privacy/README.md  \n","   creating: ./models/research/adversarial_logit_pairing/\n","  inflating: ./models/research/adversarial_logit_pairing/train.py  \n","   creating: ./models/research/adversarial_logit_pairing/tiny_imagenet_converter/\n","  inflating: ./models/research/adversarial_logit_pairing/tiny_imagenet_converter/converter.py  \n","  inflating: ./models/research/adversarial_logit_pairing/eval.py  \n","  inflating: ./models/research/adversarial_logit_pairing/adversarial_attack.py  \n","  inflating: ./models/research/adversarial_logit_pairing/README.md  \n","   creating: ./models/research/adversarial_logit_pairing/datasets/\n","  inflating: ./models/research/adversarial_logit_pairing/datasets/dataset_factory.py  \n"," extracting: ./models/research/adversarial_logit_pairing/datasets/__init__.py  \n","  inflating: ./models/research/adversarial_logit_pairing/datasets/tiny_imagenet_input.py  \n","  inflating: ./models/research/adversarial_logit_pairing/datasets/imagenet_input.py  \n","  inflating: ./models/research/adversarial_logit_pairing/model_lib.py  \n","  inflating: ./models/README.md      \n","   creating: ./models/samples/\n","   creating: ./models/samples/cookbook/\n","   creating: ./models/samples/cookbook/regression/\n","  inflating: ./models/samples/cookbook/regression/automobile_data.py  \n","  inflating: ./models/samples/cookbook/regression/dnn_regression.py  \n","  inflating: ./models/samples/cookbook/regression/linear_regression_categorical.py  \n","  inflating: ./models/samples/cookbook/regression/__init__.py  \n","  inflating: ./models/samples/cookbook/regression/linear_regression.py  \n","  inflating: ./models/samples/cookbook/regression/custom_regression.py  \n","  inflating: ./models/samples/cookbook/regression/regression_test.py  \n","   creating: ./models/samples/languages/\n","   creating: ./models/samples/languages/java/\n","  inflating: ./models/samples/languages/java/README.md  \n","   creating: ./models/samples/outreach/\n","   creating: ./models/samples/outreach/blogs/\n","  inflating: ./models/samples/outreach/blogs/blog_custom_estimators.py  \n","  inflating: ./models/samples/outreach/blogs/blog_estimators_dataset.py  \n","   creating: ./models/samples/outreach/blogs/segmentation_blogpost/\n","  inflating: ./models/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb  \n","  inflating: ./models/samples/outreach/blogs/housing_prices.ipynb  \n","   creating: ./models/samples/outreach/demos/\n","  inflating: ./models/samples/outreach/demos/eager_execution.ipynb  \n","   creating: ./models/samples/core/\n","   creating: ./models/samples/core/guide/\n","  inflating: ./models/samples/core/guide/autograph.ipynb  \n","   creating: ./models/samples/core/tutorials/\n","   creating: ./models/samples/core/tutorials/eager/\n","  inflating: ./models/samples/core/tutorials/eager/custom_training_walkthrough.ipynb  \n","   creating: ./models/samples/core/tutorials/keras/\n","  inflating: ./models/samples/core/tutorials/keras/save_and_restore_models.ipynb  \n","  inflating: ./models/samples/core/tutorials/keras/basic_classification.ipynb  \n","  inflating: ./models/samples/core/tutorials/keras/basic_regression.ipynb  \n","  inflating: ./models/samples/core/tutorials/keras/basic_text_classification.ipynb  \n","  inflating: ./models/samples/core/tutorials/keras/overfit_and_underfit.ipynb  \n","   creating: ./models/samples/core/tutorials/estimators/\n","  inflating: ./models/samples/core/tutorials/estimators/linear.ipynb  \n","   creating: ./models/samples/core/get_started/\n","  inflating: ./models/samples/core/get_started/eager.ipynb  \n","  inflating: ./models/samples/core/get_started/iris_data.py  \n","  inflating: ./models/samples/core/get_started/_index.ipynb  \n","  inflating: ./models/samples/core/get_started/premade_estimator.py  \n","  inflating: ./models/samples/core/get_started/custom_estimator.py  \n","  inflating: ./models/samples/core/get_started/estimator_test.py  \n","   creating: ./models/tutorials/\n","   creating: ./models/tutorials/image/\n","   creating: ./models/tutorials/image/imagenet/\n","  inflating: ./models/tutorials/image/imagenet/BUILD  \n","  inflating: ./models/tutorials/image/imagenet/classify_image.py  \n","   creating: ./models/tutorials/image/cifar10/\n","  inflating: ./models/tutorials/image/cifar10/cifar10_input.py  \n","  inflating: ./models/tutorials/image/cifar10/cifar10_multi_gpu_train.py  \n","  inflating: ./models/tutorials/image/cifar10/BUILD  \n","  inflating: ./models/tutorials/image/cifar10/cifar10_eval.py  \n","  inflating: ./models/tutorials/image/cifar10/README.md  \n","  inflating: ./models/tutorials/image/cifar10/cifar10_train.py  \n","  inflating: ./models/tutorials/image/cifar10/__init__.py  \n","  inflating: ./models/tutorials/image/cifar10/cifar10.py  \n","  inflating: ./models/tutorials/image/cifar10/cifar10_input_test.py  \n","   creating: ./models/tutorials/image/mnist/\n","  inflating: ./models/tutorials/image/mnist/BUILD  \n"," extracting: ./models/tutorials/image/mnist/__init__.py  \n","  inflating: ./models/tutorials/image/mnist/convolutional.py  \n","   creating: ./models/tutorials/image/alexnet/\n","  inflating: ./models/tutorials/image/alexnet/BUILD  \n","  inflating: ./models/tutorials/image/alexnet/alexnet_benchmark.py  \n"," extracting: ./models/tutorials/image/alexnet/__init__.py  \n"," extracting: ./models/tutorials/image/__init__.py  \n","   creating: ./models/tutorials/image/cifar10_estimator/\n","  inflating: ./models/tutorials/image/cifar10_estimator/cifar10_model.py  \n","  inflating: ./models/tutorials/image/cifar10_estimator/generate_cifar10_tfrecords.py  \n","  inflating: ./models/tutorials/image/cifar10_estimator/cifar10_utils.py  \n","  inflating: ./models/tutorials/image/cifar10_estimator/model_base.py  \n","  inflating: ./models/tutorials/image/cifar10_estimator/README.md  \n","  inflating: ./models/tutorials/image/cifar10_estimator/cmle_config.yaml  \n","  inflating: ./models/tutorials/image/cifar10_estimator/cifar10_main.py  \n"," extracting: ./models/tutorials/image/cifar10_estimator/__init__.py  \n","  inflating: ./models/tutorials/image/cifar10_estimator/cifar10.py  \n","   creating: ./models/tutorials/rnn/\n","   creating: ./models/tutorials/rnn/ptb/\n","  inflating: ./models/tutorials/rnn/ptb/reader_test.py  \n","  inflating: ./models/tutorials/rnn/ptb/BUILD  \n","  inflating: ./models/tutorials/rnn/ptb/ptb_word_lm.py  \n","  inflating: ./models/tutorials/rnn/ptb/util.py  \n","  inflating: ./models/tutorials/rnn/ptb/reader.py  \n","  inflating: ./models/tutorials/rnn/ptb/__init__.py  \n","  inflating: ./models/tutorials/rnn/BUILD  \n","   creating: ./models/tutorials/rnn/quickdraw/\n","  inflating: ./models/tutorials/rnn/quickdraw/BUILD  \n","  inflating: ./models/tutorials/rnn/quickdraw/create_dataset.py  \n","  inflating: ./models/tutorials/rnn/quickdraw/train_model.py  \n","  inflating: ./models/tutorials/rnn/README.md  \n","  inflating: ./models/tutorials/rnn/__init__.py  \n","   creating: ./models/tutorials/embedding/\n","  inflating: ./models/tutorials/embedding/word2vec.py  \n","  inflating: ./models/tutorials/embedding/word2vec_optimized.py  \n","  inflating: ./models/tutorials/embedding/README.md  \n","  inflating: ./models/tutorials/embedding/word2vec_kernels.cc  \n","  inflating: ./models/tutorials/embedding/__init__.py  \n","  inflating: ./models/tutorials/embedding/word2vec_test.py  \n","  inflating: ./models/tutorials/embedding/word2vec_ops.cc  \n","  inflating: ./models/tutorials/embedding/word2vec_optimized_test.py  \n","  inflating: ./models/tutorials/README.md  \n"," extracting: ./models/tutorials/__init__.py  \n","  inflating: ./models/.gitmodules    \n","  inflating: ./models/AUTHORS        \n","  inflating: ./models/ISSUE_TEMPLATE.md  \n","  inflating: ./models/CODEOWNERS     \n"," extracting: ./models/WORKSPACE      \n","  inflating: ./models/CONTRIBUTING.md  \n","  inflating: ./models/.gitignore     \n","   creating: ./include/\n","   creating: ./include/google/\n","   creating: ./include/google/protobuf/\n","  inflating: ./include/google/protobuf/api.proto  \n","  inflating: ./include/google/protobuf/struct.proto  \n","  inflating: ./include/google/protobuf/wrappers.proto  \n","  inflating: ./include/google/protobuf/source_context.proto  \n","  inflating: ./include/google/protobuf/any.proto  \n","  inflating: ./include/google/protobuf/duration.proto  \n","   creating: ./include/google/protobuf/compiler/\n","  inflating: ./include/google/protobuf/compiler/plugin.proto  \n","  inflating: ./include/google/protobuf/field_mask.proto  \n","  inflating: ./include/google/protobuf/empty.proto  \n","  inflating: ./include/google/protobuf/type.proto  \n","  inflating: ./include/google/protobuf/timestamp.proto  \n","  inflating: ./include/google/protobuf/descriptor.proto  \n","  inflating: ./readme.txt            \n","   creating: ./bin/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLG7-kQ0hJgh","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZiwa882iPqV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"ok","timestamp":1588505710732,"user_tz":-330,"elapsed":6416,"user":{"displayName":"David ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgknDk-_2Sv7OVT1kJSPyQUI1x1Sjj2EFb84IU8=s64","userId":"11929545398087895742"}},"outputId":"4aee1ac7-c7a7-4b50-961b-60abc443ba1c"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sun May  3 11:35:07 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    76W / 149W |     69MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eehyZ5B3igjk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587319311436,"user_tz":-330,"elapsed":18576,"user":{"displayName":"David ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgknDk-_2Sv7OVT1kJSPyQUI1x1Sjj2EFb84IU8=s64","userId":"11929545398087895742"}},"outputId":"db25185d-bad5-4774-873e-f6e2598d0ad8"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2xu0AI5hlNtI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595997404126,"user_tz":-330,"elapsed":3592,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"a5c222ec-f509-4404-9efa-33e3d05fd8b1"},"source":["%cd models/research\n","\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1BlktwSJyzsI","colab_type":"code","colab":{}},"source":["##!apt-get install protobuf-compiler python-pil python-lxml python-tk\n","##!pip install Cython"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VZbm06jYyzuw","colab_type":"code","colab":{}},"source":["#!apt-get install protobuf-compiler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNzxsL_Eyz0u","colab_type":"code","colab":{}},"source":["!bash -c 'mv pro/*.proto ./protos/'\n","\n","#!mv pro/anchor_generator.proto ./protos"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EaITQh-Zq23H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587238127966,"user_tz":-330,"elapsed":10584,"user":{"displayName":"David ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgknDk-_2Sv7OVT1kJSPyQUI1x1Sjj2EFb84IU8=s64","userId":"11929545398087895742"}},"outputId":"6f18db67-3760-4f1b-cb52-0c6233353617"},"source":["#!protoc --python_out=. ./protos/anchor_generator.proto ./protos/argmax_matcher.proto  ./protos/bipartite_matcher.proto ./protos/box_coder.proto ./protos/box_predictor.proto ./protos/calibration.proto ./protos/eval.proto ./protos/faster_rcnn.proto ./protos/faster_rcnn_box_coder.proto ./protos/flexible_grid_anchor_generator.proto ./protos/graph_rewriter.proto ./protos/grid_anchor_generator.proto ./protos/hyperparams.proto ./protos/image_resizer.proto ./protos/input_reader.proto ./protos/keypoint_box_coder.proto ./protos/losses.proto ./protos/matcher.proto ./protos/mean_stddev_box_coder.proto ./protos/model.proto ./protos/multiscale_anchor_generator.proto ./protos/optimizer.proto ./protos/pipeline.proto ./protos/post_processing.proto ./protos/preprocessor.proto ./protos/region_similarity_calculator.proto ./protos/square_box_coder.proto ./protos/ssd.proto ./protos/ssd_anchor_generator.proto ./protos/string_int_label_map.proto ./protos/train.proto ./protos/target_assigner.proto \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./protos/anchor_generator.proto: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6lVr29ZdxrTY","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","  print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1oxyN2UyCMA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P73bPOB3Abum","colab_type":"code","colab":{}},"source":["# import os\n","# os.environ['PYTHONPATH'] += ':/content/tensorflow/models/research/:/content/tensorflow/models/research/slim'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9OlQ3ubLRYB","colab_type":"code","colab":{}},"source":["import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DsAohJx46K7r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595997416162,"user_tz":-330,"elapsed":8220,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"630db80a-28a9-4b13-b1c7-99d7b26b89bd"},"source":["!python setup.py build\n","!python setup.py install"],"execution_count":6,"outputs":[{"output_type":"stream","text":["running build\n","running build_py\n","copying object_detection/protos/keypoint_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/target_assigner_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/mean_stddev_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/calibration_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/train_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/losses_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_predictor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/preprocessor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/optimizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/model_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/region_similarity_calculator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/hyperparams_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/square_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/argmax_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/string_int_label_map_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/graph_rewriter_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/pipeline_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/bipartite_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/input_reader_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/image_resizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/post_processing_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/eval_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/multiscale_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","running egg_info\n","writing object_detection.egg-info/PKG-INFO\n","writing dependency_links to object_detection.egg-info/dependency_links.txt\n","writing requirements to object_detection.egg-info/requires.txt\n","writing top-level names to object_detection.egg-info/top_level.txt\n","reading manifest file 'object_detection.egg-info/SOURCES.txt'\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","running install\n","running bdist_egg\n","running egg_info\n","writing object_detection.egg-info/PKG-INFO\n","writing dependency_links to object_detection.egg-info/dependency_links.txt\n","writing requirements to object_detection.egg-info/requires.txt\n","writing top-level names to object_detection.egg-info/top_level.txt\n","reading manifest file 'object_detection.egg-info/SOURCES.txt'\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/xml_to_csv.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/export_inference_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/train.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/ssd.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/faster_rcnn.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/utils.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","copying build/lib/object_detection/tpu_exporters/testdata/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","creating build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/resizer.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/io_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/Object_detection_image.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/__init__.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/Object_detection_webcam.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/eval_util_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/generate_tfrecord.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/convolutional_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","creating build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/keypoint_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/target_assigner_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/calibration_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/train_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/losses_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_predictor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/preprocessor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/optimizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/model_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/region_similarity_calculator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/hyperparams_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/square_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/argmax_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/string_int_label_map_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/graph_rewriter_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/pipeline_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/bipartite_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/input_reader_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/image_resizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/post_processing_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/eval_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/Object_detection_video.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/eval_util.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/model_lib_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/inputs.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/model_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference_test.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/infer_detections.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","creating build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","creating build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/standard_fields.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/class_agnostic_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/model.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/post_processing.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_cache.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_parser.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batch_multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","creating build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","creating build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/autoaugment_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_case.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/inputs_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_tpu_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_hparams.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/train.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/eval.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/evaluator.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer_test.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_oid_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pet_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/model_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter.py to exporter.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/xml_to_csv.py to xml_to_csv.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder.py to tf_example_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder_test.py to tf_example_decoder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_inference_graph.py to export_inference_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/train.py to train.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/ssd.py to ssd.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils_test.py to utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/faster_rcnn.py to faster_rcnn.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib.py to export_saved_model_tpu_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu.py to export_saved_model_tpu.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py to export_saved_model_tpu_lib_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder.py to post_processing_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder_test.py to losses_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder.py to image_resizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder_test.py to hyperparams_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder_test.py to box_coder_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder_test.py to image_resizer_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder.py to region_similarity_calculator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder.py to target_assigner_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder.py to graph_rewriter_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder.py to model_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder.py to losses_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder.py to box_coder_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder_test.py to post_processing_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder_test.py to graph_rewriter_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder_test.py to dataset_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_test.py to optimizer_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder_test.py to input_reader_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder.py to anchor_generator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder.py to optimizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder.py to dataset_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder.py to matcher_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder.py to input_reader_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder_test.py to anchor_generator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder.py to calibration_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder.py to hyperparams_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder_test.py to region_similarity_calculator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder_test.py to calibration_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_test.py to model_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder_test.py to target_assigner_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder_test.py to matcher_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder_test.py to preprocessor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder.py to preprocessor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder_test.py to box_predictor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder.py to box_predictor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/resizer.py to resizer.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation.py to oid_vrd_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser.py to tf_example_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py to oid_vrd_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics_test.py to calibration_metrics_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation.py to calibration_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py to oid_vrd_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation_test.py to coco_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation.py to oid_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc.py to offline_eval_map_corloc.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils.py to oid_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/io_utils.py to io_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools.py to coco_tools.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools_test.py to coco_tools_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils_test.py to oid_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics.py to calibration_metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc_test.py to offline_eval_map_corloc_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation.py to coco_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation_test.py to calibration_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser_test.py to tf_example_parser_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/Object_detection_image.py to Object_detection_image.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph.py to export_tflite_ssd_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/Object_detection_webcam.py to Object_detection_webcam.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2.py to model_lib_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib.py to model_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util_test.py to eval_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/generate_tfrecord.py to generate_tfrecord.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/head.py to head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head.py to keras_box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head_test.py to keras_mask_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head.py to class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head_test.py to keras_class_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head_test.py to keypoint_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head_test.py to box_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head.py to keras_mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head_test.py to keras_box_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head.py to box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head.py to keypoint_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head_test.py to mask_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head_test.py to class_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head.py to mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head.py to keras_class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor.py to convolutional_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor.py to rfcn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor_test.py to convolutional_keras_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor.py to rfcn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py to mask_rcnn_keras_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor.py to convolutional_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor_test.py to rfcn_keras_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor.py to mask_rcnn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor_test.py to rfcn_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor_test.py to convolutional_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor.py to mask_rcnn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor_test.py to mask_rcnn_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/keypoint_box_coder_pb2.py to keypoint_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/target_assigner_pb2.py to target_assigner_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/mean_stddev_box_coder_pb2.py to mean_stddev_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/matcher_pb2.py to matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/calibration_pb2.py to calibration_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/anchor_generator_pb2.py to anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_pb2.py to ssd_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/train_pb2.py to train_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/losses_pb2.py to losses_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_predictor_pb2.py to box_predictor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/preprocessor_pb2.py to preprocessor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/grid_anchor_generator_pb2.py to grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/optimizer_pb2.py to optimizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/model_pb2.py to model_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/region_similarity_calculator_pb2.py to region_similarity_calculator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_anchor_generator_pb2.py to ssd_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/hyperparams_pb2.py to hyperparams_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/square_box_coder_pb2.py to square_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/argmax_matcher_pb2.py to argmax_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/string_int_label_map_pb2.py to string_int_label_map_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_box_coder_pb2.py to faster_rcnn_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_coder_pb2.py to box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/graph_rewriter_pb2.py to graph_rewriter_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/flexible_grid_anchor_generator_pb2.py to flexible_grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/pipeline_pb2.py to pipeline_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/bipartite_matcher_pb2.py to bipartite_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/input_reader_pb2.py to input_reader_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_pb2.py to faster_rcnn_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/image_resizer_pb2.py to image_resizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/post_processing_pb2.py to post_processing_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/eval_pb2.py to eval_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/multiscale_anchor_generator_pb2.py to multiscale_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/Object_detection_video.py to Object_detection_video.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util.py to eval_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main.py to model_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py to flexible_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator.py to grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator.py to multiscale_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator.py to multiple_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py to multiscale_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator_test.py to grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py to multiple_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator.py to flexible_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2_test.py to model_lib_v2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_test.py to exporter_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs.py to inputs.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py to faster_rcnn_resnet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor.py to ssd_mobilenet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py to faster_rcnn_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py to ssd_mobilenet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators_test.py to feature_map_generators_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py to ssd_mobilenet_v1_ppn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor.py to faster_rcnn_pnas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py to ssd_resnet_v1_ppn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py to faster_rcnn_resnet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py to ssd_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor_test.py to faster_rcnn_nas_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py to embedded_ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py to ssd_resnet_v1_fpn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py to ssd_mobilenet_v3_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py to ssd_resnet_v1_fpn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor.py to ssd_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py to faster_rcnn_pnas_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py to ssd_mobilenet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py to faster_rcnn_inception_resnet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py to ssd_mobilenet_v2_fpn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py to ssd_mobilenet_v1_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators.py to feature_map_generators.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2_test.py to mobilenet_v2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1_test.py to resnet_v1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1.py to resnet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/model_utils.py to model_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2_test.py to inception_resnet_v2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1.py to mobilenet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1_test.py to mobilenet_v1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2.py to mobilenet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2.py to inception_resnet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py to ssd_resnet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py to ssd_mobilenet_edgetpu_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py to ssd_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py to ssd_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py to ssd_mobilenet_edgetpu_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py to ssd_mobilenet_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor.py to faster_rcnn_nas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py to embedded_ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py to faster_rcnn_inception_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py to faster_rcnn_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor_test.py to ssd_inception_v3_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor.py to ssd_mobilenet_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py to ssd_mobilenet_v3_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py to ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py to ssd_mobilenet_v1_fpn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py to ssd_mobilenet_edgetpu_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor_test.py to ssd_inception_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor.py to ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_feature_extractor_test.py to ssd_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor.py to ssd_pnasnet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor_test.py to ssd_pnasnet_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor.py to ssd_inception_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py to ssd_mobilenet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py to faster_rcnn_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py to ssd_mobilenet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py to ssd_resnet_v1_ppn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py to ssd_mobilenet_v2_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib.py to export_tflite_ssd_graph_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference.py to detection_inference.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference_test.py to detection_inference_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/infer_detections.py to infer_detections.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib_test.py to export_tflite_ssd_graph_lib_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch.py to rfcn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py to faster_rcnn_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch.py to ssd_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test.py to ssd_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py to faster_rcnn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test_lib.py to ssd_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py to faster_rcnn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch_test.py to rfcn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher.py to argmax_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher_test.py to argmax_matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher_test.py to bipartite_matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher.py to bipartite_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/standard_fields.py to standard_fields.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops.py to keypoint_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_test.py to preprocessor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator_test.py to region_similarity_calculator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses_test.py to losses_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator.py to region_similarity_calculator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/class_agnostic_nms_test.py to class_agnostic_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list.py to box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_test.py to box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher_test.py to matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner.py to target_assigner.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher_test.py to batcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/post_processing.py to post_processing.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops.py to box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher.py to prefetcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm_test.py to freezable_batch_norm_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/anchor_generator.py to anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler_test.py to balanced_positive_negative_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher.py to matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder_test.py to box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm.py to freezable_batch_norm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses.py to losses.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_cache.py to preprocessor_cache.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor.py to preprocessor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler.py to balanced_positive_negative_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner_test.py to target_assigner_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher_test.py to prefetcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_decoder.py to data_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_parser.py to data_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_predictor.py to box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher.py to batcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops_test.py to keypoint_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler_test.py to minibatch_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler.py to minibatch_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder.py to box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops_test.py to box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batch_multiclass_nms_test.py to batch_multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/multiclass_nms_test.py to multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder_test.py to keypoint_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder.py to keypoint_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder_test.py to mean_stddev_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder_test.py to faster_rcnn_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder_test.py to square_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder.py to faster_rcnn_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder.py to square_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder.py to mean_stddev_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops_test.py to np_box_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation_test.py to per_image_vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager_test.py to context_manager_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation.py to object_detection_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape_test.py to static_shape_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils_test.py to visualization_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/autoaugment_utils.py to autoaugment_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops.py to np_box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation_test.py to object_detection_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation_test.py to vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops.py to patch_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util.py to dataset_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops_test.py to np_box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops.py to ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape.py to static_shape.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops_test.py to spatial_transform_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper_test.py to variables_helper_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_test.py to np_box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util_test.py to label_map_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util.py to label_map_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case.py to test_case.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics_test.py to metrics_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation.py to per_image_vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils.py to json_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util_test.py to config_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util.py to category_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops.py to np_mask_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util.py to model_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util_test.py to dataset_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops.py to np_box_mask_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules.py to learning_schedules.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_test.py to np_box_mask_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation.py to per_image_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops_test.py to np_mask_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager.py to context_manager.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops.py to np_box_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation_test.py to per_image_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util.py to config_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops.py to spatial_transform_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules_test.py to learning_schedules_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils_test.py to shape_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper.py to variables_helper.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops_test.py to patch_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils.py to visualization_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics.py to metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation.py to vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util_test.py to category_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops_test.py to np_box_mask_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils_test.py to test_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list.py to np_box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops_test.py to ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils_test.py to json_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list.py to np_box_mask_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util_test.py to model_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils.py to shape_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs_test.py to inputs_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_tpu_main.py to model_tpu_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_hparams.py to model_hparams.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/train.py to train.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/eval.py to eval.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/evaluator.py to evaluator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer.py to trainer.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer_test.py to trainer_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record_test.py to create_coco_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_oid_tf_record.py to create_oid_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py to oid_hierarchical_labels_expansion_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record.py to create_kitti_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record.py to create_pascal_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record.py to create_coco_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py to oid_hierarchical_labels_expansion.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pet_tf_record.py to create_pet_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record_test.py to create_kitti_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation_test.py to oid_tfrecord_creation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util.py to tf_record_creation_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record_test.py to create_pascal_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation.py to oid_tfrecord_creation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util_test.py to tf_record_creation_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_test.py to model_lib_test.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","object_detection.core.__pycache__.preprocessor.cpython-36: module MAY be using inspect.stack\n","object_detection.utils.__pycache__.autoaugment_utils.cpython-36: module MAY be using inspect.stack\n","creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing object_detection-0.1-py3.6.egg\n","creating /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Extracting object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding object-detection 0.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Processing dependencies for object-detection==0.1\n","Searching for Cython==0.29.21\n","Best match: Cython 0.29.21\n","Adding Cython 0.29.21 to easy-install.pth file\n","Installing cygdb script to /usr/local/bin\n","Installing cython script to /usr/local/bin\n","Installing cythonize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for matplotlib==3.2.2\n","Best match: matplotlib 3.2.2\n","Adding matplotlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Pillow==7.0.0\n","Best match: Pillow 7.0.0\n","Adding Pillow 7.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for python-dateutil==2.8.1\n","Best match: python-dateutil 2.8.1\n","Adding python-dateutil 2.8.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.18.5\n","Best match: numpy 1.18.5\n","Adding numpy 1.18.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for cycler==0.10.0\n","Best match: cycler 0.10.0\n","Adding cycler 0.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pyparsing==2.4.7\n","Best match: pyparsing 2.4.7\n","Adding pyparsing 2.4.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for kiwisolver==1.2.0\n","Best match: kiwisolver 1.2.0\n","Adding kiwisolver 1.2.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for object-detection==0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nrU_UO5e6k3v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594040441193,"user_tz":-330,"elapsed":1321,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"f60f1bf9-b769-41c3-fd8f-d3df8f2ec341"},"source":["import time, psutil\n","Start = time.time()- psutil.boot_time()\n","Left= 12*3600 - Start\n","print('Time remaining for this session is: ', Left/3600)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time remaining for this session is:  11.860658499797186\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xmJNOZmC6wME","colab_type":"code","colab":{}},"source":["#rember the last CD you did in order to specify the directory.\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fliPbsgLG71m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590153226967,"user_tz":-330,"elapsed":3221,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"5afbeaf5-5d16-409b-d8de-6c6c9fb38274"},"source":[""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iqVH9pIg7Wl1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591882023784,"user_tz":-330,"elapsed":138916,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"c6a18668-ca70-45a9-c4f5-7adaa1198246"},"source":["#### for final dataset\n","\n","%cd object_detection/\n","\n","\n","#!cp -r /mydrive/training ./\n","!cp -r /mydrive/tensorflow/final_faster.zip ./\n","!unzip final_faster.zip -d images/\n","!cp -r /mydrive/faster_here/training ./"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n","Archive:  final_faster.zip\n","  inflating: images/test.record      \n","  inflating: images/test/101.jpg     \n","  inflating: images/test/101.xml     \n","  inflating: images/test/105.jpg     \n","  inflating: images/test/105.xml     \n","  inflating: images/test/107.jpg     \n","  inflating: images/test/107.xml     \n","  inflating: images/test/11.jpg      \n","  inflating: images/test/11.xml      \n","  inflating: images/test/111.jpg     \n","  inflating: images/test/111.xml     \n","  inflating: images/test/12.jpg      \n","  inflating: images/test/12.xml      \n","  inflating: images/test/121.jpg     \n","  inflating: images/test/121.xml     \n","  inflating: images/test/131.jpg     \n","  inflating: images/test/131.xml     \n","  inflating: images/test/135.jpg     \n","  inflating: images/test/135.xml     \n","  inflating: images/test/138.jpg     \n","  inflating: images/test/138.xml     \n","  inflating: images/test/144.jpg     \n","  inflating: images/test/144.xml     \n","  inflating: images/test/146.jpg     \n","  inflating: images/test/146.xml     \n","  inflating: images/test/155.jpg     \n","  inflating: images/test/155.xml     \n","  inflating: images/test/160.jpg     \n","  inflating: images/test/160.xml     \n","  inflating: images/test/167.jpg     \n","  inflating: images/test/167.xml     \n","  inflating: images/test/169.jpg     \n","  inflating: images/test/169.xml     \n","  inflating: images/test/171.jpg     \n","  inflating: images/test/171.xml     \n","  inflating: images/test/174.jpg     \n","  inflating: images/test/174.xml     \n","  inflating: images/test/175.jpg     \n","  inflating: images/test/175.xml     \n","  inflating: images/test/178.jpg     \n","  inflating: images/test/178.xml     \n","  inflating: images/test/187.jpg     \n","  inflating: images/test/187.xml     \n","  inflating: images/test/188.jpg     \n","  inflating: images/test/188.xml     \n","  inflating: images/test/190.jpg     \n","  inflating: images/test/190.xml     \n","  inflating: images/test/191.jpg     \n","  inflating: images/test/191.xml     \n","  inflating: images/test/197.jpg     \n","  inflating: images/test/197.xml     \n","  inflating: images/test/199.jpg     \n","  inflating: images/test/199.xml     \n","  inflating: images/test/204.jpg     \n","  inflating: images/test/204.xml     \n","  inflating: images/test/212.jpg     \n","  inflating: images/test/212.xml     \n","  inflating: images/test/214.jpg     \n","  inflating: images/test/214.xml     \n","  inflating: images/test/228.jpg     \n","  inflating: images/test/228.xml     \n","  inflating: images/test/229.jpg     \n","  inflating: images/test/229.xml     \n","  inflating: images/test/230.jpg     \n","  inflating: images/test/230.xml     \n","  inflating: images/test/239.jpg     \n","  inflating: images/test/239.xml     \n","  inflating: images/test/243.jpg     \n","  inflating: images/test/243.xml     \n","  inflating: images/test/25.jpg      \n","  inflating: images/test/25.xml      \n","  inflating: images/test/257.jpg     \n","  inflating: images/test/257.xml     \n","  inflating: images/test/260.jpg     \n","  inflating: images/test/260.xml     \n","  inflating: images/test/262.jpg     \n","  inflating: images/test/262.xml     \n","  inflating: images/test/264.jpg     \n","  inflating: images/test/264.xml     \n","  inflating: images/test/265.jpg     \n","  inflating: images/test/265.xml     \n","  inflating: images/test/266.jpg     \n","  inflating: images/test/266.xml     \n","  inflating: images/test/267.jpg     \n","  inflating: images/test/267.xml     \n","  inflating: images/test/268.jpg     \n","  inflating: images/test/268.xml     \n","  inflating: images/test/269.jpg     \n","  inflating: images/test/269.xml     \n","  inflating: images/test/270.jpg     \n","  inflating: images/test/270.xml     \n","  inflating: images/test/271.jpg     \n","  inflating: images/test/271.xml     \n","  inflating: images/test/273.jpg     \n","  inflating: images/test/273.xml     \n","  inflating: images/test/274.jpg     \n","  inflating: images/test/274.xml     \n","  inflating: images/test/275.jpg     \n","  inflating: images/test/275.xml     \n","  inflating: images/test/278.jpg     \n","  inflating: images/test/278.xml     \n","  inflating: images/test/279.jpg     \n","  inflating: images/test/279.xml     \n","  inflating: images/test/280.jpg     \n","  inflating: images/test/280.xml     \n","  inflating: images/test/281.jpg     \n","  inflating: images/test/281.xml     \n","  inflating: images/test/282.jpg     \n","  inflating: images/test/282.xml     \n","  inflating: images/test/283.jpg     \n","  inflating: images/test/283.xml     \n","  inflating: images/test/284.jpg     \n","  inflating: images/test/284.xml     \n","  inflating: images/test/286.jpg     \n","  inflating: images/test/286.xml     \n","  inflating: images/test/287.jpg     \n","  inflating: images/test/287.xml     \n","  inflating: images/test/291.jpg     \n","  inflating: images/test/291.xml     \n","  inflating: images/test/292.jpg     \n","  inflating: images/test/292.xml     \n","  inflating: images/test/294.jpg     \n","  inflating: images/test/294.xml     \n","  inflating: images/test/296.jpg     \n","  inflating: images/test/296.xml     \n","  inflating: images/test/297.jpg     \n","  inflating: images/test/297.xml     \n","  inflating: images/test/298.jpg     \n","  inflating: images/test/298.xml     \n","  inflating: images/test/299.jpg     \n","  inflating: images/test/299.xml     \n","  inflating: images/test/300.jpg     \n","  inflating: images/test/300.xml     \n","  inflating: images/test/301.jpg     \n","  inflating: images/test/301.xml     \n","  inflating: images/test/303.jpg     \n","  inflating: images/test/303.xml     \n","  inflating: images/test/305.jpg     \n","  inflating: images/test/305.xml     \n","  inflating: images/test/306.jpg     \n","  inflating: images/test/306.xml     \n","  inflating: images/test/308.jpg     \n","  inflating: images/test/308.xml     \n","  inflating: images/test/309.jpg     \n","  inflating: images/test/309.xml     \n","  inflating: images/test/315.jpg     \n","  inflating: images/test/315.xml     \n","  inflating: images/test/316.jpg     \n","  inflating: images/test/316.xml     \n","  inflating: images/test/317.jpg     \n","  inflating: images/test/317.xml     \n","  inflating: images/test/318.jpg     \n","  inflating: images/test/318.xml     \n","  inflating: images/test/324.jpg     \n","  inflating: images/test/324.xml     \n","  inflating: images/test/34.jpg      \n","  inflating: images/test/34.xml      \n","  inflating: images/test/38.jpg      \n","  inflating: images/test/38.xml      \n","  inflating: images/test/4.jpg       \n","  inflating: images/test/4.xml       \n","  inflating: images/test/41.jpg      \n","  inflating: images/test/41.xml      \n","  inflating: images/test/47.jpg      \n","  inflating: images/test/47.xml      \n","  inflating: images/test/5.jpg       \n","  inflating: images/test/5.xml       \n","  inflating: images/test/50.jpg      \n","  inflating: images/test/50.xml      \n","  inflating: images/test/55.jpg      \n","  inflating: images/test/55.xml      \n","  inflating: images/test/57.jpg      \n","  inflating: images/test/57.xml      \n","  inflating: images/test/59.jpg      \n","  inflating: images/test/59.xml      \n","  inflating: images/test/6.jpg       \n","  inflating: images/test/6.xml       \n","  inflating: images/test/60.jpg      \n","  inflating: images/test/60.xml      \n","  inflating: images/test/61.jpg      \n","  inflating: images/test/61.xml      \n","  inflating: images/test/63.jpg      \n","  inflating: images/test/63.xml      \n","  inflating: images/test/65.jpg      \n","  inflating: images/test/65.xml      \n","  inflating: images/test/67.jpg      \n","  inflating: images/test/67.xml      \n","  inflating: images/test/69.jpg      \n","  inflating: images/test/69.xml      \n","  inflating: images/test/7.jpg       \n","  inflating: images/test/7.xml       \n","  inflating: images/test/79.jpg      \n","  inflating: images/test/79.xml      \n","  inflating: images/test/83.jpg      \n","  inflating: images/test/83.xml      \n","  inflating: images/test/90.jpg      \n","  inflating: images/test/90.xml      \n","  inflating: images/test/91.jpg      \n","  inflating: images/test/91.xml      \n","  inflating: images/test/96.jpg      \n","  inflating: images/test/96.xml      \n","  inflating: images/test_labels.csv  \n","  inflating: images/train.record     \n","  inflating: images/train/1005.jpg   \n","  inflating: images/train/1005.xml   \n","  inflating: images/train/1008.jpg   \n","  inflating: images/train/1008.xml   \n","  inflating: images/train/1009.jpg   \n","  inflating: images/train/1009.xml   \n","  inflating: images/train/1015.jpg   \n","  inflating: images/train/1015.xml   \n","  inflating: images/train/1019.jpg   \n","  inflating: images/train/1019.xml   \n","  inflating: images/train/1021.jpg   \n","  inflating: images/train/1021.xml   \n","  inflating: images/train/1022.jpg   \n","  inflating: images/train/1022.xml   \n","  inflating: images/train/1024.jpg   \n","  inflating: images/train/1024.xml   \n","  inflating: images/train/1029.jpg   \n","  inflating: images/train/1029.xml   \n","  inflating: images/train/1030.jpg   \n","  inflating: images/train/1030.xml   \n","  inflating: images/train/1032.jpg   \n","  inflating: images/train/1032.xml   \n","  inflating: images/train/1033.jpg   \n","  inflating: images/train/1033.xml   \n","  inflating: images/train/1036.jpg   \n","  inflating: images/train/1036.xml   \n","  inflating: images/train/1041.jpg   \n","  inflating: images/train/1041.xml   \n","  inflating: images/train/1042.jpg   \n","  inflating: images/train/1042.xml   \n","  inflating: images/train/1044.jpg   \n","  inflating: images/train/1044.xml   \n","  inflating: images/train/1045.jpg   \n","  inflating: images/train/1045.xml   \n","  inflating: images/train/1046.jpg   \n","  inflating: images/train/1046.xml   \n","  inflating: images/train/1053.jpg   \n","  inflating: images/train/1053.xml   \n","  inflating: images/train/1055.jpg   \n","  inflating: images/train/1055.xml   \n","  inflating: images/train/1057.jpg   \n","  inflating: images/train/1057.xml   \n","  inflating: images/train/1058.jpg   \n","  inflating: images/train/1058.xml   \n","  inflating: images/train/1063.jpg   \n","  inflating: images/train/1063.xml   \n","  inflating: images/train/1065.jpg   \n","  inflating: images/train/1065.xml   \n","  inflating: images/train/1066.jpg   \n","  inflating: images/train/1066.xml   \n","  inflating: images/train/1067.jpg   \n","  inflating: images/train/1067.xml   \n","  inflating: images/train/1069.jpg   \n","  inflating: images/train/1069.xml   \n","  inflating: images/train/1071.jpg   \n","  inflating: images/train/1071.xml   \n","  inflating: images/train/1072.jpg   \n","  inflating: images/train/1072.xml   \n","  inflating: images/train/1074.jpg   \n","  inflating: images/train/1074.xml   \n","  inflating: images/train/1075.jpg   \n","  inflating: images/train/1075.xml   \n","  inflating: images/train/1077.jpg   \n","  inflating: images/train/1077.xml   \n","  inflating: images/train/1082.jpg   \n","  inflating: images/train/1082.xml   \n","  inflating: images/train/1083.jpg   \n","  inflating: images/train/1083.xml   \n","  inflating: images/train/1084.jpg   \n","  inflating: images/train/1084.xml   \n","  inflating: images/train/1086.jpg   \n","  inflating: images/train/1086.xml   \n","  inflating: images/train/1087.jpg   \n","  inflating: images/train/1087.xml   \n","  inflating: images/train/1089.jpg   \n","  inflating: images/train/1089.xml   \n","  inflating: images/train/1090.jpg   \n","  inflating: images/train/1090.xml   \n","  inflating: images/train/1092.jpg   \n","  inflating: images/train/1092.xml   \n","  inflating: images/train/1093.jpg   \n","  inflating: images/train/1093.xml   \n","  inflating: images/train/1095.jpg   \n","  inflating: images/train/1095.xml   \n","  inflating: images/train/1096.jpg   \n","  inflating: images/train/1096.xml   \n","  inflating: images/train/1097.jpg   \n","  inflating: images/train/1097.xml   \n","  inflating: images/train/1098.jpg   \n","  inflating: images/train/1098.xml   \n","  inflating: images/train/1099.jpg   \n","  inflating: images/train/1099.xml   \n","  inflating: images/train/1100.jpg   \n","  inflating: images/train/1100.xml   \n","  inflating: images/train/1102.jpg   \n","  inflating: images/train/1102.xml   \n","  inflating: images/train/1103.jpg   \n","  inflating: images/train/1103.xml   \n","  inflating: images/train/1107.jpg   \n","  inflating: images/train/1107.xml   \n","  inflating: images/train/1109.jpg   \n","  inflating: images/train/1109.xml   \n","  inflating: images/train/1110.jpg   \n","  inflating: images/train/1110.xml   \n","  inflating: images/train/1112.jpg   \n","  inflating: images/train/1112.xml   \n","  inflating: images/train/1116.jpg   \n","  inflating: images/train/1116.xml   \n","  inflating: images/train/1119.jpg   \n","  inflating: images/train/1119.xml   \n","  inflating: images/train/1122.jpg   \n","  inflating: images/train/1122.xml   \n","  inflating: images/train/1126.jpg   \n","  inflating: images/train/1126.xml   \n","  inflating: images/train/1127.jpg   \n","  inflating: images/train/1127.xml   \n","  inflating: images/train/1128.jpg   \n","  inflating: images/train/1128.xml   \n","  inflating: images/train/1129.jpg   \n","  inflating: images/train/1129.xml   \n","  inflating: images/train/1130.jpg   \n","  inflating: images/train/1130.xml   \n","  inflating: images/train/1131.jpg   \n","  inflating: images/train/1131.xml   \n","  inflating: images/train/1132.jpg   \n","  inflating: images/train/1132.xml   \n","  inflating: images/train/1135.jpg   \n","  inflating: images/train/1135.xml   \n","  inflating: images/train/1136.jpg   \n","  inflating: images/train/1136.xml   \n","  inflating: images/train/1137.jpg   \n","  inflating: images/train/1137.xml   \n","  inflating: images/train/1138.jpg   \n","  inflating: images/train/1138.xml   \n","  inflating: images/train/1140.jpg   \n","  inflating: images/train/1140.xml   \n","  inflating: images/train/1142.jpg   \n","  inflating: images/train/1142.xml   \n","  inflating: images/train/1145.jpg   \n","  inflating: images/train/1145.xml   \n","  inflating: images/train/1146.jpg   \n","  inflating: images/train/1146.xml   \n","  inflating: images/train/1147.jpg   \n","  inflating: images/train/1147.xml   \n","  inflating: images/train/1149.jpg   \n","  inflating: images/train/1149.xml   \n","  inflating: images/train/1150.jpg   \n","  inflating: images/train/1150.xml   \n","  inflating: images/train/1151.jpg   \n","  inflating: images/train/1151.xml   \n","  inflating: images/train/1152.jpg   \n","  inflating: images/train/1152.xml   \n","  inflating: images/train/1153.jpg   \n","  inflating: images/train/1153.xml   \n","  inflating: images/train/1154.jpg   \n","  inflating: images/train/1154.xml   \n","  inflating: images/train/1155.jpg   \n","  inflating: images/train/1155.xml   \n","  inflating: images/train/1156.jpg   \n","  inflating: images/train/1156.xml   \n","  inflating: images/train/1157.jpg   \n","  inflating: images/train/1157.xml   \n","  inflating: images/train/1158.jpg   \n","  inflating: images/train/1158.xml   \n","  inflating: images/train/1159.jpg   \n","  inflating: images/train/1159.xml   \n","  inflating: images/train/1160.jpg   \n","  inflating: images/train/1160.xml   \n","  inflating: images/train/1161.jpg   \n","  inflating: images/train/1161.xml   \n","  inflating: images/train/1162.jpg   \n","  inflating: images/train/1162.xml   \n","  inflating: images/train/1164.jpg   \n","  inflating: images/train/1164.xml   \n","  inflating: images/train/1165.jpg   \n","  inflating: images/train/1165.xml   \n","  inflating: images/train/1166.jpg   \n","  inflating: images/train/1166.xml   \n","  inflating: images/train/1167.jpg   \n","  inflating: images/train/1167.xml   \n","  inflating: images/train/1168.jpg   \n","  inflating: images/train/1168.xml   \n","  inflating: images/train/1169.jpg   \n","  inflating: images/train/1169.xml   \n","  inflating: images/train/1170.jpg   \n","  inflating: images/train/1170.xml   \n","  inflating: images/train/1171.jpg   \n","  inflating: images/train/1171.xml   \n","  inflating: images/train/1173.jpg   \n","  inflating: images/train/1173.xml   \n","  inflating: images/train/1174.jpg   \n","  inflating: images/train/1174.xml   \n","  inflating: images/train/1177.jpg   \n","  inflating: images/train/1177.xml   \n","  inflating: images/train/1178.jpg   \n","  inflating: images/train/1178.xml   \n","  inflating: images/train/1183.jpg   \n","  inflating: images/train/1183.xml   \n","  inflating: images/train/1185.jpg   \n","  inflating: images/train/1185.xml   \n","  inflating: images/train/1186.jpg   \n","  inflating: images/train/1186.xml   \n","  inflating: images/train/1188.jpg   \n","  inflating: images/train/1188.xml   \n","  inflating: images/train/1190.jpg   \n","  inflating: images/train/1190.xml   \n","  inflating: images/train/1191.jpg   \n","  inflating: images/train/1191.xml   \n","  inflating: images/train/1193.jpg   \n","  inflating: images/train/1193.xml   \n","  inflating: images/train/1194.jpg   \n","  inflating: images/train/1194.xml   \n","  inflating: images/train/1195.jpg   \n","  inflating: images/train/1195.xml   \n","  inflating: images/train/1196.jpg   \n","  inflating: images/train/1196.xml   \n","  inflating: images/train/1197.jpg   \n","  inflating: images/train/1197.xml   \n","  inflating: images/train/1198.jpg   \n","  inflating: images/train/1198.xml   \n","  inflating: images/train/1199.jpg   \n","  inflating: images/train/1199.xml   \n","  inflating: images/train/1201.jpg   \n","  inflating: images/train/1201.xml   \n","  inflating: images/train/1202.jpg   \n","  inflating: images/train/1202.xml   \n","  inflating: images/train/1203.jpg   \n","  inflating: images/train/1203.xml   \n","  inflating: images/train/1207.jpg   \n","  inflating: images/train/1207.xml   \n","  inflating: images/train/1208.jpg   \n","  inflating: images/train/1208.xml   \n","  inflating: images/train/1211.jpg   \n","  inflating: images/train/1211.xml   \n","  inflating: images/train/1212.jpg   \n","  inflating: images/train/1212.xml   \n","  inflating: images/train/1213.jpg   \n","  inflating: images/train/1213.xml   \n","  inflating: images/train/1214.jpg   \n","  inflating: images/train/1214.xml   \n","  inflating: images/train/1215.jpg   \n","  inflating: images/train/1215.xml   \n","  inflating: images/train/1219.jpg   \n","  inflating: images/train/1219.xml   \n","  inflating: images/train/1220.jpg   \n","  inflating: images/train/1220.xml   \n","  inflating: images/train/1221.jpg   \n","  inflating: images/train/1221.xml   \n","  inflating: images/train/1222.jpg   \n","  inflating: images/train/1222.xml   \n","  inflating: images/train/1224.jpg   \n","  inflating: images/train/1224.xml   \n","  inflating: images/train/1225.jpg   \n","  inflating: images/train/1225.xml   \n","  inflating: images/train/1228.jpg   \n","  inflating: images/train/1228.xml   \n","  inflating: images/train/1229.jpg   \n","  inflating: images/train/1229.xml   \n","  inflating: images/train/1230.jpg   \n","  inflating: images/train/1230.xml   \n","  inflating: images/train/1231.jpg   \n","  inflating: images/train/1231.xml   \n","  inflating: images/train/1232.jpg   \n","  inflating: images/train/1232.xml   \n","  inflating: images/train/1234.jpg   \n","  inflating: images/train/1234.xml   \n","  inflating: images/train/1236.jpg   \n","  inflating: images/train/1236.xml   \n","  inflating: images/train/1239.jpg   \n","  inflating: images/train/1239.xml   \n","  inflating: images/train/1240.jpg   \n","  inflating: images/train/1240.xml   \n","  inflating: images/train/1241.jpg   \n","  inflating: images/train/1241.xml   \n","  inflating: images/train/1242.jpg   \n","  inflating: images/train/1242.xml   \n","  inflating: images/train/1244.jpg   \n","  inflating: images/train/1244.xml   \n","  inflating: images/train/1245.jpg   \n","  inflating: images/train/1245.xml   \n","  inflating: images/train/1246.jpg   \n","  inflating: images/train/1246.xml   \n","  inflating: images/train/1248.jpg   \n","  inflating: images/train/1248.xml   \n","  inflating: images/train/1250.jpg   \n","  inflating: images/train/1250.xml   \n","  inflating: images/train/1251.jpg   \n","  inflating: images/train/1251.xml   \n","  inflating: images/train/1252.jpg   \n","  inflating: images/train/1252.xml   \n","  inflating: images/train/1253.jpg   \n","  inflating: images/train/1253.xml   \n","  inflating: images/train/1256.jpg   \n","  inflating: images/train/1256.xml   \n","  inflating: images/train/1257.jpg   \n","  inflating: images/train/1257.xml   \n","  inflating: images/train/1258.jpg   \n","  inflating: images/train/1258.xml   \n","  inflating: images/train/1260.jpg   \n","  inflating: images/train/1260.xml   \n","  inflating: images/train/1261.jpg   \n","  inflating: images/train/1261.xml   \n","  inflating: images/train/1262.jpg   \n","  inflating: images/train/1262.xml   \n","  inflating: images/train/1263.jpg   \n","  inflating: images/train/1263.xml   \n","  inflating: images/train/1264.jpg   \n","  inflating: images/train/1264.xml   \n","  inflating: images/train/1265.jpg   \n","  inflating: images/train/1265.xml   \n","  inflating: images/train/1266.jpg   \n","  inflating: images/train/1266.xml   \n","  inflating: images/train/1267.jpg   \n","  inflating: images/train/1267.xml   \n","  inflating: images/train/1268.jpg   \n","  inflating: images/train/1268.xml   \n","  inflating: images/train/1269.jpg   \n","  inflating: images/train/1269.xml   \n","  inflating: images/train/1270.jpg   \n","  inflating: images/train/1270.xml   \n","  inflating: images/train/1271.jpg   \n","  inflating: images/train/1271.xml   \n","  inflating: images/train/1272.jpg   \n","  inflating: images/train/1272.xml   \n","  inflating: images/train/1274.jpg   \n","  inflating: images/train/1274.xml   \n","  inflating: images/train/1277.jpg   \n","  inflating: images/train/1277.xml   \n","  inflating: images/train/1278.jpg   \n","  inflating: images/train/1278.xml   \n","  inflating: images/train/1279.jpg   \n","  inflating: images/train/1279.xml   \n","  inflating: images/train/1280.jpg   \n","  inflating: images/train/1280.xml   \n","  inflating: images/train/1282.jpg   \n","  inflating: images/train/1282.xml   \n","  inflating: images/train/1283.jpg   \n","  inflating: images/train/1283.xml   \n","  inflating: images/train/1284.jpg   \n","  inflating: images/train/1284.xml   \n","  inflating: images/train/1285.jpg   \n","  inflating: images/train/1285.xml   \n","  inflating: images/train/1286.jpg   \n","  inflating: images/train/1286.xml   \n","  inflating: images/train/1287.jpg   \n","  inflating: images/train/1287.xml   \n","  inflating: images/train/1288.jpg   \n","  inflating: images/train/1288.xml   \n","  inflating: images/train/1289.jpg   \n","  inflating: images/train/1289.xml   \n","  inflating: images/train/1290.jpg   \n","  inflating: images/train/1290.xml   \n","  inflating: images/train/1291.jpg   \n","  inflating: images/train/1291.xml   \n","  inflating: images/train/1292.jpg   \n","  inflating: images/train/1292.xml   \n","  inflating: images/train/1293.jpg   \n","  inflating: images/train/1293.xml   \n","  inflating: images/train/1294.jpg   \n","  inflating: images/train/1294.xml   \n","  inflating: images/train/1295.jpg   \n","  inflating: images/train/1295.xml   \n","  inflating: images/train/1296.jpg   \n","  inflating: images/train/1296.xml   \n","  inflating: images/train/1298.jpg   \n","  inflating: images/train/1298.xml   \n","  inflating: images/train/1299.jpg   \n","  inflating: images/train/1299.xml   \n","  inflating: images/train/1300.jpg   \n","  inflating: images/train/1300.xml   \n","  inflating: images/train/1301.jpg   \n","  inflating: images/train/1301.xml   \n","  inflating: images/train/1302.jpg   \n","  inflating: images/train/1302.xml   \n","  inflating: images/train/1304.jpg   \n","  inflating: images/train/1304.xml   \n","  inflating: images/train/1305.jpg   \n","  inflating: images/train/1305.xml   \n","  inflating: images/train/1306.jpg   \n","  inflating: images/train/1306.xml   \n","  inflating: images/train/1307.jpg   \n","  inflating: images/train/1307.xml   \n","  inflating: images/train/1308.jpg   \n","  inflating: images/train/1308.xml   \n","  inflating: images/train/1309.jpg   \n","  inflating: images/train/1309.xml   \n","  inflating: images/train/1310.jpg   \n","  inflating: images/train/1310.xml   \n","  inflating: images/train/1311.jpg   \n","  inflating: images/train/1311.xml   \n","  inflating: images/train/1312.jpg   \n","  inflating: images/train/1312.xml   \n","  inflating: images/train/1313.jpg   \n","  inflating: images/train/1313.xml   \n","  inflating: images/train/1314.jpg   \n","  inflating: images/train/1314.xml   \n","  inflating: images/train/1315.jpg   \n","  inflating: images/train/1315.xml   \n","  inflating: images/train/1319.jpg   \n","  inflating: images/train/1319.xml   \n","  inflating: images/train/1320.jpg   \n","  inflating: images/train/1320.xml   \n","  inflating: images/train/1321.jpg   \n","  inflating: images/train/1321.xml   \n","  inflating: images/train/1322.jpg   \n","  inflating: images/train/1322.xml   \n","  inflating: images/train/1323.jpg   \n","  inflating: images/train/1323.xml   \n","  inflating: images/train/1324.jpg   \n","  inflating: images/train/1324.xml   \n","  inflating: images/train/1325.jpg   \n","  inflating: images/train/1325.xml   \n","  inflating: images/train/1326.jpg   \n","  inflating: images/train/1326.xml   \n","  inflating: images/train/1327.jpg   \n","  inflating: images/train/1327.xml   \n","  inflating: images/train/1330.jpg   \n","  inflating: images/train/1330.xml   \n","  inflating: images/train/1333.jpg   \n","  inflating: images/train/1333.xml   \n","  inflating: images/train/1334.jpg   \n","  inflating: images/train/1334.xml   \n","  inflating: images/train/1335.jpg   \n","  inflating: images/train/1335.xml   \n","  inflating: images/train/1336.jpg   \n","  inflating: images/train/1336.xml   \n","  inflating: images/train/1339.jpg   \n","  inflating: images/train/1339.xml   \n","  inflating: images/train/1340.jpg   \n","  inflating: images/train/1340.xml   \n","  inflating: images/train/1341.jpg   \n","  inflating: images/train/1341.xml   \n","  inflating: images/train/1342.jpg   \n","  inflating: images/train/1342.xml   \n","  inflating: images/train/1344.jpg   \n","  inflating: images/train/1344.xml   \n","  inflating: images/train/1345.jpg   \n","  inflating: images/train/1345.xml   \n","  inflating: images/train/1346.jpg   \n","  inflating: images/train/1346.xml   \n","  inflating: images/train/1347.jpg   \n","  inflating: images/train/1347.xml   \n","  inflating: images/train/1349.jpg   \n","  inflating: images/train/1349.xml   \n","  inflating: images/train/1351.jpg   \n","  inflating: images/train/1351.xml   \n","  inflating: images/train/1352.jpg   \n","  inflating: images/train/1352.xml   \n","  inflating: images/train/1353.jpg   \n","  inflating: images/train/1353.xml   \n","  inflating: images/train/1354.jpg   \n","  inflating: images/train/1354.xml   \n","  inflating: images/train/1356.jpg   \n","  inflating: images/train/1356.xml   \n","  inflating: images/train/1359.jpg   \n","  inflating: images/train/1359.xml   \n","  inflating: images/train/1360.jpg   \n","  inflating: images/train/1360.xml   \n","  inflating: images/train/1361.jpg   \n","  inflating: images/train/1361.xml   \n","  inflating: images/train/1362.jpg   \n","  inflating: images/train/1362.xml   \n","  inflating: images/train/1364.jpg   \n","  inflating: images/train/1364.xml   \n","  inflating: images/train/1365.jpg   \n","  inflating: images/train/1365.xml   \n","  inflating: images/train/1368.jpg   \n","  inflating: images/train/1368.xml   \n","  inflating: images/train/1370.jpg   \n","  inflating: images/train/1370.xml   \n","  inflating: images/train/1371.jpg   \n","  inflating: images/train/1371.xml   \n","  inflating: images/train/1372.jpg   \n","  inflating: images/train/1372.xml   \n","  inflating: images/train/1373.jpg   \n","  inflating: images/train/1373.xml   \n","  inflating: images/train/1374.jpg   \n","  inflating: images/train/1374.xml   \n","  inflating: images/train/1375.jpg   \n","  inflating: images/train/1375.xml   \n","  inflating: images/train/1376.jpg   \n","  inflating: images/train/1376.xml   \n","  inflating: images/train/1377.jpg   \n","  inflating: images/train/1377.xml   \n","  inflating: images/train/1378.jpg   \n","  inflating: images/train/1378.xml   \n","  inflating: images/train/1379.jpg   \n","  inflating: images/train/1379.xml   \n","  inflating: images/train/1380.jpg   \n","  inflating: images/train/1380.xml   \n","  inflating: images/train/1382.jpg   \n","  inflating: images/train/1382.xml   \n","  inflating: images/train/1383.jpg   \n","  inflating: images/train/1383.xml   \n","  inflating: images/train/1386.jpg   \n","  inflating: images/train/1386.xml   \n","  inflating: images/train/1387.jpg   \n","  inflating: images/train/1387.xml   \n","  inflating: images/train/1390.jpg   \n","  inflating: images/train/1390.xml   \n","  inflating: images/train/1391.jpg   \n","  inflating: images/train/1391.xml   \n","  inflating: images/train/1392.jpg   \n","  inflating: images/train/1392.xml   \n","  inflating: images/train/1395.jpg   \n","  inflating: images/train/1395.xml   \n","  inflating: images/train/1396.jpg   \n","  inflating: images/train/1396.xml   \n","  inflating: images/train/1397.jpg   \n","  inflating: images/train/1397.xml   \n","  inflating: images/train/1398.jpg   \n","  inflating: images/train/1398.xml   \n","  inflating: images/train/1399.jpg   \n","  inflating: images/train/1399.xml   \n","  inflating: images/train/1400.jpg   \n","  inflating: images/train/1400.xml   \n","  inflating: images/train/1401.jpg   \n","  inflating: images/train/1401.xml   \n","  inflating: images/train/1405.jpg   \n","  inflating: images/train/1405.xml   \n","  inflating: images/train/1406.jpg   \n","  inflating: images/train/1406.xml   \n","  inflating: images/train/1407.jpg   \n","  inflating: images/train/1407.xml   \n","  inflating: images/train/1408.jpg   \n","  inflating: images/train/1408.xml   \n","  inflating: images/train/1409.jpg   \n","  inflating: images/train/1409.xml   \n","  inflating: images/train/1410.jpg   \n","  inflating: images/train/1410.xml   \n","  inflating: images/train/1411.jpg   \n","  inflating: images/train/1411.xml   \n","  inflating: images/train/1412.jpg   \n","  inflating: images/train/1412.xml   \n","  inflating: images/train/1416.jpg   \n","  inflating: images/train/1416.xml   \n","  inflating: images/train/1417.jpg   \n","  inflating: images/train/1417.xml   \n","  inflating: images/train/1418.jpg   \n","  inflating: images/train/1418.xml   \n","  inflating: images/train/1419.jpg   \n","  inflating: images/train/1419.xml   \n","  inflating: images/train/1420.jpg   \n","  inflating: images/train/1420.xml   \n","  inflating: images/train/1421.jpg   \n","  inflating: images/train/1421.xml   \n","  inflating: images/train/1422.jpg   \n","  inflating: images/train/1422.xml   \n","  inflating: images/train/1423.jpg   \n","  inflating: images/train/1423.xml   \n","  inflating: images/train/1426.jpg   \n","  inflating: images/train/1426.xml   \n","  inflating: images/train/1427.jpg   \n","  inflating: images/train/1427.xml   \n","  inflating: images/train/1428.jpg   \n","  inflating: images/train/1428.xml   \n","  inflating: images/train/1430.jpg   \n","  inflating: images/train/1430.xml   \n","  inflating: images/train/1432.jpg   \n","  inflating: images/train/1432.xml   \n","  inflating: images/train/1433.jpg   \n","  inflating: images/train/1433.xml   \n","  inflating: images/train/1434.jpg   \n","  inflating: images/train/1434.xml   \n","  inflating: images/train/1435.jpg   \n","  inflating: images/train/1435.xml   \n","  inflating: images/train/1437.jpg   \n","  inflating: images/train/1437.xml   \n","  inflating: images/train/1438.jpg   \n","  inflating: images/train/1438.xml   \n","  inflating: images/train/1439.jpg   \n","  inflating: images/train/1439.xml   \n","  inflating: images/train/1440.jpg   \n","  inflating: images/train/1440.xml   \n","  inflating: images/train/1445.jpg   \n","  inflating: images/train/1445.xml   \n","  inflating: images/train/1446.jpg   \n","  inflating: images/train/1446.xml   \n","  inflating: images/train/1447.jpg   \n","  inflating: images/train/1447.xml   \n","  inflating: images/train/1448.jpg   \n","  inflating: images/train/1448.xml   \n","  inflating: images/train/1449.jpg   \n","  inflating: images/train/1449.xml   \n","  inflating: images/train/1450.jpg   \n","  inflating: images/train/1450.xml   \n","  inflating: images/train/1451.jpg   \n","  inflating: images/train/1451.xml   \n","  inflating: images/train/1452.jpg   \n","  inflating: images/train/1452.xml   \n","  inflating: images/train/1453.jpg   \n","  inflating: images/train/1453.xml   \n","  inflating: images/train/1455.jpg   \n","  inflating: images/train/1455.xml   \n","  inflating: images/train/1457.jpg   \n","  inflating: images/train/1457.xml   \n","  inflating: images/train/1458.jpg   \n","  inflating: images/train/1458.xml   \n","  inflating: images/train/1462.jpg   \n","  inflating: images/train/1462.xml   \n","  inflating: images/train/1465.jpg   \n","  inflating: images/train/1465.xml   \n","  inflating: images/train/1468.jpg   \n","  inflating: images/train/1468.xml   \n","  inflating: images/train/1469.jpg   \n","  inflating: images/train/1469.xml   \n","  inflating: images/train/1471.jpg   \n","  inflating: images/train/1471.xml   \n","  inflating: images/train/1472.jpg   \n","  inflating: images/train/1472.xml   \n","  inflating: images/train/1473.jpg   \n","  inflating: images/train/1473.xml   \n","  inflating: images/train/1474.jpg   \n","  inflating: images/train/1474.xml   \n","  inflating: images/train/1475.jpg   \n","  inflating: images/train/1475.xml   \n","  inflating: images/train/1476.jpg   \n","  inflating: images/train/1476.xml   \n","  inflating: images/train/1477.jpg   \n","  inflating: images/train/1477.xml   \n","  inflating: images/train/1478.jpg   \n","  inflating: images/train/1478.xml   \n","  inflating: images/train/1479.jpg   \n","  inflating: images/train/1479.xml   \n","  inflating: images/train/1480.jpg   \n","  inflating: images/train/1480.xml   \n","  inflating: images/train/1485.jpg   \n","  inflating: images/train/1485.xml   \n","  inflating: images/train/1486.jpg   \n","  inflating: images/train/1486.xml   \n","  inflating: images/train/1489.jpg   \n","  inflating: images/train/1489.xml   \n","  inflating: images/train/1490.jpg   \n","  inflating: images/train/1490.xml   \n","  inflating: images/train/1491.jpg   \n","  inflating: images/train/1491.xml   \n","  inflating: images/train/1492.jpg   \n","  inflating: images/train/1492.xml   \n","  inflating: images/train/1493.jpg   \n","  inflating: images/train/1493.xml   \n","  inflating: images/train/1494.jpg   \n","  inflating: images/train/1494.xml   \n","  inflating: images/train/1496.jpg   \n","  inflating: images/train/1496.xml   \n","  inflating: images/train/1503.jpg   \n","  inflating: images/train/1503.xml   \n","  inflating: images/train/1508.jpg   \n","  inflating: images/train/1508.xml   \n","  inflating: images/train/1509.jpg   \n","  inflating: images/train/1509.xml   \n","  inflating: images/train/1511.jpg   \n","  inflating: images/train/1511.xml   \n","  inflating: images/train/1512.jpg   \n","  inflating: images/train/1512.xml   \n","  inflating: images/train/1514.jpg   \n","  inflating: images/train/1514.xml   \n","  inflating: images/train/1515.jpg   \n","  inflating: images/train/1515.xml   \n","  inflating: images/train/1516.jpg   \n","  inflating: images/train/1516.xml   \n","  inflating: images/train/1517.jpg   \n","  inflating: images/train/1517.xml   \n","  inflating: images/train/1518.jpg   \n","  inflating: images/train/1518.xml   \n","  inflating: images/train/1519.jpg   \n","  inflating: images/train/1519.xml   \n","  inflating: images/train/1520.jpg   \n","  inflating: images/train/1520.xml   \n","  inflating: images/train/1521.jpg   \n","  inflating: images/train/1521.xml   \n","  inflating: images/train/1522.jpg   \n","  inflating: images/train/1522.xml   \n","  inflating: images/train/1523.jpg   \n","  inflating: images/train/1523.xml   \n","  inflating: images/train/1524.jpg   \n","  inflating: images/train/1524.xml   \n","  inflating: images/train/1525.jpg   \n","  inflating: images/train/1525.xml   \n","  inflating: images/train/1526.jpg   \n","  inflating: images/train/1526.xml   \n","  inflating: images/train/1527.jpg   \n","  inflating: images/train/1527.xml   \n","  inflating: images/train/1528.jpg   \n","  inflating: images/train/1528.xml   \n","  inflating: images/train/1529.jpg   \n","  inflating: images/train/1529.xml   \n","  inflating: images/train/1530.jpg   \n","  inflating: images/train/1530.xml   \n","  inflating: images/train/1531.jpg   \n","  inflating: images/train/1531.xml   \n","  inflating: images/train/1532.jpg   \n","  inflating: images/train/1532.xml   \n","  inflating: images/train/1533.jpg   \n","  inflating: images/train/1533.xml   \n","  inflating: images/train/1534.jpg   \n","  inflating: images/train/1534.xml   \n","  inflating: images/train/1535.jpg   \n","  inflating: images/train/1535.xml   \n","  inflating: images/train/1536.jpg   \n","  inflating: images/train/1536.xml   \n","  inflating: images/train/1537.jpg   \n","  inflating: images/train/1537.xml   \n","  inflating: images/train/1538.jpg   \n","  inflating: images/train/1538.xml   \n","  inflating: images/train/1539.jpg   \n","  inflating: images/train/1539.xml   \n","  inflating: images/train/1540.jpg   \n","  inflating: images/train/1540.xml   \n","  inflating: images/train/1541.jpg   \n","  inflating: images/train/1541.xml   \n","  inflating: images/train/1542.jpg   \n","  inflating: images/train/1542.xml   \n","  inflating: images/train/1543.jpg   \n","  inflating: images/train/1543.xml   \n","  inflating: images/train/1544.jpg   \n","  inflating: images/train/1544.xml   \n","  inflating: images/train/1545.jpg   \n","  inflating: images/train/1545.xml   \n","  inflating: images/train/1546.jpg   \n","  inflating: images/train/1546.xml   \n","  inflating: images/train/1547.jpg   \n","  inflating: images/train/1547.xml   \n","  inflating: images/train/1548.jpg   \n","  inflating: images/train/1548.xml   \n","  inflating: images/train/1549.jpg   \n","  inflating: images/train/1549.xml   \n","  inflating: images/train/1550.jpg   \n","  inflating: images/train/1550.xml   \n","  inflating: images/train/1551.jpg   \n","  inflating: images/train/1551.xml   \n","  inflating: images/train/1552.jpg   \n","  inflating: images/train/1552.xml   \n","  inflating: images/train/1553.jpg   \n","  inflating: images/train/1553.xml   \n","  inflating: images/train/1554.jpg   \n","  inflating: images/train/1554.xml   \n","  inflating: images/train/1555.jpg   \n","  inflating: images/train/1555.xml   \n","  inflating: images/train/1556.jpg   \n","  inflating: images/train/1556.xml   \n","  inflating: images/train/1557.jpg   \n","  inflating: images/train/1557.xml   \n","  inflating: images/train/1558.jpg   \n","  inflating: images/train/1558.xml   \n","  inflating: images/train/1559.jpg   \n","  inflating: images/train/1559.xml   \n","  inflating: images/train/1560.jpg   \n","  inflating: images/train/1560.xml   \n","  inflating: images/train/1561.jpg   \n","  inflating: images/train/1561.xml   \n","  inflating: images/train/1562.jpg   \n","  inflating: images/train/1562.xml   \n","  inflating: images/train/1563.jpg   \n","  inflating: images/train/1563.xml   \n","  inflating: images/train/1564.jpg   \n","  inflating: images/train/1564.xml   \n","  inflating: images/train/1565.jpg   \n","  inflating: images/train/1565.xml   \n","  inflating: images/train/1566.jpg   \n","  inflating: images/train/1566.xml   \n","  inflating: images/train/1567.jpg   \n","  inflating: images/train/1567.xml   \n","  inflating: images/train/1568.jpg   \n","  inflating: images/train/1568.xml   \n","  inflating: images/train/1569.jpg   \n","  inflating: images/train/1569.xml   \n","  inflating: images/train/1570.jpg   \n","  inflating: images/train/1570.xml   \n","  inflating: images/train/1571.jpg   \n","  inflating: images/train/1571.xml   \n","  inflating: images/train/1572.jpg   \n","  inflating: images/train/1572.xml   \n","  inflating: images/train/1573.jpg   \n","  inflating: images/train/1573.xml   \n","  inflating: images/train/1574.jpg   \n","  inflating: images/train/1574.xml   \n","  inflating: images/train/1575.jpg   \n","  inflating: images/train/1575.xml   \n","  inflating: images/train/1576.jpg   \n","  inflating: images/train/1576.xml   \n","  inflating: images/train/1577.jpg   \n","  inflating: images/train/1577.xml   \n","  inflating: images/train/1578.jpg   \n","  inflating: images/train/1578.xml   \n","  inflating: images/train/1579.jpg   \n","  inflating: images/train/1579.xml   \n","  inflating: images/train/1580.jpg   \n","  inflating: images/train/1580.xml   \n","  inflating: images/train/1582.jpg   \n","  inflating: images/train/1582.xml   \n","  inflating: images/train/1583.jpg   \n","  inflating: images/train/1583.xml   \n","  inflating: images/train/1585.jpg   \n","  inflating: images/train/1585.xml   \n","  inflating: images/train/1586.jpg   \n","  inflating: images/train/1586.xml   \n","  inflating: images/train/1587.jpg   \n","  inflating: images/train/1587.xml   \n","  inflating: images/train/1588.jpg   \n","  inflating: images/train/1588.xml   \n","  inflating: images/train/1589.jpg   \n","  inflating: images/train/1589.xml   \n","  inflating: images/train/1595.jpg   \n","  inflating: images/train/1595.xml   \n","  inflating: images/train/1610.jpg   \n","  inflating: images/train/1610.xml   \n","  inflating: images/train/1621.jpg   \n","  inflating: images/train/1621.xml   \n","  inflating: images/train/1622.jpg   \n","  inflating: images/train/1622.xml   \n","  inflating: images/train/1630.jpg   \n","  inflating: images/train/1630.xml   \n","  inflating: images/train/1631.jpg   \n","  inflating: images/train/1631.xml   \n","  inflating: images/train/1633.jpg   \n","  inflating: images/train/1633.xml   \n","  inflating: images/train/1634.jpg   \n","  inflating: images/train/1634.xml   \n","  inflating: images/train/1637.jpg   \n","  inflating: images/train/1637.xml   \n","  inflating: images/train/1645.jpg   \n","  inflating: images/train/1645.xml   \n","  inflating: images/train/1646.jpg   \n","  inflating: images/train/1646.xml   \n","  inflating: images/train/1647.jpg   \n","  inflating: images/train/1647.xml   \n","  inflating: images/train/1648.jpg   \n","  inflating: images/train/1648.xml   \n","  inflating: images/train/1649.jpg   \n","  inflating: images/train/1649.xml   \n","  inflating: images/train/1651.jpg   \n","  inflating: images/train/1651.xml   \n","  inflating: images/train/1657.jpg   \n","  inflating: images/train/1657.xml   \n","  inflating: images/train/1658.jpg   \n","  inflating: images/train/1658.xml   \n","  inflating: images/train/1659.jpg   \n","  inflating: images/train/1659.xml   \n","  inflating: images/train/1660.jpg   \n","  inflating: images/train/1660.xml   \n","  inflating: images/train/1661.jpg   \n","  inflating: images/train/1661.xml   \n","  inflating: images/train/1663.jpg   \n","  inflating: images/train/1663.xml   \n","  inflating: images/train/1666.jpg   \n","  inflating: images/train/1666.xml   \n","  inflating: images/train/1667.jpg   \n","  inflating: images/train/1667.xml   \n","  inflating: images/train/1668.jpg   \n","  inflating: images/train/1668.xml   \n","  inflating: images/train/1671.jpg   \n","  inflating: images/train/1671.xml   \n","  inflating: images/train/1672.jpg   \n","  inflating: images/train/1672.xml   \n","  inflating: images/train/1673.jpg   \n","  inflating: images/train/1673.xml   \n","  inflating: images/train/1678.jpg   \n","  inflating: images/train/1678.xml   \n","  inflating: images/train/1681.jpg   \n","  inflating: images/train/1681.xml   \n","  inflating: images/train/1683.jpg   \n","  inflating: images/train/1683.xml   \n","  inflating: images/train/1684.jpg   \n","  inflating: images/train/1684.xml   \n","  inflating: images/train/1685.jpg   \n","  inflating: images/train/1685.xml   \n","  inflating: images/train/1688.jpg   \n","  inflating: images/train/1688.xml   \n","  inflating: images/train/1689.jpg   \n","  inflating: images/train/1689.xml   \n","  inflating: images/train/1690.jpg   \n","  inflating: images/train/1690.xml   \n","  inflating: images/train/1691.jpg   \n","  inflating: images/train/1691.xml   \n","  inflating: images/train/1693.jpg   \n","  inflating: images/train/1693.xml   \n","  inflating: images/train/1695.jpg   \n","  inflating: images/train/1695.xml   \n","  inflating: images/train/1697.jpg   \n","  inflating: images/train/1697.xml   \n","  inflating: images/train/1702.jpg   \n","  inflating: images/train/1702.xml   \n","  inflating: images/train/1706.jpg   \n","  inflating: images/train/1706.xml   \n","  inflating: images/train/1708.jpg   \n","  inflating: images/train/1708.xml   \n","  inflating: images/train/1709.jpg   \n","  inflating: images/train/1709.xml   \n","  inflating: images/train/1710.jpg   \n","  inflating: images/train/1710.xml   \n","  inflating: images/train/1711.jpg   \n","  inflating: images/train/1711.xml   \n","  inflating: images/train/1714.jpg   \n","  inflating: images/train/1714.xml   \n","  inflating: images/train/1720.jpg   \n","  inflating: images/train/1720.xml   \n","  inflating: images/train/1725.jpg   \n","  inflating: images/train/1725.xml   \n","  inflating: images/train/1726.jpg   \n","  inflating: images/train/1726.xml   \n","  inflating: images/train/1727.jpg   \n","  inflating: images/train/1727.xml   \n","  inflating: images/train/1732.jpg   \n","  inflating: images/train/1732.xml   \n","  inflating: images/train/1738.jpg   \n","  inflating: images/train/1738.xml   \n","  inflating: images/train/1739.jpg   \n","  inflating: images/train/1739.xml   \n","  inflating: images/train/1740.jpg   \n","  inflating: images/train/1740.xml   \n","  inflating: images/train/1742.jpg   \n","  inflating: images/train/1742.xml   \n","  inflating: images/train/1743.jpg   \n","  inflating: images/train/1743.xml   \n","  inflating: images/train/1745.jpg   \n","  inflating: images/train/1745.xml   \n","  inflating: images/train/1746.jpg   \n","  inflating: images/train/1746.xml   \n","  inflating: images/train/1749.jpg   \n","  inflating: images/train/1749.xml   \n","  inflating: images/train/1750.jpg   \n","  inflating: images/train/1750.xml   \n","  inflating: images/train/1755.jpg   \n","  inflating: images/train/1755.xml   \n","  inflating: images/train/1757.jpg   \n","  inflating: images/train/1757.xml   \n","  inflating: images/train/1763.jpg   \n","  inflating: images/train/1763.xml   \n","  inflating: images/train/1765.jpg   \n","  inflating: images/train/1765.xml   \n","  inflating: images/train/1767.jpg   \n","  inflating: images/train/1767.xml   \n","  inflating: images/train/1768.jpg   \n","  inflating: images/train/1768.xml   \n","  inflating: images/train/1770.jpg   \n","  inflating: images/train/1770.xml   \n","  inflating: images/train/1775.jpg   \n","  inflating: images/train/1775.xml   \n","  inflating: images/train/1781.jpg   \n","  inflating: images/train/1781.xml   \n","  inflating: images/train/1782.jpg   \n","  inflating: images/train/1782.xml   \n","  inflating: images/train/1784.jpg   \n","  inflating: images/train/1784.xml   \n","  inflating: images/train/1786.jpg   \n","  inflating: images/train/1786.xml   \n","  inflating: images/train/1791.jpg   \n","  inflating: images/train/1791.xml   \n","  inflating: images/train/1796.jpg   \n","  inflating: images/train/1796.xml   \n","  inflating: images/train/1798.jpg   \n","  inflating: images/train/1798.xml   \n","  inflating: images/train/1799.jpg   \n","  inflating: images/train/1799.xml   \n","  inflating: images/train/1800.jpg   \n","  inflating: images/train/1800.xml   \n","  inflating: images/train/1801.jpg   \n","  inflating: images/train/1801.xml   \n","  inflating: images/train/1816.jpg   \n","  inflating: images/train/1816.xml   \n","  inflating: images/train/1818.jpg   \n","  inflating: images/train/1818.xml   \n","  inflating: images/train/1820.jpg   \n","  inflating: images/train/1820.xml   \n","  inflating: images/train/1821.jpg   \n","  inflating: images/train/1821.xml   \n","  inflating: images/train/1823.jpg   \n","  inflating: images/train/1823.xml   \n","  inflating: images/train/1824.jpg   \n","  inflating: images/train/1824.xml   \n","  inflating: images/train/1825.jpg   \n","  inflating: images/train/1825.xml   \n","  inflating: images/train/1826.jpg   \n","  inflating: images/train/1826.xml   \n","  inflating: images/train/1827.jpg   \n","  inflating: images/train/1827.xml   \n","  inflating: images/train/1834.jpg   \n","  inflating: images/train/1834.xml   \n","  inflating: images/train/1835.jpg   \n","  inflating: images/train/1835.xml   \n","  inflating: images/train/1836.jpg   \n","  inflating: images/train/1836.xml   \n","  inflating: images/train/1837.jpg   \n","  inflating: images/train/1837.xml   \n","  inflating: images/train/1839.jpg   \n","  inflating: images/train/1839.xml   \n","  inflating: images/train/1840.jpg   \n","  inflating: images/train/1840.xml   \n","  inflating: images/train/1841.jpg   \n","  inflating: images/train/1841.xml   \n","  inflating: images/train/1842.jpg   \n","  inflating: images/train/1842.xml   \n","  inflating: images/train/1844.jpg   \n","  inflating: images/train/1844.xml   \n","  inflating: images/train/1846.jpg   \n","  inflating: images/train/1846.xml   \n","  inflating: images/train/1851.jpg   \n","  inflating: images/train/1851.xml   \n","  inflating: images/train/1852.jpg   \n","  inflating: images/train/1852.xml   \n","  inflating: images/train/1854.jpg   \n","  inflating: images/train/1854.xml   \n","  inflating: images/train/1855.jpg   \n","  inflating: images/train/1855.xml   \n","  inflating: images/train/1870.jpg   \n","  inflating: images/train/1870.xml   \n","  inflating: images/train/1873.jpg   \n","  inflating: images/train/1873.xml   \n","  inflating: images/train/1874.jpg   \n","  inflating: images/train/1874.xml   \n","  inflating: images/train/1885.jpg   \n","  inflating: images/train/1885.xml   \n","  inflating: images/train/1888.jpg   \n","  inflating: images/train/1888.xml   \n","  inflating: images/train/1889.jpg   \n","  inflating: images/train/1889.xml   \n","  inflating: images/train/1893.jpg   \n","  inflating: images/train/1893.xml   \n","  inflating: images/train/1898.jpg   \n","  inflating: images/train/1898.xml   \n","  inflating: images/train/1901.jpg   \n","  inflating: images/train/1901.xml   \n","  inflating: images/train/1906.jpg   \n","  inflating: images/train/1906.xml   \n","  inflating: images/train/1912.jpg   \n","  inflating: images/train/1912.xml   \n","  inflating: images/train/1917.jpg   \n","  inflating: images/train/1917.xml   \n","  inflating: images/train/1921.jpg   \n","  inflating: images/train/1921.xml   \n","  inflating: images/train/1922.jpg   \n","  inflating: images/train/1922.xml   \n","  inflating: images/train/1923.jpg   \n","  inflating: images/train/1923.xml   \n","  inflating: images/train/1936.jpg   \n","  inflating: images/train/1936.xml   \n","  inflating: images/train/1937.jpg   \n","  inflating: images/train/1937.xml   \n","  inflating: images/train/1944.jpg   \n","  inflating: images/train/1944.xml   \n","  inflating: images/train/1945.jpg   \n","  inflating: images/train/1945.xml   \n","  inflating: images/train/1954.jpg   \n","  inflating: images/train/1954.xml   \n","  inflating: images/train/1967.jpg   \n","  inflating: images/train/1967.xml   \n","  inflating: images/train/1974.jpg   \n","  inflating: images/train/1974.xml   \n","  inflating: images/train/1981.jpg   \n","  inflating: images/train/1981.xml   \n","  inflating: images/train/1993.jpg   \n","  inflating: images/train/1993.xml   \n","  inflating: images/train/2013.jpg   \n","  inflating: images/train/2013.xml   \n","  inflating: images/train/2017.jpg   \n","  inflating: images/train/2017.xml   \n","  inflating: images/train/2018.jpg   \n","  inflating: images/train/2018.xml   \n","  inflating: images/train/2029.jpg   \n","  inflating: images/train/2029.xml   \n","  inflating: images/train/2031.jpg   \n","  inflating: images/train/2031.xml   \n","  inflating: images/train/2040.jpg   \n","  inflating: images/train/2040.xml   \n","  inflating: images/train/2041.jpg   \n","  inflating: images/train/2041.xml   \n","  inflating: images/train/2044.jpg   \n","  inflating: images/train/2044.xml   \n","  inflating: images/train/2049.jpg   \n","  inflating: images/train/2049.xml   \n","  inflating: images/train/2052.jpg   \n","  inflating: images/train/2052.xml   \n","  inflating: images/train/2053.jpg   \n","  inflating: images/train/2053.xml   \n","  inflating: images/train/2063.jpg   \n","  inflating: images/train/2063.xml   \n","  inflating: images/train/2083.jpg   \n","  inflating: images/train/2083.xml   \n","  inflating: images/train/2084.jpg   \n","  inflating: images/train/2084.xml   \n","  inflating: images/train/2087.jpg   \n","  inflating: images/train/2087.xml   \n","  inflating: images/train/330.jpg    \n","  inflating: images/train/330.xml    \n","  inflating: images/train/334.jpg    \n","  inflating: images/train/334.xml    \n","  inflating: images/train/337.jpg    \n","  inflating: images/train/337.xml    \n","  inflating: images/train/338.jpg    \n","  inflating: images/train/338.xml    \n","  inflating: images/train/343.jpg    \n","  inflating: images/train/343.xml    \n","  inflating: images/train/344.jpg    \n","  inflating: images/train/344.xml    \n","  inflating: images/train/345.jpg    \n","  inflating: images/train/345.xml    \n","  inflating: images/train/347.jpg    \n","  inflating: images/train/347.xml    \n","  inflating: images/train/348.jpg    \n","  inflating: images/train/348.xml    \n","  inflating: images/train/351.jpg    \n","  inflating: images/train/351.xml    \n","  inflating: images/train/352.jpg    \n","  inflating: images/train/352.xml    \n","  inflating: images/train/355.jpg    \n","  inflating: images/train/355.xml    \n","  inflating: images/train/357.jpg    \n","  inflating: images/train/357.xml    \n","  inflating: images/train/358.jpg    \n","  inflating: images/train/358.xml    \n","  inflating: images/train/360.jpg    \n","  inflating: images/train/360.xml    \n","  inflating: images/train/367.jpg    \n","  inflating: images/train/367.xml    \n","  inflating: images/train/374.jpg    \n","  inflating: images/train/374.xml    \n","  inflating: images/train/375.jpg    \n","  inflating: images/train/375.xml    \n","  inflating: images/train/376.jpg    \n","  inflating: images/train/376.xml    \n","  inflating: images/train/379.jpg    \n","  inflating: images/train/379.xml    \n","  inflating: images/train/382.jpg    \n","  inflating: images/train/382.xml    \n","  inflating: images/train/383.jpg    \n","  inflating: images/train/383.xml    \n","  inflating: images/train/384.jpg    \n","  inflating: images/train/384.xml    \n","  inflating: images/train/385.jpg    \n","  inflating: images/train/385.xml    \n","  inflating: images/train/386.jpg    \n","  inflating: images/train/386.xml    \n","  inflating: images/train/389.jpg    \n","  inflating: images/train/389.xml    \n","  inflating: images/train/390.jpg    \n","  inflating: images/train/390.xml    \n","  inflating: images/train/391.jpg    \n","  inflating: images/train/391.xml    \n","  inflating: images/train/392.jpg    \n","  inflating: images/train/392.xml    \n","  inflating: images/train/394.jpg    \n","  inflating: images/train/394.xml    \n","  inflating: images/train/395.jpg    \n","  inflating: images/train/395.xml    \n","  inflating: images/train/396.jpg    \n","  inflating: images/train/396.xml    \n","  inflating: images/train/397.jpg    \n","  inflating: images/train/397.xml    \n","  inflating: images/train/398.jpg    \n","  inflating: images/train/398.xml    \n","  inflating: images/train/401.jpg    \n","  inflating: images/train/401.xml    \n","  inflating: images/train/402.jpg    \n","  inflating: images/train/402.xml    \n","  inflating: images/train/413.jpg    \n","  inflating: images/train/413.xml    \n","  inflating: images/train/417.jpg    \n","  inflating: images/train/417.xml    \n","  inflating: images/train/420.jpg    \n","  inflating: images/train/420.xml    \n","  inflating: images/train/434.jpg    \n","  inflating: images/train/434.xml    \n","  inflating: images/train/436.jpg    \n","  inflating: images/train/436.xml    \n","  inflating: images/train/437.jpg    \n","  inflating: images/train/437.xml    \n","  inflating: images/train/438.jpg    \n","  inflating: images/train/438.xml    \n","  inflating: images/train/441.jpg    \n","  inflating: images/train/441.xml    \n","  inflating: images/train/443.jpg    \n","  inflating: images/train/443.xml    \n","  inflating: images/train/444.jpg    \n","  inflating: images/train/444.xml    \n","  inflating: images/train/453.jpg    \n","  inflating: images/train/453.xml    \n","  inflating: images/train/465.jpg    \n","  inflating: images/train/465.xml    \n","  inflating: images/train/466.jpg    \n","  inflating: images/train/466.xml    \n","  inflating: images/train/469.jpg    \n","  inflating: images/train/469.xml    \n","  inflating: images/train/470.jpg    \n","  inflating: images/train/470.xml    \n","  inflating: images/train/475.jpg    \n","  inflating: images/train/475.xml    \n","  inflating: images/train/492.jpg    \n","  inflating: images/train/492.xml    \n","  inflating: images/train/494.jpg    \n","  inflating: images/train/494.xml    \n","  inflating: images/train/496.jpg    \n","  inflating: images/train/496.xml    \n","  inflating: images/train/497.jpg    \n","  inflating: images/train/497.xml    \n","  inflating: images/train/500.jpg    \n","  inflating: images/train/500.xml    \n","  inflating: images/train/503.jpg    \n","  inflating: images/train/503.xml    \n","  inflating: images/train/510.jpg    \n","  inflating: images/train/510.xml    \n","  inflating: images/train/512.jpg    \n","  inflating: images/train/512.xml    \n","  inflating: images/train/517.jpg    \n","  inflating: images/train/517.xml    \n","  inflating: images/train/525.jpg    \n","  inflating: images/train/525.xml    \n","  inflating: images/train/531.jpg    \n","  inflating: images/train/531.xml    \n","  inflating: images/train/533.jpg    \n","  inflating: images/train/533.xml    \n","  inflating: images/train/534.jpg    \n","  inflating: images/train/534.xml    \n","  inflating: images/train/535.jpg    \n","  inflating: images/train/535.xml    \n","  inflating: images/train/537.jpg    \n","  inflating: images/train/537.xml    \n","  inflating: images/train/538.jpg    \n","  inflating: images/train/538.xml    \n","  inflating: images/train/540.jpg    \n","  inflating: images/train/540.xml    \n","  inflating: images/train/541.jpg    \n","  inflating: images/train/541.xml    \n","  inflating: images/train/542.jpg    \n","  inflating: images/train/542.xml    \n","  inflating: images/train/543.jpg    \n","  inflating: images/train/543.xml    \n","  inflating: images/train/544.jpg    \n","  inflating: images/train/544.xml    \n","  inflating: images/train/545.jpg    \n","  inflating: images/train/545.xml    \n","  inflating: images/train/547.jpg    \n","  inflating: images/train/547.xml    \n","  inflating: images/train/549.jpg    \n","  inflating: images/train/549.xml    \n","  inflating: images/train/550.jpg    \n","  inflating: images/train/550.xml    \n","  inflating: images/train/551.jpg    \n","  inflating: images/train/551.xml    \n","  inflating: images/train/552.jpg    \n","  inflating: images/train/552.xml    \n","  inflating: images/train/554.jpg    \n","  inflating: images/train/554.xml    \n","  inflating: images/train/555.jpg    \n","  inflating: images/train/555.xml    \n","  inflating: images/train/556.jpg    \n","  inflating: images/train/556.xml    \n","  inflating: images/train/561.jpg    \n","  inflating: images/train/561.xml    \n","  inflating: images/train/562.jpg    \n","  inflating: images/train/562.xml    \n","  inflating: images/train/563.jpg    \n","  inflating: images/train/563.xml    \n","  inflating: images/train/566.jpg    \n","  inflating: images/train/566.xml    \n","  inflating: images/train/567.jpg    \n","  inflating: images/train/567.xml    \n","  inflating: images/train/572.jpg    \n","  inflating: images/train/572.xml    \n","  inflating: images/train/573.jpg    \n","  inflating: images/train/573.xml    \n","  inflating: images/train/577.jpg    \n","  inflating: images/train/577.xml    \n","  inflating: images/train/578.jpg    \n","  inflating: images/train/578.xml    \n","  inflating: images/train/579.jpg    \n","  inflating: images/train/579.xml    \n","  inflating: images/train/584.jpg    \n","  inflating: images/train/584.xml    \n","  inflating: images/train/586.jpg    \n","  inflating: images/train/586.xml    \n","  inflating: images/train/587.jpg    \n","  inflating: images/train/587.xml    \n","  inflating: images/train/588.jpg    \n","  inflating: images/train/588.xml    \n","  inflating: images/train/589.jpg    \n","  inflating: images/train/589.xml    \n","  inflating: images/train/590.jpg    \n","  inflating: images/train/590.xml    \n","  inflating: images/train/593.jpg    \n","  inflating: images/train/593.xml    \n","  inflating: images/train/594.jpg    \n","  inflating: images/train/594.xml    \n","  inflating: images/train/596.jpg    \n","  inflating: images/train/596.xml    \n","  inflating: images/train/597.jpg    \n","  inflating: images/train/597.xml    \n","  inflating: images/train/599.jpg    \n","  inflating: images/train/599.xml    \n","  inflating: images/train/600.jpg    \n","  inflating: images/train/600.xml    \n","  inflating: images/train/601.jpg    \n","  inflating: images/train/601.xml    \n","  inflating: images/train/602.jpg    \n","  inflating: images/train/602.xml    \n","  inflating: images/train/605.jpg    \n","  inflating: images/train/605.xml    \n","  inflating: images/train/608.jpg    \n","  inflating: images/train/608.xml    \n","  inflating: images/train/617.jpg    \n","  inflating: images/train/617.xml    \n","  inflating: images/train/620.jpg    \n","  inflating: images/train/620.xml    \n","  inflating: images/train/622.jpg    \n","  inflating: images/train/622.xml    \n","  inflating: images/train/623.jpg    \n","  inflating: images/train/623.xml    \n","  inflating: images/train/624.jpg    \n","  inflating: images/train/624.xml    \n","  inflating: images/train/626.jpg    \n","  inflating: images/train/626.xml    \n","  inflating: images/train/629.jpg    \n","  inflating: images/train/629.xml    \n","  inflating: images/train/630.jpg    \n","  inflating: images/train/630.xml    \n","  inflating: images/train/635.jpg    \n","  inflating: images/train/635.xml    \n","  inflating: images/train/641.jpg    \n","  inflating: images/train/641.xml    \n","  inflating: images/train/644.jpg    \n","  inflating: images/train/644.xml    \n","  inflating: images/train/648.jpg    \n","  inflating: images/train/648.xml    \n","  inflating: images/train/650.jpg    \n","  inflating: images/train/650.xml    \n","  inflating: images/train/652.jpg    \n","  inflating: images/train/652.xml    \n","  inflating: images/train/658.jpg    \n","  inflating: images/train/658.xml    \n","  inflating: images/train/661.jpg    \n","  inflating: images/train/661.xml    \n","  inflating: images/train/662.jpg    \n","  inflating: images/train/662.xml    \n","  inflating: images/train/664.jpg    \n","  inflating: images/train/664.xml    \n","  inflating: images/train/667.jpg    \n","  inflating: images/train/667.xml    \n","  inflating: images/train/668.jpg    \n","  inflating: images/train/668.xml    \n","  inflating: images/train/669.jpg    \n","  inflating: images/train/669.xml    \n","  inflating: images/train/671.jpg    \n","  inflating: images/train/671.xml    \n","  inflating: images/train/672.jpg    \n","  inflating: images/train/672.xml    \n","  inflating: images/train/674.jpg    \n","  inflating: images/train/674.xml    \n","  inflating: images/train/680.jpg    \n","  inflating: images/train/680.xml    \n","  inflating: images/train/683.jpg    \n","  inflating: images/train/683.xml    \n","  inflating: images/train/685.jpg    \n","  inflating: images/train/685.xml    \n","  inflating: images/train/686.jpg    \n","  inflating: images/train/686.xml    \n","  inflating: images/train/687.jpg    \n","  inflating: images/train/687.xml    \n","  inflating: images/train/689.jpg    \n","  inflating: images/train/689.xml    \n","  inflating: images/train/692.jpg    \n","  inflating: images/train/692.xml    \n","  inflating: images/train/695.jpg    \n","  inflating: images/train/695.xml    \n","  inflating: images/train/697.jpg    \n","  inflating: images/train/697.xml    \n","  inflating: images/train/698.jpg    \n","  inflating: images/train/698.xml    \n","  inflating: images/train/702.jpg    \n","  inflating: images/train/702.xml    \n","  inflating: images/train/705.jpg    \n","  inflating: images/train/705.xml    \n","  inflating: images/train/706.jpg    \n","  inflating: images/train/706.xml    \n","  inflating: images/train/708.jpg    \n","  inflating: images/train/708.xml    \n","  inflating: images/train/709.jpg    \n","  inflating: images/train/709.xml    \n","  inflating: images/train/711.jpg    \n","  inflating: images/train/711.xml    \n","  inflating: images/train/715.jpg    \n","  inflating: images/train/715.xml    \n","  inflating: images/train/716.jpg    \n","  inflating: images/train/716.xml    \n","  inflating: images/train/717.jpg    \n","  inflating: images/train/717.xml    \n","  inflating: images/train/720.jpg    \n","  inflating: images/train/720.xml    \n","  inflating: images/train/723.jpg    \n","  inflating: images/train/723.xml    \n","  inflating: images/train/724.jpg    \n","  inflating: images/train/724.xml    \n","  inflating: images/train/726.jpg    \n","  inflating: images/train/726.xml    \n","  inflating: images/train/728.jpg    \n","  inflating: images/train/728.xml    \n","  inflating: images/train/729.jpg    \n","  inflating: images/train/729.xml    \n","  inflating: images/train/734.jpg    \n","  inflating: images/train/734.xml    \n","  inflating: images/train/742.jpg    \n","  inflating: images/train/742.xml    \n","  inflating: images/train/743.jpg    \n","  inflating: images/train/743.xml    \n","  inflating: images/train/746.jpg    \n","  inflating: images/train/746.xml    \n","  inflating: images/train/747.jpg    \n","  inflating: images/train/747.xml    \n","  inflating: images/train/748.jpg    \n","  inflating: images/train/748.xml    \n","  inflating: images/train/758.jpg    \n","  inflating: images/train/758.xml    \n","  inflating: images/train/759.jpg    \n","  inflating: images/train/759.xml    \n","  inflating: images/train/770.jpg    \n","  inflating: images/train/770.xml    \n","  inflating: images/train/774.jpg    \n","  inflating: images/train/774.xml    \n","  inflating: images/train/782.jpg    \n","  inflating: images/train/782.xml    \n","  inflating: images/train/785.jpg    \n","  inflating: images/train/785.xml    \n","  inflating: images/train/788.jpg    \n","  inflating: images/train/788.xml    \n","  inflating: images/train/792.jpg    \n","  inflating: images/train/792.xml    \n","  inflating: images/train/794.jpg    \n","  inflating: images/train/794.xml    \n","  inflating: images/train/795.jpg    \n","  inflating: images/train/795.xml    \n","  inflating: images/train/797.jpg    \n","  inflating: images/train/797.xml    \n","  inflating: images/train/798.jpg    \n","  inflating: images/train/798.xml    \n","  inflating: images/train/799.jpg    \n","  inflating: images/train/799.xml    \n","  inflating: images/train/801.jpg    \n","  inflating: images/train/801.xml    \n","  inflating: images/train/804.jpg    \n","  inflating: images/train/804.xml    \n","  inflating: images/train/805.jpg    \n","  inflating: images/train/805.xml    \n","  inflating: images/train/806.jpg    \n","  inflating: images/train/806.xml    \n","  inflating: images/train/807.jpg    \n","  inflating: images/train/807.xml    \n","  inflating: images/train/813.jpg    \n","  inflating: images/train/813.xml    \n","  inflating: images/train/816.jpg    \n","  inflating: images/train/816.xml    \n","  inflating: images/train/822.jpg    \n","  inflating: images/train/822.xml    \n","  inflating: images/train/823.jpg    \n","  inflating: images/train/823.xml    \n","  inflating: images/train/824.jpg    \n","  inflating: images/train/824.xml    \n","  inflating: images/train/825.jpg    \n","  inflating: images/train/825.xml    \n","  inflating: images/train/828.jpg    \n","  inflating: images/train/828.xml    \n","  inflating: images/train/834.jpg    \n","  inflating: images/train/834.xml    \n","  inflating: images/train/835.jpg    \n","  inflating: images/train/835.xml    \n","  inflating: images/train/836.jpg    \n","  inflating: images/train/836.xml    \n","  inflating: images/train/841.jpg    \n","  inflating: images/train/841.xml    \n","  inflating: images/train/842.jpg    \n","  inflating: images/train/842.xml    \n","  inflating: images/train/843.jpg    \n","  inflating: images/train/843.xml    \n","  inflating: images/train/844.jpg    \n","  inflating: images/train/844.xml    \n","  inflating: images/train/845.jpg    \n","  inflating: images/train/845.xml    \n","  inflating: images/train/846.jpg    \n","  inflating: images/train/846.xml    \n","  inflating: images/train/849.jpg    \n","  inflating: images/train/849.xml    \n","  inflating: images/train/850.jpg    \n","  inflating: images/train/850.xml    \n","  inflating: images/train/851.jpg    \n","  inflating: images/train/851.xml    \n","  inflating: images/train/852.jpg    \n","  inflating: images/train/852.xml    \n","  inflating: images/train/855.jpg    \n","  inflating: images/train/855.xml    \n","  inflating: images/train/856.jpg    \n","  inflating: images/train/856.xml    \n","  inflating: images/train/860.jpg    \n","  inflating: images/train/860.xml    \n","  inflating: images/train/861.jpg    \n","  inflating: images/train/861.xml    \n","  inflating: images/train/862.jpg    \n","  inflating: images/train/862.xml    \n","  inflating: images/train/863.jpg    \n","  inflating: images/train/863.xml    \n","  inflating: images/train/865.jpg    \n","  inflating: images/train/865.xml    \n","  inflating: images/train/866.jpg    \n","  inflating: images/train/866.xml    \n","  inflating: images/train/867.jpg    \n","  inflating: images/train/867.xml    \n","  inflating: images/train/868.jpg    \n","  inflating: images/train/868.xml    \n","  inflating: images/train/870.jpg    \n","  inflating: images/train/870.xml    \n","  inflating: images/train/873.jpg    \n","  inflating: images/train/873.xml    \n","  inflating: images/train/876.jpg    \n","  inflating: images/train/876.xml    \n","  inflating: images/train/884.jpg    \n","  inflating: images/train/884.xml    \n","  inflating: images/train/885.jpg    \n","  inflating: images/train/885.xml    \n","  inflating: images/train/888.jpg    \n","  inflating: images/train/888.xml    \n","  inflating: images/train/891.jpg    \n","  inflating: images/train/891.xml    \n","  inflating: images/train/896.jpg    \n","  inflating: images/train/896.xml    \n","  inflating: images/train/900.jpg    \n","  inflating: images/train/900.xml    \n","  inflating: images/train/906.jpg    \n","  inflating: images/train/906.xml    \n","  inflating: images/train/907.jpg    \n","  inflating: images/train/907.xml    \n","  inflating: images/train/908.jpg    \n","  inflating: images/train/908.xml    \n","  inflating: images/train/909.jpg    \n","  inflating: images/train/909.xml    \n","  inflating: images/train/928.jpg    \n","  inflating: images/train/928.xml    \n","  inflating: images/train/930.jpg    \n","  inflating: images/train/930.xml    \n","  inflating: images/train/937.jpg    \n","  inflating: images/train/937.xml    \n","  inflating: images/train/943.jpg    \n","  inflating: images/train/943.xml    \n","  inflating: images/train/944.jpg    \n","  inflating: images/train/944.xml    \n","  inflating: images/train/945.jpg    \n","  inflating: images/train/945.xml    \n","  inflating: images/train/949.jpg    \n","  inflating: images/train/949.xml    \n","  inflating: images/train/954.jpg    \n","  inflating: images/train/954.xml    \n","  inflating: images/train/955.jpg    \n","  inflating: images/train/955.xml    \n","  inflating: images/train/956.jpg    \n","  inflating: images/train/956.xml    \n","  inflating: images/train/958.jpg    \n","  inflating: images/train/958.xml    \n","  inflating: images/train/960.jpg    \n","  inflating: images/train/960.xml    \n","  inflating: images/train/963.jpg    \n","  inflating: images/train/963.xml    \n","  inflating: images/train/964.jpg    \n","  inflating: images/train/964.xml    \n","  inflating: images/train/965.jpg    \n","  inflating: images/train/965.xml    \n","  inflating: images/train/966.jpg    \n","  inflating: images/train/966.xml    \n","  inflating: images/train/970.jpg    \n","  inflating: images/train/970.xml    \n","  inflating: images/train/971.jpg    \n","  inflating: images/train/971.xml    \n","  inflating: images/train/976.jpg    \n","  inflating: images/train/976.xml    \n","  inflating: images/train/977.jpg    \n","  inflating: images/train/977.xml    \n","  inflating: images/train/981.jpg    \n","  inflating: images/train/981.xml    \n","  inflating: images/train/982.jpg    \n","  inflating: images/train/982.xml    \n","  inflating: images/train/983.jpg    \n","  inflating: images/train/983.xml    \n","  inflating: images/train/984.jpg    \n","  inflating: images/train/984.xml    \n","  inflating: images/train/988.jpg    \n","  inflating: images/train/988.xml    \n","  inflating: images/train/993.jpg    \n","  inflating: images/train/993.xml    \n","  inflating: images/train/994.jpg    \n","  inflating: images/train/994.xml    \n","  inflating: images/train/997.jpg    \n","  inflating: images/train/997.xml    \n","  inflating: images/train/998.jpg    \n","  inflating: images/train/998.xml    \n","  inflating: images/train/999.jpg    \n","  inflating: images/train/999.xml    \n","  inflating: images/train_labels.csv  \n","  inflating: images/training/faster_rcnn_inception_v2_pets.config  \n","  inflating: images/training/graph.pbtxt  \n","  inflating: images/training/labelmap.pbtxt  \n","  inflating: images/training/pipeline.config  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S1zdTbqf8XS8","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4wCSQ0XY9opM","colab_type":"code","colab":{}},"source":["LOG_DIR = 'training'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","# Install\n","! npm install -g localtunnel\n","! npm i -g npm\n","# Tunnel port 6006 (TensorBoard assumed running)\n","get_ipython().system_raw('lt --port 6006 >> url1.txt 2>&1 &')\n","# Get url\n","! cat url1.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZubGYv2CK3r","colab_type":"code","colab":{}},"source":["! npm i -g npm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WcpLANPoRJ7","colab_type":"code","colab":{}},"source":["!cp ssd_mobilenet_v2_coco_2018_03_29/pipeline.config ./training"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qlDoKlkqM58j","colab_type":"code","colab":{}},"source":["#!cp /mydrive/faster/final/final.zip ./"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1C0ges92NDMf","colab_type":"code","colab":{}},"source":["#!unzip final.zip -d ./images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDr6TA7WxAha","colab_type":"code","colab":{}},"source":["#!cp -r /mydrive/faster/final/training ./"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jG-2Gy0CO-0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591884794273,"user_tz":-330,"elapsed":2675732,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"74d03c75-e5d3-4070-c1cb-04cf19ca052e"},"source":["!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:375: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:399: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From train.py:55: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From train.py:55: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","WARNING:tensorflow:From train.py:184: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use object_detection/model_main.py.\n","W0611 13:28:46.155520 140666084398976 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use object_detection/model_main.py.\n","WARNING:tensorflow:From train.py:90: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0611 13:28:46.155854 140666084398976 module_wrapper.py:139] From train.py:90: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0611 13:28:46.156216 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From train.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n","\n","W0611 13:28:46.161718 140666084398976 module_wrapper.py:139] From train.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.create_global_step\n","W0611 13:28:46.184486 140666084398976 deprecation.py:323] From /content/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.create_global_step\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0611 13:28:46.205061 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0611 13:28:46.205333 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0611 13:28:46.219986 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0611 13:28:46.222606 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0611 13:28:46.222804 140666084398976 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0611 13:28:46.231435 140666084398976 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0611 13:28:46.231632 140666084398976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0611 13:28:46.274416 140666084398976 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7feefa63d048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","W0611 13:28:46.309567 140666084398976 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7feefa63d048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n","W0611 13:28:46.542320 140666084398976 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0611 13:28:46.550202 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0611 13:28:46.557097 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n","W0611 13:28:46.613464 140666084398976 deprecation.py:323] From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0611 13:28:46.618041 140666084398976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0611 13:28:46.619327 140666084398976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n","\n","W0611 13:28:46.625058 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0611 13:28:46.628568 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","W0611 13:28:46.631892 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0611 13:28:46.632260 140666084398976 module_wrapper.py:139] From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","W0611 13:28:46.632479 140666084398976 module_wrapper.py:139] From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0611 13:28:47.200881 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0611 13:28:47.586313 140666084398976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0611 13:28:49.515566 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0611 13:28:49.524185 140666084398976 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0611 13:28:49.542784 140666084398976 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0611 13:28:49.543156 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0611 13:28:49.543313 140666084398976 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:174: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0611 13:28:49.592767 140666084398976 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:174: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0611 13:28:50.688782 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","W0611 13:28:50.741604 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","W0611 13:28:55.669012 140666084398976 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","W0611 13:28:55.707196 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","W0611 13:28:56.319761 140666084398976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0611 13:28:56.322591 140666084398976 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0611 13:28:56.342372 140666084398976 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0611 13:29:00.910433 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0611 13:29:00.911953 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0611 13:29:00.967304 140666084398976 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n","\n","W0611 13:29:03.498072 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0611 13:29:03.498700 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","W0611 13:29:03.507798 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n","\n","W0611 13:29:09.162000 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n","\n","W0611 13:29:12.758613 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n","\n","W0611 13:29:13.171432 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n","\n","W0611 13:29:13.176552 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","W0611 13:29:13.180168 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0611 13:29:13.188642 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0611 13:29:13.188915 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","W0611 13:29:13.718462 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0611 13:29:13.718863 140666084398976 deprecation.py:323] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0611 13:29:13.722077 140666084398976 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.MonitoredTrainingSession\n","W0611 13:29:14.667962 140666084398976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.MonitoredTrainingSession\n","2020-06-11 13:29:16.478375: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-06-11 13:29:16.478618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cccd100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-06-11 13:29:16.478688: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-06-11 13:29:16.481863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-06-11 13:29:16.535203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-11 13:29:16.536206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cccd2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-06-11 13:29:16.536237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-06-11 13:29:16.536458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-11 13:29:16.537112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-06-11 13:29:16.537414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-11 13:29:16.554024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-06-11 13:29:16.560489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-06-11 13:29:16.568025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-06-11 13:29:16.581635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-06-11 13:29:16.586242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-06-11 13:29:16.602292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-11 13:29:16.602460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-11 13:29:16.603328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-11 13:29:16.604014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-06-11 13:29:16.604098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-06-11 13:29:16.605620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-06-11 13:29:16.605667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-06-11 13:29:16.605693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-06-11 13:29:16.605826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-11 13:29:16.606555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-06-11 13:29:16.607205: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-06-11 13:29:16.607261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10748 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-199277\n","I0611 13:29:16.610315 140666084398976 saver.py:1284] Restoring parameters from training/model.ckpt-199277\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","W0611 13:29:18.757156 140666084398976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","INFO:tensorflow:Running local_init_op.\n","I0611 13:29:18.762973 140666084398976 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0611 13:29:19.575815 140666084398976 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Starting Session.\n","I0611 13:29:32.974861 140666084398976 learning.py:754] Starting Session.\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I0611 13:29:33.573468 140662755038976 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:Starting Queues.\n","I0611 13:29:33.579726 140666084398976 learning.py:768] Starting Queues.\n","2020-06-11 13:29:42.694157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","INFO:tensorflow:global_step/sec: 0\n","I0611 13:29:59.271948 140662746646272 supervisor.py:1099] global_step/sec: 0\n","2020-06-11 13:29:59.607973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-06-11 13:30:04.518405: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:04.556587: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:06.220312: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:06.295741: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:06.424848: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:06.797681: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:06.861277: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:07.041863: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:07.094070: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","2020-06-11 13:30:07.977341: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.63GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","INFO:tensorflow:Recording summary at step 199277.\n","I0611 13:30:15.522185 140662738253568 supervisor.py:1050] Recording summary at step 199277.\n","2020-06-11 13:30:22.870387: W tensorflow/core/common_runtime/bfc_allocator.cc:305] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n","INFO:tensorflow:global step 199278: loss = 0.0312 (50.727 sec/step)\n","I0611 13:30:24.992816 140666084398976 learning.py:507] global step 199278: loss = 0.0312 (50.727 sec/step)\n","INFO:tensorflow:global step 199279: loss = 0.0302 (3.552 sec/step)\n","I0611 13:30:29.187307 140666084398976 learning.py:507] global step 199279: loss = 0.0302 (3.552 sec/step)\n","INFO:tensorflow:global step 199280: loss = 0.0356 (3.543 sec/step)\n","I0611 13:30:32.732030 140666084398976 learning.py:507] global step 199280: loss = 0.0356 (3.543 sec/step)\n","INFO:tensorflow:global step 199281: loss = 0.0321 (3.521 sec/step)\n","I0611 13:30:36.254835 140666084398976 learning.py:507] global step 199281: loss = 0.0321 (3.521 sec/step)\n","INFO:tensorflow:global step 199282: loss = 0.0337 (3.510 sec/step)\n","I0611 13:30:39.766258 140666084398976 learning.py:507] global step 199282: loss = 0.0337 (3.510 sec/step)\n","INFO:tensorflow:global step 199283: loss = 0.0425 (3.505 sec/step)\n","I0611 13:30:43.273332 140666084398976 learning.py:507] global step 199283: loss = 0.0425 (3.505 sec/step)\n","INFO:tensorflow:global step 199284: loss = 0.0666 (3.554 sec/step)\n","I0611 13:30:46.829057 140666084398976 learning.py:507] global step 199284: loss = 0.0666 (3.554 sec/step)\n","INFO:tensorflow:global step 199285: loss = 0.0334 (3.482 sec/step)\n","I0611 13:30:50.312772 140666084398976 learning.py:507] global step 199285: loss = 0.0334 (3.482 sec/step)\n","INFO:tensorflow:global step 199286: loss = 0.0450 (3.500 sec/step)\n","I0611 13:30:53.814795 140666084398976 learning.py:507] global step 199286: loss = 0.0450 (3.500 sec/step)\n","INFO:tensorflow:global step 199287: loss = 0.0279 (3.532 sec/step)\n","I0611 13:30:57.348677 140666084398976 learning.py:507] global step 199287: loss = 0.0279 (3.532 sec/step)\n","INFO:tensorflow:global step 199288: loss = 0.0372 (3.560 sec/step)\n","I0611 13:31:00.910131 140666084398976 learning.py:507] global step 199288: loss = 0.0372 (3.560 sec/step)\n","INFO:tensorflow:global step 199289: loss = 0.0455 (3.554 sec/step)\n","I0611 13:31:04.466537 140666084398976 learning.py:507] global step 199289: loss = 0.0455 (3.554 sec/step)\n","INFO:tensorflow:global step 199290: loss = 0.0319 (3.475 sec/step)\n","I0611 13:31:07.943711 140666084398976 learning.py:507] global step 199290: loss = 0.0319 (3.475 sec/step)\n","INFO:tensorflow:global step 199291: loss = 0.0337 (3.552 sec/step)\n","I0611 13:31:11.497706 140666084398976 learning.py:507] global step 199291: loss = 0.0337 (3.552 sec/step)\n","INFO:tensorflow:global step 199292: loss = 0.0366 (3.519 sec/step)\n","I0611 13:31:15.018012 140666084398976 learning.py:507] global step 199292: loss = 0.0366 (3.519 sec/step)\n","INFO:tensorflow:global step 199293: loss = 0.0251 (3.536 sec/step)\n","I0611 13:31:18.556077 140666084398976 learning.py:507] global step 199293: loss = 0.0251 (3.536 sec/step)\n","INFO:tensorflow:global step 199294: loss = 0.0291 (3.605 sec/step)\n","I0611 13:31:22.163408 140666084398976 learning.py:507] global step 199294: loss = 0.0291 (3.605 sec/step)\n","INFO:tensorflow:global step 199295: loss = 0.0298 (3.502 sec/step)\n","I0611 13:31:25.667709 140666084398976 learning.py:507] global step 199295: loss = 0.0298 (3.502 sec/step)\n","INFO:tensorflow:global step 199296: loss = 0.0341 (3.552 sec/step)\n","I0611 13:31:29.221163 140666084398976 learning.py:507] global step 199296: loss = 0.0341 (3.552 sec/step)\n","INFO:tensorflow:global step 199297: loss = 0.0388 (3.543 sec/step)\n","I0611 13:31:32.765851 140666084398976 learning.py:507] global step 199297: loss = 0.0388 (3.543 sec/step)\n","INFO:tensorflow:global step 199298: loss = 0.0376 (3.896 sec/step)\n","I0611 13:31:36.664436 140666084398976 learning.py:507] global step 199298: loss = 0.0376 (3.896 sec/step)\n","INFO:tensorflow:Recording summary at step 199298.\n","I0611 13:31:38.657429 140662738253568 supervisor.py:1050] Recording summary at step 199298.\n","INFO:tensorflow:global step 199299: loss = 0.0360 (4.488 sec/step)\n","I0611 13:31:41.167135 140666084398976 learning.py:507] global step 199299: loss = 0.0360 (4.488 sec/step)\n","INFO:tensorflow:global_step/sec: 0.21395\n","I0611 13:31:42.099919 140662746646272 supervisor.py:1099] global_step/sec: 0.21395\n","INFO:tensorflow:global step 199300: loss = 0.0392 (3.493 sec/step)\n","I0611 13:31:44.662692 140666084398976 learning.py:507] global step 199300: loss = 0.0392 (3.493 sec/step)\n","INFO:tensorflow:global step 199301: loss = 0.0337 (3.441 sec/step)\n","I0611 13:31:48.105298 140666084398976 learning.py:507] global step 199301: loss = 0.0337 (3.441 sec/step)\n","INFO:tensorflow:global step 199302: loss = 0.0363 (3.543 sec/step)\n","I0611 13:31:51.650578 140666084398976 learning.py:507] global step 199302: loss = 0.0363 (3.543 sec/step)\n","INFO:tensorflow:global step 199303: loss = 0.0322 (3.679 sec/step)\n","I0611 13:31:55.332024 140666084398976 learning.py:507] global step 199303: loss = 0.0322 (3.679 sec/step)\n","INFO:tensorflow:global step 199304: loss = 0.0281 (3.486 sec/step)\n","I0611 13:31:58.823469 140666084398976 learning.py:507] global step 199304: loss = 0.0281 (3.486 sec/step)\n","INFO:tensorflow:global step 199305: loss = 0.0393 (3.502 sec/step)\n","I0611 13:32:02.326989 140666084398976 learning.py:507] global step 199305: loss = 0.0393 (3.502 sec/step)\n","INFO:tensorflow:global step 199306: loss = 0.0262 (3.572 sec/step)\n","I0611 13:32:05.900817 140666084398976 learning.py:507] global step 199306: loss = 0.0262 (3.572 sec/step)\n","INFO:tensorflow:global step 199307: loss = 0.0322 (3.462 sec/step)\n","I0611 13:32:09.364895 140666084398976 learning.py:507] global step 199307: loss = 0.0322 (3.462 sec/step)\n","INFO:tensorflow:global step 199308: loss = 0.0411 (3.479 sec/step)\n","I0611 13:32:12.846312 140666084398976 learning.py:507] global step 199308: loss = 0.0411 (3.479 sec/step)\n","INFO:tensorflow:global step 199309: loss = 0.0284 (3.444 sec/step)\n","I0611 13:32:16.292324 140666084398976 learning.py:507] global step 199309: loss = 0.0284 (3.444 sec/step)\n","INFO:tensorflow:global step 199310: loss = 0.0434 (3.470 sec/step)\n","I0611 13:32:19.764113 140666084398976 learning.py:507] global step 199310: loss = 0.0434 (3.470 sec/step)\n","INFO:tensorflow:global step 199311: loss = 0.0410 (3.486 sec/step)\n","I0611 13:32:23.251779 140666084398976 learning.py:507] global step 199311: loss = 0.0410 (3.486 sec/step)\n","INFO:tensorflow:global step 199312: loss = 0.0402 (3.484 sec/step)\n","I0611 13:32:26.737440 140666084398976 learning.py:507] global step 199312: loss = 0.0402 (3.484 sec/step)\n","INFO:tensorflow:global step 199313: loss = 0.0190 (3.474 sec/step)\n","I0611 13:32:30.213438 140666084398976 learning.py:507] global step 199313: loss = 0.0190 (3.474 sec/step)\n","INFO:tensorflow:global step 199314: loss = 0.0503 (3.522 sec/step)\n","I0611 13:32:33.737230 140666084398976 learning.py:507] global step 199314: loss = 0.0503 (3.522 sec/step)\n","INFO:tensorflow:global step 199315: loss = 0.0350 (3.437 sec/step)\n","I0611 13:32:37.175939 140666084398976 learning.py:507] global step 199315: loss = 0.0350 (3.437 sec/step)\n","INFO:tensorflow:global step 199316: loss = 0.0547 (3.508 sec/step)\n","I0611 13:32:40.686584 140666084398976 learning.py:507] global step 199316: loss = 0.0547 (3.508 sec/step)\n","INFO:tensorflow:global step 199317: loss = 0.0381 (3.411 sec/step)\n","I0611 13:32:44.100229 140666084398976 learning.py:507] global step 199317: loss = 0.0381 (3.411 sec/step)\n","INFO:tensorflow:global step 199318: loss = 0.0353 (3.566 sec/step)\n","I0611 13:32:47.668180 140666084398976 learning.py:507] global step 199318: loss = 0.0353 (3.566 sec/step)\n","INFO:tensorflow:global step 199319: loss = 0.0314 (3.475 sec/step)\n","I0611 13:32:51.145205 140666084398976 learning.py:507] global step 199319: loss = 0.0314 (3.475 sec/step)\n","INFO:tensorflow:global step 199320: loss = 0.0299 (3.472 sec/step)\n","I0611 13:32:54.618777 140666084398976 learning.py:507] global step 199320: loss = 0.0299 (3.472 sec/step)\n","INFO:tensorflow:global step 199321: loss = 0.0310 (3.442 sec/step)\n","I0611 13:32:58.062901 140666084398976 learning.py:507] global step 199321: loss = 0.0310 (3.442 sec/step)\n","INFO:tensorflow:global step 199322: loss = 0.0315 (3.522 sec/step)\n","I0611 13:33:01.586610 140666084398976 learning.py:507] global step 199322: loss = 0.0315 (3.522 sec/step)\n","INFO:tensorflow:global step 199323: loss = 0.0390 (3.522 sec/step)\n","I0611 13:33:05.110297 140666084398976 learning.py:507] global step 199323: loss = 0.0390 (3.522 sec/step)\n","INFO:tensorflow:global step 199324: loss = 0.0423 (3.494 sec/step)\n","I0611 13:33:08.606456 140666084398976 learning.py:507] global step 199324: loss = 0.0423 (3.494 sec/step)\n","INFO:tensorflow:global step 199325: loss = 0.0255 (3.525 sec/step)\n","I0611 13:33:12.132866 140666084398976 learning.py:507] global step 199325: loss = 0.0255 (3.525 sec/step)\n","INFO:tensorflow:global step 199326: loss = 0.0257 (3.501 sec/step)\n","I0611 13:33:15.635575 140666084398976 learning.py:507] global step 199326: loss = 0.0257 (3.501 sec/step)\n","INFO:tensorflow:global step 199327: loss = 0.0481 (3.545 sec/step)\n","I0611 13:33:19.182327 140666084398976 learning.py:507] global step 199327: loss = 0.0481 (3.545 sec/step)\n","INFO:tensorflow:global step 199328: loss = 0.0214 (3.474 sec/step)\n","I0611 13:33:22.658198 140666084398976 learning.py:507] global step 199328: loss = 0.0214 (3.474 sec/step)\n","INFO:tensorflow:global step 199329: loss = 0.0183 (3.419 sec/step)\n","I0611 13:33:26.078966 140666084398976 learning.py:507] global step 199329: loss = 0.0183 (3.419 sec/step)\n","INFO:tensorflow:global step 199330: loss = 0.0472 (3.539 sec/step)\n","I0611 13:33:29.619520 140666084398976 learning.py:507] global step 199330: loss = 0.0472 (3.539 sec/step)\n","INFO:tensorflow:global step 199331: loss = 0.0317 (3.504 sec/step)\n","I0611 13:33:33.127682 140666084398976 learning.py:507] global step 199331: loss = 0.0317 (3.504 sec/step)\n","INFO:tensorflow:global step 199332: loss = 0.0194 (3.882 sec/step)\n","I0611 13:33:37.337010 140666084398976 learning.py:507] global step 199332: loss = 0.0194 (3.882 sec/step)\n","INFO:tensorflow:Recording summary at step 199332.\n","I0611 13:33:38.798507 140662738253568 supervisor.py:1050] Recording summary at step 199332.\n","INFO:tensorflow:global step 199333: loss = 0.0321 (3.962 sec/step)\n","I0611 13:33:41.308033 140666084398976 learning.py:507] global step 199333: loss = 0.0321 (3.962 sec/step)\n","INFO:tensorflow:global_step/sec: 0.283335\n","I0611 13:33:42.098850 140662746646272 supervisor.py:1099] global_step/sec: 0.283335\n","INFO:tensorflow:global step 199334: loss = 0.0422 (3.501 sec/step)\n","I0611 13:33:44.811265 140666084398976 learning.py:507] global step 199334: loss = 0.0422 (3.501 sec/step)\n","INFO:tensorflow:global step 199335: loss = 0.0323 (3.479 sec/step)\n","I0611 13:33:48.292631 140666084398976 learning.py:507] global step 199335: loss = 0.0323 (3.479 sec/step)\n","INFO:tensorflow:global step 199336: loss = 0.0259 (3.487 sec/step)\n","I0611 13:33:51.782083 140666084398976 learning.py:507] global step 199336: loss = 0.0259 (3.487 sec/step)\n","INFO:tensorflow:global step 199337: loss = 0.0404 (3.484 sec/step)\n","I0611 13:33:55.268078 140666084398976 learning.py:507] global step 199337: loss = 0.0404 (3.484 sec/step)\n","INFO:tensorflow:global step 199338: loss = 0.0297 (3.557 sec/step)\n","I0611 13:33:58.828092 140666084398976 learning.py:507] global step 199338: loss = 0.0297 (3.557 sec/step)\n","INFO:tensorflow:global step 199339: loss = 0.0248 (3.529 sec/step)\n","I0611 13:34:02.358326 140666084398976 learning.py:507] global step 199339: loss = 0.0248 (3.529 sec/step)\n","INFO:tensorflow:global step 199340: loss = 0.0365 (3.549 sec/step)\n","I0611 13:34:05.908717 140666084398976 learning.py:507] global step 199340: loss = 0.0365 (3.549 sec/step)\n","INFO:tensorflow:global step 199341: loss = 0.0357 (3.518 sec/step)\n","I0611 13:34:09.428444 140666084398976 learning.py:507] global step 199341: loss = 0.0357 (3.518 sec/step)\n","INFO:tensorflow:global step 199342: loss = 0.0362 (3.451 sec/step)\n","I0611 13:34:12.881147 140666084398976 learning.py:507] global step 199342: loss = 0.0362 (3.451 sec/step)\n","INFO:tensorflow:global step 199343: loss = 0.0257 (3.468 sec/step)\n","I0611 13:34:16.353756 140666084398976 learning.py:507] global step 199343: loss = 0.0257 (3.468 sec/step)\n","INFO:tensorflow:global step 199344: loss = 0.0399 (3.534 sec/step)\n","I0611 13:34:19.889415 140666084398976 learning.py:507] global step 199344: loss = 0.0399 (3.534 sec/step)\n","INFO:tensorflow:global step 199345: loss = 0.0265 (3.490 sec/step)\n","I0611 13:34:23.381510 140666084398976 learning.py:507] global step 199345: loss = 0.0265 (3.490 sec/step)\n","INFO:tensorflow:global step 199346: loss = 0.0315 (3.527 sec/step)\n","I0611 13:34:26.910069 140666084398976 learning.py:507] global step 199346: loss = 0.0315 (3.527 sec/step)\n","INFO:tensorflow:global step 199347: loss = 0.0491 (3.543 sec/step)\n","I0611 13:34:30.454286 140666084398976 learning.py:507] global step 199347: loss = 0.0491 (3.543 sec/step)\n","INFO:tensorflow:global step 199348: loss = 0.0464 (3.430 sec/step)\n","I0611 13:34:33.886923 140666084398976 learning.py:507] global step 199348: loss = 0.0464 (3.430 sec/step)\n","INFO:tensorflow:global step 199349: loss = 0.0475 (3.443 sec/step)\n","I0611 13:34:37.331980 140666084398976 learning.py:507] global step 199349: loss = 0.0475 (3.443 sec/step)\n","INFO:tensorflow:global step 199350: loss = 0.0369 (3.549 sec/step)\n","I0611 13:34:40.882989 140666084398976 learning.py:507] global step 199350: loss = 0.0369 (3.549 sec/step)\n","INFO:tensorflow:global step 199351: loss = 0.0386 (3.486 sec/step)\n","I0611 13:34:44.371200 140666084398976 learning.py:507] global step 199351: loss = 0.0386 (3.486 sec/step)\n","INFO:tensorflow:global step 199352: loss = 0.0270 (3.556 sec/step)\n","I0611 13:34:47.929768 140666084398976 learning.py:507] global step 199352: loss = 0.0270 (3.556 sec/step)\n","INFO:tensorflow:global step 199353: loss = 0.0295 (3.435 sec/step)\n","I0611 13:34:51.366561 140666084398976 learning.py:507] global step 199353: loss = 0.0295 (3.435 sec/step)\n","INFO:tensorflow:global step 199354: loss = 0.0251 (3.483 sec/step)\n","I0611 13:34:54.851865 140666084398976 learning.py:507] global step 199354: loss = 0.0251 (3.483 sec/step)\n","INFO:tensorflow:global step 199355: loss = 0.0371 (3.508 sec/step)\n","I0611 13:34:58.361437 140666084398976 learning.py:507] global step 199355: loss = 0.0371 (3.508 sec/step)\n","INFO:tensorflow:global step 199356: loss = 0.0459 (3.469 sec/step)\n","I0611 13:35:01.831771 140666084398976 learning.py:507] global step 199356: loss = 0.0459 (3.469 sec/step)\n","INFO:tensorflow:global step 199357: loss = 0.0351 (3.498 sec/step)\n","I0611 13:35:05.331750 140666084398976 learning.py:507] global step 199357: loss = 0.0351 (3.498 sec/step)\n","INFO:tensorflow:global step 199358: loss = 0.0379 (3.498 sec/step)\n","I0611 13:35:08.831103 140666084398976 learning.py:507] global step 199358: loss = 0.0379 (3.498 sec/step)\n","INFO:tensorflow:global step 199359: loss = 0.0351 (3.439 sec/step)\n","I0611 13:35:12.271564 140666084398976 learning.py:507] global step 199359: loss = 0.0351 (3.439 sec/step)\n","INFO:tensorflow:global step 199360: loss = 0.0374 (3.423 sec/step)\n","I0611 13:35:15.695996 140666084398976 learning.py:507] global step 199360: loss = 0.0374 (3.423 sec/step)\n","INFO:tensorflow:global step 199361: loss = 0.0329 (3.491 sec/step)\n","I0611 13:35:19.189081 140666084398976 learning.py:507] global step 199361: loss = 0.0329 (3.491 sec/step)\n","INFO:tensorflow:global step 199362: loss = 0.0381 (3.519 sec/step)\n","I0611 13:35:22.709861 140666084398976 learning.py:507] global step 199362: loss = 0.0381 (3.519 sec/step)\n","INFO:tensorflow:global step 199363: loss = 0.0239 (3.508 sec/step)\n","I0611 13:35:26.219135 140666084398976 learning.py:507] global step 199363: loss = 0.0239 (3.508 sec/step)\n","INFO:tensorflow:global step 199364: loss = 0.0326 (3.528 sec/step)\n","I0611 13:35:29.748741 140666084398976 learning.py:507] global step 199364: loss = 0.0326 (3.528 sec/step)\n","INFO:tensorflow:global step 199365: loss = 0.0331 (3.537 sec/step)\n","I0611 13:35:33.287161 140666084398976 learning.py:507] global step 199365: loss = 0.0331 (3.537 sec/step)\n","INFO:tensorflow:global step 199366: loss = 0.0401 (3.928 sec/step)\n","I0611 13:35:37.216857 140666084398976 learning.py:507] global step 199366: loss = 0.0401 (3.928 sec/step)\n","INFO:tensorflow:global step 199367: loss = 0.0308 (4.199 sec/step)\n","I0611 13:35:41.439508 140666084398976 learning.py:507] global step 199367: loss = 0.0308 (4.199 sec/step)\n","INFO:tensorflow:Recording summary at step 199367.\n","I0611 13:35:41.715503 140662738253568 supervisor.py:1050] Recording summary at step 199367.\n","INFO:tensorflow:global_step/sec: 0.283333\n","I0611 13:35:42.098949 140662746646272 supervisor.py:1099] global_step/sec: 0.283333\n","INFO:tensorflow:global step 199368: loss = 0.0325 (3.773 sec/step)\n","I0611 13:35:45.215294 140666084398976 learning.py:507] global step 199368: loss = 0.0325 (3.773 sec/step)\n","INFO:tensorflow:global step 199369: loss = 0.0313 (3.480 sec/step)\n","I0611 13:35:48.697482 140666084398976 learning.py:507] global step 199369: loss = 0.0313 (3.480 sec/step)\n","INFO:tensorflow:global step 199370: loss = 0.0210 (3.492 sec/step)\n","I0611 13:35:52.190977 140666084398976 learning.py:507] global step 199370: loss = 0.0210 (3.492 sec/step)\n","INFO:tensorflow:global step 199371: loss = 0.0370 (3.530 sec/step)\n","I0611 13:35:55.722642 140666084398976 learning.py:507] global step 199371: loss = 0.0370 (3.530 sec/step)\n","INFO:tensorflow:global step 199372: loss = 0.0263 (3.480 sec/step)\n","I0611 13:35:59.204046 140666084398976 learning.py:507] global step 199372: loss = 0.0263 (3.480 sec/step)\n","INFO:tensorflow:global step 199373: loss = 0.0419 (3.471 sec/step)\n","I0611 13:36:02.677249 140666084398976 learning.py:507] global step 199373: loss = 0.0419 (3.471 sec/step)\n","INFO:tensorflow:global step 199374: loss = 0.0310 (3.479 sec/step)\n","I0611 13:36:06.157995 140666084398976 learning.py:507] global step 199374: loss = 0.0310 (3.479 sec/step)\n","INFO:tensorflow:global step 199375: loss = 0.0259 (3.493 sec/step)\n","I0611 13:36:09.653220 140666084398976 learning.py:507] global step 199375: loss = 0.0259 (3.493 sec/step)\n","INFO:tensorflow:global step 199376: loss = 0.0533 (3.532 sec/step)\n","I0611 13:36:13.186803 140666084398976 learning.py:507] global step 199376: loss = 0.0533 (3.532 sec/step)\n","INFO:tensorflow:global step 199377: loss = 0.0352 (3.514 sec/step)\n","I0611 13:36:16.702371 140666084398976 learning.py:507] global step 199377: loss = 0.0352 (3.514 sec/step)\n","INFO:tensorflow:global step 199378: loss = 0.0267 (3.486 sec/step)\n","I0611 13:36:20.189915 140666084398976 learning.py:507] global step 199378: loss = 0.0267 (3.486 sec/step)\n","INFO:tensorflow:global step 199379: loss = 0.0311 (3.485 sec/step)\n","I0611 13:36:23.677002 140666084398976 learning.py:507] global step 199379: loss = 0.0311 (3.485 sec/step)\n","INFO:tensorflow:global step 199380: loss = 0.0316 (3.442 sec/step)\n","I0611 13:36:27.120712 140666084398976 learning.py:507] global step 199380: loss = 0.0316 (3.442 sec/step)\n","INFO:tensorflow:global step 199381: loss = 0.0348 (3.475 sec/step)\n","I0611 13:36:30.597696 140666084398976 learning.py:507] global step 199381: loss = 0.0348 (3.475 sec/step)\n","INFO:tensorflow:global step 199382: loss = 0.0378 (3.523 sec/step)\n","I0611 13:36:34.122566 140666084398976 learning.py:507] global step 199382: loss = 0.0378 (3.523 sec/step)\n","INFO:tensorflow:global step 199383: loss = 0.0441 (3.500 sec/step)\n","I0611 13:36:37.624772 140666084398976 learning.py:507] global step 199383: loss = 0.0441 (3.500 sec/step)\n","INFO:tensorflow:global step 199384: loss = 0.0387 (3.493 sec/step)\n","I0611 13:36:41.119260 140666084398976 learning.py:507] global step 199384: loss = 0.0387 (3.493 sec/step)\n","INFO:tensorflow:global step 199385: loss = 0.0273 (3.468 sec/step)\n","I0611 13:36:44.589050 140666084398976 learning.py:507] global step 199385: loss = 0.0273 (3.468 sec/step)\n","INFO:tensorflow:global step 199386: loss = 0.0426 (3.488 sec/step)\n","I0611 13:36:48.079367 140666084398976 learning.py:507] global step 199386: loss = 0.0426 (3.488 sec/step)\n","INFO:tensorflow:global step 199387: loss = 0.0397 (3.440 sec/step)\n","I0611 13:36:51.521676 140666084398976 learning.py:507] global step 199387: loss = 0.0397 (3.440 sec/step)\n","INFO:tensorflow:global step 199388: loss = 0.0567 (3.532 sec/step)\n","I0611 13:36:55.055843 140666084398976 learning.py:507] global step 199388: loss = 0.0567 (3.532 sec/step)\n","INFO:tensorflow:global step 199389: loss = 0.0289 (3.563 sec/step)\n","I0611 13:36:58.621006 140666084398976 learning.py:507] global step 199389: loss = 0.0289 (3.563 sec/step)\n","INFO:tensorflow:global step 199390: loss = 0.0539 (3.451 sec/step)\n","I0611 13:37:02.073559 140666084398976 learning.py:507] global step 199390: loss = 0.0539 (3.451 sec/step)\n","INFO:tensorflow:global step 199391: loss = 0.0303 (3.551 sec/step)\n","I0611 13:37:05.626578 140666084398976 learning.py:507] global step 199391: loss = 0.0303 (3.551 sec/step)\n","INFO:tensorflow:global step 199392: loss = 0.0487 (3.512 sec/step)\n","I0611 13:37:09.140480 140666084398976 learning.py:507] global step 199392: loss = 0.0487 (3.512 sec/step)\n","INFO:tensorflow:global step 199393: loss = 0.0350 (3.648 sec/step)\n","I0611 13:37:12.790355 140666084398976 learning.py:507] global step 199393: loss = 0.0350 (3.648 sec/step)\n","INFO:tensorflow:global step 199394: loss = 0.0287 (3.527 sec/step)\n","I0611 13:37:16.319179 140666084398976 learning.py:507] global step 199394: loss = 0.0287 (3.527 sec/step)\n","INFO:tensorflow:global step 199395: loss = 0.0304 (3.449 sec/step)\n","I0611 13:37:19.769705 140666084398976 learning.py:507] global step 199395: loss = 0.0304 (3.449 sec/step)\n","INFO:tensorflow:global step 199396: loss = 0.0272 (3.553 sec/step)\n","I0611 13:37:23.324738 140666084398976 learning.py:507] global step 199396: loss = 0.0272 (3.553 sec/step)\n","INFO:tensorflow:global step 199397: loss = 0.0328 (3.442 sec/step)\n","I0611 13:37:26.768566 140666084398976 learning.py:507] global step 199397: loss = 0.0328 (3.442 sec/step)\n","INFO:tensorflow:global step 199398: loss = 0.0295 (3.479 sec/step)\n","I0611 13:37:30.249152 140666084398976 learning.py:507] global step 199398: loss = 0.0295 (3.479 sec/step)\n","INFO:tensorflow:global step 199399: loss = 0.0310 (3.462 sec/step)\n","I0611 13:37:33.820595 140666084398976 learning.py:507] global step 199399: loss = 0.0310 (3.462 sec/step)\n","INFO:tensorflow:global step 199400: loss = 0.0336 (4.383 sec/step)\n","I0611 13:37:38.209483 140666084398976 learning.py:507] global step 199400: loss = 0.0336 (4.383 sec/step)\n","INFO:tensorflow:Recording summary at step 199400.\n","I0611 13:37:39.753302 140662738253568 supervisor.py:1050] Recording summary at step 199400.\n","INFO:tensorflow:global step 199401: loss = 0.0283 (3.824 sec/step)\n","I0611 13:37:42.057544 140666084398976 learning.py:507] global step 199401: loss = 0.0283 (3.824 sec/step)\n","INFO:tensorflow:global_step/sec: 0.283334\n","I0611 13:37:42.098793 140662746646272 supervisor.py:1099] global_step/sec: 0.283334\n","INFO:tensorflow:global step 199402: loss = 0.0374 (3.475 sec/step)\n","I0611 13:37:45.534327 140666084398976 learning.py:507] global step 199402: loss = 0.0374 (3.475 sec/step)\n","INFO:tensorflow:global step 199403: loss = 0.0400 (3.519 sec/step)\n","I0611 13:37:49.055059 140666084398976 learning.py:507] global step 199403: loss = 0.0400 (3.519 sec/step)\n","INFO:tensorflow:global step 199404: loss = 0.0286 (3.447 sec/step)\n","I0611 13:37:52.503561 140666084398976 learning.py:507] global step 199404: loss = 0.0286 (3.447 sec/step)\n","INFO:tensorflow:global step 199405: loss = 0.0397 (3.458 sec/step)\n","I0611 13:37:55.963906 140666084398976 learning.py:507] global step 199405: loss = 0.0397 (3.458 sec/step)\n","INFO:tensorflow:global step 199406: loss = 0.0397 (3.494 sec/step)\n","I0611 13:37:59.459947 140666084398976 learning.py:507] global step 199406: loss = 0.0397 (3.494 sec/step)\n","INFO:tensorflow:global step 199407: loss = 0.0313 (3.584 sec/step)\n","I0611 13:38:03.046643 140666084398976 learning.py:507] global step 199407: loss = 0.0313 (3.584 sec/step)\n","INFO:tensorflow:global step 199408: loss = 0.0358 (3.521 sec/step)\n","I0611 13:38:06.569321 140666084398976 learning.py:507] global step 199408: loss = 0.0358 (3.521 sec/step)\n","INFO:tensorflow:global step 199409: loss = 0.0275 (3.452 sec/step)\n","I0611 13:38:10.023570 140666084398976 learning.py:507] global step 199409: loss = 0.0275 (3.452 sec/step)\n","INFO:tensorflow:global step 199410: loss = 0.0474 (3.480 sec/step)\n","I0611 13:38:13.505489 140666084398976 learning.py:507] global step 199410: loss = 0.0474 (3.480 sec/step)\n","INFO:tensorflow:global step 199411: loss = 0.0368 (3.518 sec/step)\n","I0611 13:38:17.025605 140666084398976 learning.py:507] global step 199411: loss = 0.0368 (3.518 sec/step)\n","INFO:tensorflow:global step 199412: loss = 0.0512 (3.564 sec/step)\n","I0611 13:38:20.591219 140666084398976 learning.py:507] global step 199412: loss = 0.0512 (3.564 sec/step)\n","INFO:tensorflow:global step 199413: loss = 0.0330 (3.517 sec/step)\n","I0611 13:38:24.110088 140666084398976 learning.py:507] global step 199413: loss = 0.0330 (3.517 sec/step)\n","INFO:tensorflow:global step 199414: loss = 0.0437 (3.513 sec/step)\n","I0611 13:38:27.624411 140666084398976 learning.py:507] global step 199414: loss = 0.0437 (3.513 sec/step)\n","INFO:tensorflow:global step 199415: loss = 0.0430 (3.530 sec/step)\n","I0611 13:38:31.156328 140666084398976 learning.py:507] global step 199415: loss = 0.0430 (3.530 sec/step)\n","INFO:tensorflow:global step 199416: loss = 0.0288 (3.490 sec/step)\n","I0611 13:38:34.648596 140666084398976 learning.py:507] global step 199416: loss = 0.0288 (3.490 sec/step)\n","INFO:tensorflow:global step 199417: loss = 0.0321 (3.528 sec/step)\n","I0611 13:38:38.178783 140666084398976 learning.py:507] global step 199417: loss = 0.0321 (3.528 sec/step)\n","INFO:tensorflow:global step 199418: loss = 0.0427 (3.501 sec/step)\n","I0611 13:38:41.682055 140666084398976 learning.py:507] global step 199418: loss = 0.0427 (3.501 sec/step)\n","INFO:tensorflow:global step 199419: loss = 0.0282 (3.543 sec/step)\n","I0611 13:38:45.226851 140666084398976 learning.py:507] global step 199419: loss = 0.0282 (3.543 sec/step)\n","INFO:tensorflow:global step 199420: loss = 0.0269 (3.484 sec/step)\n","I0611 13:38:48.712805 140666084398976 learning.py:507] global step 199420: loss = 0.0269 (3.484 sec/step)\n","INFO:tensorflow:global step 199421: loss = 0.0415 (3.551 sec/step)\n","I0611 13:38:52.265349 140666084398976 learning.py:507] global step 199421: loss = 0.0415 (3.551 sec/step)\n","INFO:tensorflow:global step 199422: loss = 0.0555 (3.476 sec/step)\n","I0611 13:38:55.743298 140666084398976 learning.py:507] global step 199422: loss = 0.0555 (3.476 sec/step)\n","INFO:tensorflow:global step 199423: loss = 0.0344 (3.480 sec/step)\n","I0611 13:38:59.224819 140666084398976 learning.py:507] global step 199423: loss = 0.0344 (3.480 sec/step)\n","INFO:tensorflow:global step 199424: loss = 0.0394 (3.464 sec/step)\n","I0611 13:39:02.690400 140666084398976 learning.py:507] global step 199424: loss = 0.0394 (3.464 sec/step)\n","INFO:tensorflow:global step 199425: loss = 0.0553 (3.591 sec/step)\n","I0611 13:39:06.283093 140666084398976 learning.py:507] global step 199425: loss = 0.0553 (3.591 sec/step)\n","INFO:tensorflow:global step 199426: loss = 0.0410 (3.471 sec/step)\n","I0611 13:39:09.756120 140666084398976 learning.py:507] global step 199426: loss = 0.0410 (3.471 sec/step)\n","INFO:tensorflow:global step 199427: loss = 0.0323 (3.505 sec/step)\n","I0611 13:39:13.262618 140666084398976 learning.py:507] global step 199427: loss = 0.0323 (3.505 sec/step)\n","INFO:tensorflow:global step 199428: loss = 0.0273 (3.542 sec/step)\n","I0611 13:39:16.806864 140666084398976 learning.py:507] global step 199428: loss = 0.0273 (3.542 sec/step)\n","INFO:tensorflow:global step 199429: loss = 0.0400 (3.455 sec/step)\n","I0611 13:39:20.263543 140666084398976 learning.py:507] global step 199429: loss = 0.0400 (3.455 sec/step)\n","INFO:tensorflow:global step 199430: loss = 0.0303 (3.485 sec/step)\n","I0611 13:39:23.750273 140666084398976 learning.py:507] global step 199430: loss = 0.0303 (3.485 sec/step)\n","INFO:tensorflow:global step 199431: loss = 0.0537 (3.548 sec/step)\n","I0611 13:39:27.300234 140666084398976 learning.py:507] global step 199431: loss = 0.0537 (3.548 sec/step)\n","INFO:tensorflow:global step 199432: loss = 0.0331 (3.472 sec/step)\n","I0611 13:39:30.773521 140666084398976 learning.py:507] global step 199432: loss = 0.0331 (3.472 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I0611 13:39:33.573837 140662755038976 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0611 13:39:34.451734 140662755038976 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:global step 199433: loss = 0.0293 (3.709 sec/step)\n","I0611 13:39:34.522442 140666084398976 learning.py:507] global step 199433: loss = 0.0293 (3.709 sec/step)\n","INFO:tensorflow:Recording summary at step 199433.\n","I0611 13:39:37.189292 140662738253568 supervisor.py:1050] Recording summary at step 199433.\n","INFO:tensorflow:global step 199434: loss = 0.0390 (4.846 sec/step)\n","I0611 13:39:39.373157 140666084398976 learning.py:507] global step 199434: loss = 0.0390 (4.846 sec/step)\n","INFO:tensorflow:global_step/sec: 0.275\n","I0611 13:39:42.098834 140662746646272 supervisor.py:1099] global_step/sec: 0.275\n","INFO:tensorflow:global step 199435: loss = 0.0529 (3.516 sec/step)\n","I0611 13:39:42.891495 140666084398976 learning.py:507] global step 199435: loss = 0.0529 (3.516 sec/step)\n","INFO:tensorflow:global step 199436: loss = 0.0333 (3.548 sec/step)\n","I0611 13:39:46.441955 140666084398976 learning.py:507] global step 199436: loss = 0.0333 (3.548 sec/step)\n","INFO:tensorflow:global step 199437: loss = 0.0429 (3.617 sec/step)\n","I0611 13:39:50.060466 140666084398976 learning.py:507] global step 199437: loss = 0.0429 (3.617 sec/step)\n","INFO:tensorflow:global step 199438: loss = 0.0440 (3.517 sec/step)\n","I0611 13:39:53.578796 140666084398976 learning.py:507] global step 199438: loss = 0.0440 (3.517 sec/step)\n","INFO:tensorflow:global step 199439: loss = 0.0413 (3.453 sec/step)\n","I0611 13:39:57.033233 140666084398976 learning.py:507] global step 199439: loss = 0.0413 (3.453 sec/step)\n","INFO:tensorflow:global step 199440: loss = 0.0245 (3.497 sec/step)\n","I0611 13:40:00.534809 140666084398976 learning.py:507] global step 199440: loss = 0.0245 (3.497 sec/step)\n","INFO:tensorflow:global step 199441: loss = 0.0368 (3.444 sec/step)\n","I0611 13:40:03.980399 140666084398976 learning.py:507] global step 199441: loss = 0.0368 (3.444 sec/step)\n","INFO:tensorflow:global step 199442: loss = 0.0317 (3.572 sec/step)\n","I0611 13:40:07.554316 140666084398976 learning.py:507] global step 199442: loss = 0.0317 (3.572 sec/step)\n","INFO:tensorflow:global step 199443: loss = 0.0378 (3.551 sec/step)\n","I0611 13:40:11.106765 140666084398976 learning.py:507] global step 199443: loss = 0.0378 (3.551 sec/step)\n","INFO:tensorflow:global step 199444: loss = 0.0260 (3.575 sec/step)\n","I0611 13:40:14.683558 140666084398976 learning.py:507] global step 199444: loss = 0.0260 (3.575 sec/step)\n","INFO:tensorflow:global step 199445: loss = 0.0281 (3.457 sec/step)\n","I0611 13:40:18.142111 140666084398976 learning.py:507] global step 199445: loss = 0.0281 (3.457 sec/step)\n","INFO:tensorflow:global step 199446: loss = 0.0395 (3.502 sec/step)\n","I0611 13:40:21.646211 140666084398976 learning.py:507] global step 199446: loss = 0.0395 (3.502 sec/step)\n","INFO:tensorflow:global step 199447: loss = 0.0367 (3.493 sec/step)\n","I0611 13:40:25.141429 140666084398976 learning.py:507] global step 199447: loss = 0.0367 (3.493 sec/step)\n","INFO:tensorflow:global step 199448: loss = 0.0305 (3.614 sec/step)\n","I0611 13:40:28.757837 140666084398976 learning.py:507] global step 199448: loss = 0.0305 (3.614 sec/step)\n","INFO:tensorflow:global step 199449: loss = 0.0370 (3.507 sec/step)\n","I0611 13:40:32.267115 140666084398976 learning.py:507] global step 199449: loss = 0.0370 (3.507 sec/step)\n","INFO:tensorflow:global step 199450: loss = 0.0334 (3.539 sec/step)\n","I0611 13:40:35.808603 140666084398976 learning.py:507] global step 199450: loss = 0.0334 (3.539 sec/step)\n","INFO:tensorflow:global step 199451: loss = 0.0334 (3.574 sec/step)\n","I0611 13:40:39.384872 140666084398976 learning.py:507] global step 199451: loss = 0.0334 (3.574 sec/step)\n","INFO:tensorflow:global step 199452: loss = 0.0298 (3.492 sec/step)\n","I0611 13:40:42.879050 140666084398976 learning.py:507] global step 199452: loss = 0.0298 (3.492 sec/step)\n","INFO:tensorflow:global step 199453: loss = 0.0349 (3.456 sec/step)\n","I0611 13:40:46.336614 140666084398976 learning.py:507] global step 199453: loss = 0.0349 (3.456 sec/step)\n","INFO:tensorflow:global step 199454: loss = 0.0501 (3.516 sec/step)\n","I0611 13:40:49.854921 140666084398976 learning.py:507] global step 199454: loss = 0.0501 (3.516 sec/step)\n","INFO:tensorflow:global step 199455: loss = 0.0244 (3.498 sec/step)\n","I0611 13:40:53.355455 140666084398976 learning.py:507] global step 199455: loss = 0.0244 (3.498 sec/step)\n","INFO:tensorflow:global step 199456: loss = 0.0250 (3.590 sec/step)\n","I0611 13:40:56.947499 140666084398976 learning.py:507] global step 199456: loss = 0.0250 (3.590 sec/step)\n","INFO:tensorflow:global step 199457: loss = 0.0357 (3.641 sec/step)\n","I0611 13:41:00.592400 140666084398976 learning.py:507] global step 199457: loss = 0.0357 (3.641 sec/step)\n","INFO:tensorflow:global step 199458: loss = 0.0461 (3.589 sec/step)\n","I0611 13:41:04.184611 140666084398976 learning.py:507] global step 199458: loss = 0.0461 (3.589 sec/step)\n","INFO:tensorflow:global step 199459: loss = 0.0542 (3.566 sec/step)\n","I0611 13:41:07.752034 140666084398976 learning.py:507] global step 199459: loss = 0.0542 (3.566 sec/step)\n","INFO:tensorflow:global step 199460: loss = 0.0368 (3.568 sec/step)\n","I0611 13:41:11.321214 140666084398976 learning.py:507] global step 199460: loss = 0.0368 (3.568 sec/step)\n","INFO:tensorflow:global step 199461: loss = 0.0310 (3.533 sec/step)\n","I0611 13:41:14.855780 140666084398976 learning.py:507] global step 199461: loss = 0.0310 (3.533 sec/step)\n","INFO:tensorflow:global step 199462: loss = 0.0302 (3.500 sec/step)\n","I0611 13:41:18.358052 140666084398976 learning.py:507] global step 199462: loss = 0.0302 (3.500 sec/step)\n","INFO:tensorflow:global step 199463: loss = 0.0416 (3.512 sec/step)\n","I0611 13:41:21.871551 140666084398976 learning.py:507] global step 199463: loss = 0.0416 (3.512 sec/step)\n","INFO:tensorflow:global step 199464: loss = 0.0391 (3.541 sec/step)\n","I0611 13:41:25.413963 140666084398976 learning.py:507] global step 199464: loss = 0.0391 (3.541 sec/step)\n","INFO:tensorflow:global step 199465: loss = 0.0373 (3.557 sec/step)\n","I0611 13:41:28.972433 140666084398976 learning.py:507] global step 199465: loss = 0.0373 (3.557 sec/step)\n","INFO:tensorflow:global step 199466: loss = 0.0347 (3.543 sec/step)\n","I0611 13:41:32.517978 140666084398976 learning.py:507] global step 199466: loss = 0.0347 (3.543 sec/step)\n","INFO:tensorflow:global step 199467: loss = 0.0385 (3.700 sec/step)\n","I0611 13:41:36.219549 140666084398976 learning.py:507] global step 199467: loss = 0.0385 (3.700 sec/step)\n","INFO:tensorflow:global step 199468: loss = 0.0278 (4.675 sec/step)\n","I0611 13:41:40.903216 140666084398976 learning.py:507] global step 199468: loss = 0.0278 (4.675 sec/step)\n","INFO:tensorflow:Recording summary at step 199468.\n","I0611 13:41:42.058277 140662738253568 supervisor.py:1050] Recording summary at step 199468.\n","INFO:tensorflow:global_step/sec: 0.283333\n","I0611 13:41:42.098858 140662746646272 supervisor.py:1099] global_step/sec: 0.283333\n","INFO:tensorflow:global step 199469: loss = 0.0304 (3.827 sec/step)\n","I0611 13:41:44.734339 140666084398976 learning.py:507] global step 199469: loss = 0.0304 (3.827 sec/step)\n","INFO:tensorflow:global step 199470: loss = 0.0346 (3.474 sec/step)\n","I0611 13:41:48.210461 140666084398976 learning.py:507] global step 199470: loss = 0.0346 (3.474 sec/step)\n","INFO:tensorflow:global step 199471: loss = 0.0265 (3.508 sec/step)\n","I0611 13:41:51.719944 140666084398976 learning.py:507] global step 199471: loss = 0.0265 (3.508 sec/step)\n","INFO:tensorflow:global step 199472: loss = 0.0442 (3.501 sec/step)\n","I0611 13:41:55.222227 140666084398976 learning.py:507] global step 199472: loss = 0.0442 (3.501 sec/step)\n","INFO:tensorflow:global step 199473: loss = 0.0301 (3.466 sec/step)\n","I0611 13:41:58.690430 140666084398976 learning.py:507] global step 199473: loss = 0.0301 (3.466 sec/step)\n","INFO:tensorflow:global step 199474: loss = 0.0378 (3.586 sec/step)\n","I0611 13:42:02.278490 140666084398976 learning.py:507] global step 199474: loss = 0.0378 (3.586 sec/step)\n","INFO:tensorflow:global step 199475: loss = 0.0492 (3.526 sec/step)\n","I0611 13:42:05.806806 140666084398976 learning.py:507] global step 199475: loss = 0.0492 (3.526 sec/step)\n","INFO:tensorflow:global step 199476: loss = 0.0332 (3.514 sec/step)\n","I0611 13:42:09.322260 140666084398976 learning.py:507] global step 199476: loss = 0.0332 (3.514 sec/step)\n","INFO:tensorflow:global step 199477: loss = 0.0372 (3.448 sec/step)\n","I0611 13:42:12.772785 140666084398976 learning.py:507] global step 199477: loss = 0.0372 (3.448 sec/step)\n","INFO:tensorflow:global step 199478: loss = 0.0405 (3.497 sec/step)\n","I0611 13:42:16.271483 140666084398976 learning.py:507] global step 199478: loss = 0.0405 (3.497 sec/step)\n","INFO:tensorflow:global step 199479: loss = 0.0344 (3.452 sec/step)\n","I0611 13:42:19.725466 140666084398976 learning.py:507] global step 199479: loss = 0.0344 (3.452 sec/step)\n","INFO:tensorflow:global step 199480: loss = 0.0298 (3.513 sec/step)\n","I0611 13:42:23.239948 140666084398976 learning.py:507] global step 199480: loss = 0.0298 (3.513 sec/step)\n","INFO:tensorflow:global step 199481: loss = 0.0385 (3.523 sec/step)\n","I0611 13:42:26.765168 140666084398976 learning.py:507] global step 199481: loss = 0.0385 (3.523 sec/step)\n","INFO:tensorflow:global step 199482: loss = 0.0300 (3.452 sec/step)\n","I0611 13:42:30.221445 140666084398976 learning.py:507] global step 199482: loss = 0.0300 (3.452 sec/step)\n","INFO:tensorflow:global step 199483: loss = 0.0300 (3.528 sec/step)\n","I0611 13:42:33.752471 140666084398976 learning.py:507] global step 199483: loss = 0.0300 (3.528 sec/step)\n","INFO:tensorflow:global step 199484: loss = 0.0376 (3.460 sec/step)\n","I0611 13:42:37.214440 140666084398976 learning.py:507] global step 199484: loss = 0.0376 (3.460 sec/step)\n","INFO:tensorflow:global step 199485: loss = 0.0381 (3.516 sec/step)\n","I0611 13:42:40.732443 140666084398976 learning.py:507] global step 199485: loss = 0.0381 (3.516 sec/step)\n","INFO:tensorflow:global step 199486: loss = 0.0389 (3.479 sec/step)\n","I0611 13:42:44.213581 140666084398976 learning.py:507] global step 199486: loss = 0.0389 (3.479 sec/step)\n","INFO:tensorflow:global step 199487: loss = 0.0327 (3.560 sec/step)\n","I0611 13:42:47.775600 140666084398976 learning.py:507] global step 199487: loss = 0.0327 (3.560 sec/step)\n","INFO:tensorflow:global step 199488: loss = 0.0273 (3.563 sec/step)\n","I0611 13:42:51.340178 140666084398976 learning.py:507] global step 199488: loss = 0.0273 (3.563 sec/step)\n","INFO:tensorflow:global step 199489: loss = 0.0324 (3.550 sec/step)\n","I0611 13:42:54.892318 140666084398976 learning.py:507] global step 199489: loss = 0.0324 (3.550 sec/step)\n","INFO:tensorflow:global step 199490: loss = 0.0355 (3.409 sec/step)\n","I0611 13:42:58.303460 140666084398976 learning.py:507] global step 199490: loss = 0.0355 (3.409 sec/step)\n","INFO:tensorflow:global step 199491: loss = 0.0405 (3.536 sec/step)\n","I0611 13:43:01.841552 140666084398976 learning.py:507] global step 199491: loss = 0.0405 (3.536 sec/step)\n","INFO:tensorflow:global step 199492: loss = 0.0274 (3.566 sec/step)\n","I0611 13:43:05.410748 140666084398976 learning.py:507] global step 199492: loss = 0.0274 (3.566 sec/step)\n","INFO:tensorflow:global step 199493: loss = 0.0427 (3.447 sec/step)\n","I0611 13:43:08.862250 140666084398976 learning.py:507] global step 199493: loss = 0.0427 (3.447 sec/step)\n","INFO:tensorflow:global step 199494: loss = 0.0417 (3.718 sec/step)\n","I0611 13:43:12.581977 140666084398976 learning.py:507] global step 199494: loss = 0.0417 (3.718 sec/step)\n","INFO:tensorflow:global step 199495: loss = 0.0514 (3.514 sec/step)\n","I0611 13:43:16.099405 140666084398976 learning.py:507] global step 199495: loss = 0.0514 (3.514 sec/step)\n","INFO:tensorflow:global step 199496: loss = 0.0320 (3.493 sec/step)\n","I0611 13:43:19.594737 140666084398976 learning.py:507] global step 199496: loss = 0.0320 (3.493 sec/step)\n","INFO:tensorflow:global step 199497: loss = 0.0382 (3.472 sec/step)\n","I0611 13:43:23.068548 140666084398976 learning.py:507] global step 199497: loss = 0.0382 (3.472 sec/step)\n","INFO:tensorflow:global step 199498: loss = 0.0311 (3.463 sec/step)\n","I0611 13:43:26.533581 140666084398976 learning.py:507] global step 199498: loss = 0.0311 (3.463 sec/step)\n","INFO:tensorflow:global step 199499: loss = 0.0263 (3.475 sec/step)\n","I0611 13:43:30.010826 140666084398976 learning.py:507] global step 199499: loss = 0.0263 (3.475 sec/step)\n","INFO:tensorflow:global step 199500: loss = 0.0488 (3.645 sec/step)\n","I0611 13:43:33.749186 140666084398976 learning.py:507] global step 199500: loss = 0.0488 (3.645 sec/step)\n","INFO:tensorflow:global step 199501: loss = 0.0405 (4.087 sec/step)\n","I0611 13:43:37.931045 140666084398976 learning.py:507] global step 199501: loss = 0.0405 (4.087 sec/step)\n","INFO:tensorflow:Recording summary at step 199501.\n","I0611 13:43:39.329976 140662738253568 supervisor.py:1050] Recording summary at step 199501.\n","INFO:tensorflow:global step 199502: loss = 0.0313 (3.901 sec/step)\n","I0611 13:43:41.870993 140666084398976 learning.py:507] global step 199502: loss = 0.0313 (3.901 sec/step)\n","INFO:tensorflow:global_step/sec: 0.283333\n","I0611 13:43:42.098886 140662746646272 supervisor.py:1099] global_step/sec: 0.283333\n","INFO:tensorflow:global step 199503: loss = 0.0495 (3.532 sec/step)\n","I0611 13:43:45.404809 140666084398976 learning.py:507] global step 199503: loss = 0.0495 (3.532 sec/step)\n","INFO:tensorflow:global step 199504: loss = 0.0515 (3.476 sec/step)\n","I0611 13:43:48.883041 140666084398976 learning.py:507] global step 199504: loss = 0.0515 (3.476 sec/step)\n","INFO:tensorflow:global step 199505: loss = 0.0374 (3.641 sec/step)\n","I0611 13:43:52.525491 140666084398976 learning.py:507] global step 199505: loss = 0.0374 (3.641 sec/step)\n","INFO:tensorflow:global step 199506: loss = 0.0380 (3.550 sec/step)\n","I0611 13:43:56.077787 140666084398976 learning.py:507] global step 199506: loss = 0.0380 (3.550 sec/step)\n","INFO:tensorflow:global step 199507: loss = 0.0410 (3.530 sec/step)\n","I0611 13:43:59.609692 140666084398976 learning.py:507] global step 199507: loss = 0.0410 (3.530 sec/step)\n","INFO:tensorflow:global step 199508: loss = 0.0289 (3.542 sec/step)\n","I0611 13:44:03.153540 140666084398976 learning.py:507] global step 199508: loss = 0.0289 (3.542 sec/step)\n","INFO:tensorflow:global step 199509: loss = 0.0474 (3.475 sec/step)\n","I0611 13:44:06.630205 140666084398976 learning.py:507] global step 199509: loss = 0.0474 (3.475 sec/step)\n","INFO:tensorflow:global step 199510: loss = 0.0262 (3.518 sec/step)\n","I0611 13:44:10.150269 140666084398976 learning.py:507] global step 199510: loss = 0.0262 (3.518 sec/step)\n","INFO:tensorflow:global step 199511: loss = 0.0336 (3.489 sec/step)\n","I0611 13:44:13.641269 140666084398976 learning.py:507] global step 199511: loss = 0.0336 (3.489 sec/step)\n","INFO:tensorflow:global step 199512: loss = 0.0425 (3.491 sec/step)\n","I0611 13:44:17.133891 140666084398976 learning.py:507] global step 199512: loss = 0.0425 (3.491 sec/step)\n","INFO:tensorflow:global step 199513: loss = 0.0366 (3.563 sec/step)\n","I0611 13:44:20.699120 140666084398976 learning.py:507] global step 199513: loss = 0.0366 (3.563 sec/step)\n","INFO:tensorflow:global step 199514: loss = 0.0476 (3.484 sec/step)\n","I0611 13:44:24.185350 140666084398976 learning.py:507] global step 199514: loss = 0.0476 (3.484 sec/step)\n","INFO:tensorflow:global step 199515: loss = 0.0251 (3.478 sec/step)\n","I0611 13:44:27.665040 140666084398976 learning.py:507] global step 199515: loss = 0.0251 (3.478 sec/step)\n","INFO:tensorflow:global step 199516: loss = 0.0301 (3.471 sec/step)\n","I0611 13:44:31.138026 140666084398976 learning.py:507] global step 199516: loss = 0.0301 (3.471 sec/step)\n","INFO:tensorflow:global step 199517: loss = 0.0333 (3.538 sec/step)\n","I0611 13:44:34.677433 140666084398976 learning.py:507] global step 199517: loss = 0.0333 (3.538 sec/step)\n","INFO:tensorflow:global step 199518: loss = 0.0380 (3.519 sec/step)\n","I0611 13:44:38.199957 140666084398976 learning.py:507] global step 199518: loss = 0.0380 (3.519 sec/step)\n","INFO:tensorflow:global step 199519: loss = 0.0354 (3.454 sec/step)\n","I0611 13:44:41.656750 140666084398976 learning.py:507] global step 199519: loss = 0.0354 (3.454 sec/step)\n","INFO:tensorflow:global step 199520: loss = 0.0376 (3.455 sec/step)\n","I0611 13:44:45.113504 140666084398976 learning.py:507] global step 199520: loss = 0.0376 (3.455 sec/step)\n","INFO:tensorflow:global step 199521: loss = 0.0266 (3.478 sec/step)\n","I0611 13:44:48.593293 140666084398976 learning.py:507] global step 199521: loss = 0.0266 (3.478 sec/step)\n","INFO:tensorflow:global step 199522: loss = 0.0337 (3.506 sec/step)\n","I0611 13:44:52.101127 140666084398976 learning.py:507] global step 199522: loss = 0.0337 (3.506 sec/step)\n","INFO:tensorflow:global step 199523: loss = 0.0308 (3.435 sec/step)\n","I0611 13:44:55.538747 140666084398976 learning.py:507] global step 199523: loss = 0.0308 (3.435 sec/step)\n","INFO:tensorflow:global step 199524: loss = 0.0511 (3.475 sec/step)\n","I0611 13:44:59.015257 140666084398976 learning.py:507] global step 199524: loss = 0.0511 (3.475 sec/step)\n","INFO:tensorflow:global step 199525: loss = 0.0286 (3.438 sec/step)\n","I0611 13:45:02.455479 140666084398976 learning.py:507] global step 199525: loss = 0.0286 (3.438 sec/step)\n","INFO:tensorflow:global step 199526: loss = 0.0310 (3.519 sec/step)\n","I0611 13:45:05.975892 140666084398976 learning.py:507] global step 199526: loss = 0.0310 (3.519 sec/step)\n","INFO:tensorflow:global step 199527: loss = 0.0360 (3.580 sec/step)\n","I0611 13:45:09.558262 140666084398976 learning.py:507] global step 199527: loss = 0.0360 (3.580 sec/step)\n","INFO:tensorflow:global step 199528: loss = 0.0381 (3.483 sec/step)\n","I0611 13:45:13.042988 140666084398976 learning.py:507] global step 199528: loss = 0.0381 (3.483 sec/step)\n","INFO:tensorflow:global step 199529: loss = 0.0338 (3.536 sec/step)\n","I0611 13:45:16.580792 140666084398976 learning.py:507] global step 199529: loss = 0.0338 (3.536 sec/step)\n","INFO:tensorflow:global step 199530: loss = 0.0319 (3.576 sec/step)\n","I0611 13:45:20.158270 140666084398976 learning.py:507] global step 199530: loss = 0.0319 (3.576 sec/step)\n","INFO:tensorflow:global step 199531: loss = 0.0389 (3.426 sec/step)\n","I0611 13:45:23.586415 140666084398976 learning.py:507] global step 199531: loss = 0.0389 (3.426 sec/step)\n","INFO:tensorflow:global step 199532: loss = 0.0318 (3.469 sec/step)\n","I0611 13:45:27.057264 140666084398976 learning.py:507] global step 199532: loss = 0.0318 (3.469 sec/step)\n","INFO:tensorflow:global step 199533: loss = 0.0398 (3.483 sec/step)\n","I0611 13:45:30.542483 140666084398976 learning.py:507] global step 199533: loss = 0.0398 (3.483 sec/step)\n","INFO:tensorflow:global step 199534: loss = 0.0445 (3.701 sec/step)\n","I0611 13:45:34.248267 140666084398976 learning.py:507] global step 199534: loss = 0.0445 (3.701 sec/step)\n","INFO:tensorflow:global step 199535: loss = 0.0432 (4.621 sec/step)\n","I0611 13:45:38.885708 140666084398976 learning.py:507] global step 199535: loss = 0.0432 (4.621 sec/step)\n","INFO:tensorflow:Recording summary at step 199535.\n","I0611 13:45:40.113607 140662738253568 supervisor.py:1050] Recording summary at step 199535.\n","INFO:tensorflow:global_step/sec: 0.275\n","I0611 13:45:42.099065 140662746646272 supervisor.py:1099] global_step/sec: 0.275\n","INFO:tensorflow:global step 199536: loss = 0.0379 (3.769 sec/step)\n","I0611 13:45:42.676048 140666084398976 learning.py:507] global step 199536: loss = 0.0379 (3.769 sec/step)\n","INFO:tensorflow:global step 199537: loss = 0.0207 (3.523 sec/step)\n","I0611 13:45:46.201054 140666084398976 learning.py:507] global step 199537: loss = 0.0207 (3.523 sec/step)\n","INFO:tensorflow:global step 199538: loss = 0.0307 (3.553 sec/step)\n","I0611 13:45:49.755912 140666084398976 learning.py:507] global step 199538: loss = 0.0307 (3.553 sec/step)\n","INFO:tensorflow:global step 199539: loss = 0.0348 (3.481 sec/step)\n","I0611 13:45:53.238960 140666084398976 learning.py:507] global step 199539: loss = 0.0348 (3.481 sec/step)\n","INFO:tensorflow:global step 199540: loss = 0.0536 (3.522 sec/step)\n","I0611 13:45:56.763028 140666084398976 learning.py:507] global step 199540: loss = 0.0536 (3.522 sec/step)\n","INFO:tensorflow:global step 199541: loss = 0.0317 (3.512 sec/step)\n","I0611 13:46:00.276896 140666084398976 learning.py:507] global step 199541: loss = 0.0317 (3.512 sec/step)\n","INFO:tensorflow:global step 199542: loss = 0.0302 (3.535 sec/step)\n","I0611 13:46:03.813840 140666084398976 learning.py:507] global step 199542: loss = 0.0302 (3.535 sec/step)\n","INFO:tensorflow:global step 199543: loss = 0.0319 (3.507 sec/step)\n","I0611 13:46:07.322290 140666084398976 learning.py:507] global step 199543: loss = 0.0319 (3.507 sec/step)\n","INFO:tensorflow:global step 199544: loss = 0.0394 (3.497 sec/step)\n","I0611 13:46:10.820901 140666084398976 learning.py:507] global step 199544: loss = 0.0394 (3.497 sec/step)\n","INFO:tensorflow:global step 199545: loss = 0.0521 (3.557 sec/step)\n","I0611 13:46:14.379456 140666084398976 learning.py:507] global step 199545: loss = 0.0521 (3.557 sec/step)\n","INFO:tensorflow:global step 199546: loss = 0.0377 (3.447 sec/step)\n","I0611 13:46:17.828375 140666084398976 learning.py:507] global step 199546: loss = 0.0377 (3.447 sec/step)\n","INFO:tensorflow:global step 199547: loss = 0.0455 (3.475 sec/step)\n","I0611 13:46:21.305031 140666084398976 learning.py:507] global step 199547: loss = 0.0455 (3.475 sec/step)\n","INFO:tensorflow:global step 199548: loss = 0.0393 (3.514 sec/step)\n","I0611 13:46:24.820996 140666084398976 learning.py:507] global step 199548: loss = 0.0393 (3.514 sec/step)\n","INFO:tensorflow:global step 199549: loss = 0.0275 (3.492 sec/step)\n","I0611 13:46:28.315000 140666084398976 learning.py:507] global step 199549: loss = 0.0275 (3.492 sec/step)\n","INFO:tensorflow:global step 199550: loss = 0.0379 (3.531 sec/step)\n","I0611 13:46:31.848295 140666084398976 learning.py:507] global step 199550: loss = 0.0379 (3.531 sec/step)\n","INFO:tensorflow:global step 199551: loss = 0.0306 (3.424 sec/step)\n","I0611 13:46:35.274175 140666084398976 learning.py:507] global step 199551: loss = 0.0306 (3.424 sec/step)\n","INFO:tensorflow:global step 199552: loss = 0.0318 (3.481 sec/step)\n","I0611 13:46:38.757220 140666084398976 learning.py:507] global step 199552: loss = 0.0318 (3.481 sec/step)\n","INFO:tensorflow:global step 199553: loss = 0.0291 (3.560 sec/step)\n","I0611 13:46:42.318845 140666084398976 learning.py:507] global step 199553: loss = 0.0291 (3.560 sec/step)\n","INFO:tensorflow:global step 199554: loss = 0.0372 (3.480 sec/step)\n","I0611 13:46:45.801172 140666084398976 learning.py:507] global step 199554: loss = 0.0372 (3.480 sec/step)\n","INFO:tensorflow:global step 199555: loss = 0.0328 (3.550 sec/step)\n","I0611 13:46:49.352735 140666084398976 learning.py:507] global step 199555: loss = 0.0328 (3.550 sec/step)\n","INFO:tensorflow:global step 199556: loss = 0.0280 (3.438 sec/step)\n","I0611 13:46:52.791838 140666084398976 learning.py:507] global step 199556: loss = 0.0280 (3.438 sec/step)\n","INFO:tensorflow:global step 199557: loss = 0.0358 (3.509 sec/step)\n","I0611 13:46:56.302314 140666084398976 learning.py:507] global step 199557: loss = 0.0358 (3.509 sec/step)\n","INFO:tensorflow:global step 199558: loss = 0.0316 (3.519 sec/step)\n","I0611 13:46:59.822741 140666084398976 learning.py:507] global step 199558: loss = 0.0316 (3.519 sec/step)\n","INFO:tensorflow:global step 199559: loss = 0.0407 (3.515 sec/step)\n","I0611 13:47:03.339752 140666084398976 learning.py:507] global step 199559: loss = 0.0407 (3.515 sec/step)\n","INFO:tensorflow:global step 199560: loss = 0.0268 (3.543 sec/step)\n","I0611 13:47:06.887140 140666084398976 learning.py:507] global step 199560: loss = 0.0268 (3.543 sec/step)\n","INFO:tensorflow:global step 199561: loss = 0.0433 (3.504 sec/step)\n","I0611 13:47:10.393151 140666084398976 learning.py:507] global step 199561: loss = 0.0433 (3.504 sec/step)\n","INFO:tensorflow:global step 199562: loss = 0.0528 (3.454 sec/step)\n","I0611 13:47:13.849240 140666084398976 learning.py:507] global step 199562: loss = 0.0528 (3.454 sec/step)\n","INFO:tensorflow:global step 199563: loss = 0.0338 (3.528 sec/step)\n","I0611 13:47:17.379028 140666084398976 learning.py:507] global step 199563: loss = 0.0338 (3.528 sec/step)\n","INFO:tensorflow:global step 199564: loss = 0.0518 (3.452 sec/step)\n","I0611 13:47:20.833102 140666084398976 learning.py:507] global step 199564: loss = 0.0518 (3.452 sec/step)\n","INFO:tensorflow:global step 199565: loss = 0.0264 (3.505 sec/step)\n","I0611 13:47:24.340000 140666084398976 learning.py:507] global step 199565: loss = 0.0264 (3.505 sec/step)\n","INFO:tensorflow:global step 199566: loss = 0.0251 (3.522 sec/step)\n","I0611 13:47:27.864099 140666084398976 learning.py:507] global step 199566: loss = 0.0251 (3.522 sec/step)\n","INFO:tensorflow:global step 199567: loss = 0.0345 (3.460 sec/step)\n","I0611 13:47:31.326003 140666084398976 learning.py:507] global step 199567: loss = 0.0345 (3.460 sec/step)\n","INFO:tensorflow:global step 199568: loss = 0.0281 (3.517 sec/step)\n","I0611 13:47:34.867941 140666084398976 learning.py:507] global step 199568: loss = 0.0281 (3.517 sec/step)\n","INFO:tensorflow:global step 199569: loss = 0.0419 (4.223 sec/step)\n","I0611 13:47:39.098076 140666084398976 learning.py:507] global step 199569: loss = 0.0419 (4.223 sec/step)\n","INFO:tensorflow:Recording summary at step 199569.\n","I0611 13:47:40.574631 140662738253568 supervisor.py:1050] Recording summary at step 199569.\n","INFO:tensorflow:global_step/sec: 0.283333\n","I0611 13:47:42.099176 140662746646272 supervisor.py:1099] global_step/sec: 0.283333\n","INFO:tensorflow:global step 199570: loss = 0.0404 (3.935 sec/step)\n","I0611 13:47:43.119156 140666084398976 learning.py:507] global step 199570: loss = 0.0404 (3.935 sec/step)\n","INFO:tensorflow:global step 199571: loss = 0.0282 (3.501 sec/step)\n","I0611 13:47:46.622546 140666084398976 learning.py:507] global step 199571: loss = 0.0282 (3.501 sec/step)\n","INFO:tensorflow:global step 199572: loss = 0.0380 (3.459 sec/step)\n","I0611 13:47:50.083039 140666084398976 learning.py:507] global step 199572: loss = 0.0380 (3.459 sec/step)\n","INFO:tensorflow:global step 199573: loss = 0.0239 (3.493 sec/step)\n","I0611 13:47:53.577687 140666084398976 learning.py:507] global step 199573: loss = 0.0239 (3.493 sec/step)\n","INFO:tensorflow:global step 199574: loss = 0.0238 (3.449 sec/step)\n","I0611 13:47:57.028751 140666084398976 learning.py:507] global step 199574: loss = 0.0238 (3.449 sec/step)\n","INFO:tensorflow:global step 199575: loss = 0.0340 (3.477 sec/step)\n","I0611 13:48:00.507775 140666084398976 learning.py:507] global step 199575: loss = 0.0340 (3.477 sec/step)\n","INFO:tensorflow:global step 199576: loss = 0.0459 (3.498 sec/step)\n","I0611 13:48:04.007555 140666084398976 learning.py:507] global step 199576: loss = 0.0459 (3.498 sec/step)\n","INFO:tensorflow:global step 199577: loss = 0.0317 (3.491 sec/step)\n","I0611 13:48:07.500310 140666084398976 learning.py:507] global step 199577: loss = 0.0317 (3.491 sec/step)\n","INFO:tensorflow:global step 199578: loss = 0.0279 (3.443 sec/step)\n","I0611 13:48:10.945403 140666084398976 learning.py:507] global step 199578: loss = 0.0279 (3.443 sec/step)\n","INFO:tensorflow:global step 199579: loss = 0.0422 (3.474 sec/step)\n","I0611 13:48:14.421383 140666084398976 learning.py:507] global step 199579: loss = 0.0422 (3.474 sec/step)\n","INFO:tensorflow:global step 199580: loss = 0.0371 (3.485 sec/step)\n","I0611 13:48:17.908568 140666084398976 learning.py:507] global step 199580: loss = 0.0371 (3.485 sec/step)\n","INFO:tensorflow:global step 199581: loss = 0.0305 (3.461 sec/step)\n","I0611 13:48:21.371819 140666084398976 learning.py:507] global step 199581: loss = 0.0305 (3.461 sec/step)\n","INFO:tensorflow:global step 199582: loss = 0.0312 (3.438 sec/step)\n","I0611 13:48:24.812101 140666084398976 learning.py:507] global step 199582: loss = 0.0312 (3.438 sec/step)\n","INFO:tensorflow:global step 199583: loss = 0.0280 (3.425 sec/step)\n","I0611 13:48:28.239122 140666084398976 learning.py:507] global step 199583: loss = 0.0280 (3.425 sec/step)\n","INFO:tensorflow:global step 199584: loss = 0.0434 (3.460 sec/step)\n","I0611 13:48:31.700767 140666084398976 learning.py:507] global step 199584: loss = 0.0434 (3.460 sec/step)\n","INFO:tensorflow:global step 199585: loss = 0.0331 (3.469 sec/step)\n","I0611 13:48:35.171322 140666084398976 learning.py:507] global step 199585: loss = 0.0331 (3.469 sec/step)\n","INFO:tensorflow:global step 199586: loss = 0.0446 (3.584 sec/step)\n","I0611 13:48:38.756942 140666084398976 learning.py:507] global step 199586: loss = 0.0446 (3.584 sec/step)\n","INFO:tensorflow:global step 199587: loss = 0.0215 (3.523 sec/step)\n","I0611 13:48:42.281595 140666084398976 learning.py:507] global step 199587: loss = 0.0215 (3.523 sec/step)\n","INFO:tensorflow:global step 199588: loss = 0.0269 (3.579 sec/step)\n","I0611 13:48:45.862473 140666084398976 learning.py:507] global step 199588: loss = 0.0269 (3.579 sec/step)\n","INFO:tensorflow:global step 199589: loss = 0.0438 (3.527 sec/step)\n","I0611 13:48:49.391620 140666084398976 learning.py:507] global step 199589: loss = 0.0438 (3.527 sec/step)\n","INFO:tensorflow:global step 199590: loss = 0.0348 (3.566 sec/step)\n","I0611 13:48:52.959460 140666084398976 learning.py:507] global step 199590: loss = 0.0348 (3.566 sec/step)\n","INFO:tensorflow:global step 199591: loss = 0.0266 (3.542 sec/step)\n","I0611 13:48:56.503813 140666084398976 learning.py:507] global step 199591: loss = 0.0266 (3.542 sec/step)\n","INFO:tensorflow:global step 199592: loss = 0.0266 (3.568 sec/step)\n","I0611 13:49:00.073738 140666084398976 learning.py:507] global step 199592: loss = 0.0266 (3.568 sec/step)\n","INFO:tensorflow:global step 199593: loss = 0.0286 (3.547 sec/step)\n","I0611 13:49:03.622573 140666084398976 learning.py:507] global step 199593: loss = 0.0286 (3.547 sec/step)\n","INFO:tensorflow:global step 199594: loss = 0.0427 (3.484 sec/step)\n","I0611 13:49:07.108050 140666084398976 learning.py:507] global step 199594: loss = 0.0427 (3.484 sec/step)\n","INFO:tensorflow:global step 199595: loss = 0.0361 (3.472 sec/step)\n","I0611 13:49:10.582509 140666084398976 learning.py:507] global step 199595: loss = 0.0361 (3.472 sec/step)\n","INFO:tensorflow:global step 199596: loss = 0.0356 (3.421 sec/step)\n","I0611 13:49:14.005597 140666084398976 learning.py:507] global step 199596: loss = 0.0356 (3.421 sec/step)\n","INFO:tensorflow:global step 199597: loss = 0.0497 (3.506 sec/step)\n","I0611 13:49:17.513844 140666084398976 learning.py:507] global step 199597: loss = 0.0497 (3.506 sec/step)\n","INFO:tensorflow:global step 199598: loss = 0.0303 (3.578 sec/step)\n","I0611 13:49:21.093882 140666084398976 learning.py:507] global step 199598: loss = 0.0303 (3.578 sec/step)\n","INFO:tensorflow:global step 199599: loss = 0.0451 (3.487 sec/step)\n","I0611 13:49:24.582886 140666084398976 learning.py:507] global step 199599: loss = 0.0451 (3.487 sec/step)\n","INFO:tensorflow:global step 199600: loss = 0.0309 (3.523 sec/step)\n","I0611 13:49:28.107808 140666084398976 learning.py:507] global step 199600: loss = 0.0309 (3.523 sec/step)\n","INFO:tensorflow:global step 199601: loss = 0.0402 (3.491 sec/step)\n","I0611 13:49:31.600867 140666084398976 learning.py:507] global step 199601: loss = 0.0402 (3.491 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I0611 13:49:33.573623 140662755038976 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:global step 199602: loss = 0.0336 (3.530 sec/step)\n","I0611 13:49:35.266790 140666084398976 learning.py:507] global step 199602: loss = 0.0336 (3.530 sec/step)\n","INFO:tensorflow:Recording summary at step 199603.\n","I0611 13:49:40.332971 140662738253568 supervisor.py:1050] Recording summary at step 199603.\n","INFO:tensorflow:global step 199603: loss = 0.0299 (5.022 sec/step)\n","I0611 13:49:40.337363 140666084398976 learning.py:507] global step 199603: loss = 0.0299 (5.022 sec/step)\n","INFO:tensorflow:global step 199604: loss = 0.0394 (3.577 sec/step)\n","I0611 13:49:43.917690 140666084398976 learning.py:507] global step 199604: loss = 0.0394 (3.577 sec/step)\n","INFO:tensorflow:global step 199605: loss = 0.0362 (3.485 sec/step)\n","I0611 13:49:47.404245 140666084398976 learning.py:507] global step 199605: loss = 0.0362 (3.485 sec/step)\n","INFO:tensorflow:global step 199606: loss = 0.0349 (3.428 sec/step)\n","I0611 13:49:50.834394 140666084398976 learning.py:507] global step 199606: loss = 0.0349 (3.428 sec/step)\n","INFO:tensorflow:global step 199607: loss = 0.0483 (3.461 sec/step)\n","I0611 13:49:54.296688 140666084398976 learning.py:507] global step 199607: loss = 0.0483 (3.461 sec/step)\n","INFO:tensorflow:global step 199608: loss = 0.0453 (3.512 sec/step)\n","I0611 13:49:57.810298 140666084398976 learning.py:507] global step 199608: loss = 0.0453 (3.512 sec/step)\n","INFO:tensorflow:global step 199609: loss = 0.0245 (3.533 sec/step)\n","I0611 13:50:01.344825 140666084398976 learning.py:507] global step 199609: loss = 0.0245 (3.533 sec/step)\n","INFO:tensorflow:global step 199610: loss = 0.0298 (3.521 sec/step)\n","I0611 13:50:04.868204 140666084398976 learning.py:507] global step 199610: loss = 0.0298 (3.521 sec/step)\n","INFO:tensorflow:global step 199611: loss = 0.0253 (3.459 sec/step)\n","I0611 13:50:08.329448 140666084398976 learning.py:507] global step 199611: loss = 0.0253 (3.459 sec/step)\n","INFO:tensorflow:global step 199612: loss = 0.0339 (3.554 sec/step)\n","I0611 13:50:11.885343 140666084398976 learning.py:507] global step 199612: loss = 0.0339 (3.554 sec/step)\n","INFO:tensorflow:global step 199613: loss = 0.0470 (3.460 sec/step)\n","I0611 13:50:15.347257 140666084398976 learning.py:507] global step 199613: loss = 0.0470 (3.460 sec/step)\n","INFO:tensorflow:global step 199614: loss = 0.0644 (3.504 sec/step)\n","I0611 13:50:18.852843 140666084398976 learning.py:507] global step 199614: loss = 0.0644 (3.504 sec/step)\n","INFO:tensorflow:global step 199615: loss = 0.0217 (3.467 sec/step)\n","I0611 13:50:22.321466 140666084398976 learning.py:507] global step 199615: loss = 0.0217 (3.467 sec/step)\n","INFO:tensorflow:global step 199616: loss = 0.0501 (3.459 sec/step)\n","I0611 13:50:25.782312 140666084398976 learning.py:507] global step 199616: loss = 0.0501 (3.459 sec/step)\n","INFO:tensorflow:global step 199617: loss = 0.0434 (3.453 sec/step)\n","I0611 13:50:29.237088 140666084398976 learning.py:507] global step 199617: loss = 0.0434 (3.453 sec/step)\n","INFO:tensorflow:global step 199618: loss = 0.0385 (3.478 sec/step)\n","I0611 13:50:32.717087 140666084398976 learning.py:507] global step 199618: loss = 0.0385 (3.478 sec/step)\n","INFO:tensorflow:global step 199619: loss = 0.0339 (3.456 sec/step)\n","I0611 13:50:36.174862 140666084398976 learning.py:507] global step 199619: loss = 0.0339 (3.456 sec/step)\n","INFO:tensorflow:global step 199620: loss = 0.0499 (3.489 sec/step)\n","I0611 13:50:39.666208 140666084398976 learning.py:507] global step 199620: loss = 0.0499 (3.489 sec/step)\n","INFO:tensorflow:global step 199621: loss = 0.0359 (3.482 sec/step)\n","I0611 13:50:43.149914 140666084398976 learning.py:507] global step 199621: loss = 0.0359 (3.482 sec/step)\n","INFO:tensorflow:global step 199622: loss = 0.0258 (3.480 sec/step)\n","I0611 13:50:46.632313 140666084398976 learning.py:507] global step 199622: loss = 0.0258 (3.480 sec/step)\n","INFO:tensorflow:global step 199623: loss = 0.0302 (3.461 sec/step)\n","I0611 13:50:50.094965 140666084398976 learning.py:507] global step 199623: loss = 0.0302 (3.461 sec/step)\n","INFO:tensorflow:global step 199624: loss = 0.0251 (3.588 sec/step)\n","I0611 13:50:53.684551 140666084398976 learning.py:507] global step 199624: loss = 0.0251 (3.588 sec/step)\n","INFO:tensorflow:global step 199625: loss = 0.0420 (3.472 sec/step)\n","I0611 13:50:57.158435 140666084398976 learning.py:507] global step 199625: loss = 0.0420 (3.472 sec/step)\n","INFO:tensorflow:global step 199626: loss = 0.0311 (3.520 sec/step)\n","I0611 13:51:00.680649 140666084398976 learning.py:507] global step 199626: loss = 0.0311 (3.520 sec/step)\n","INFO:tensorflow:global step 199627: loss = 0.0322 (3.563 sec/step)\n","I0611 13:51:04.245312 140666084398976 learning.py:507] global step 199627: loss = 0.0322 (3.563 sec/step)\n","INFO:tensorflow:global step 199628: loss = 0.0404 (3.521 sec/step)\n","I0611 13:51:07.768616 140666084398976 learning.py:507] global step 199628: loss = 0.0404 (3.521 sec/step)\n","INFO:tensorflow:global step 199629: loss = 0.0400 (3.503 sec/step)\n","I0611 13:51:11.273787 140666084398976 learning.py:507] global step 199629: loss = 0.0400 (3.503 sec/step)\n","INFO:tensorflow:global step 199630: loss = 0.0283 (3.489 sec/step)\n","I0611 13:51:14.764576 140666084398976 learning.py:507] global step 199630: loss = 0.0283 (3.489 sec/step)\n","INFO:tensorflow:global step 199631: loss = 0.0261 (3.501 sec/step)\n","I0611 13:51:18.267275 140666084398976 learning.py:507] global step 199631: loss = 0.0261 (3.501 sec/step)\n","INFO:tensorflow:global step 199632: loss = 0.0364 (3.480 sec/step)\n","I0611 13:51:21.749322 140666084398976 learning.py:507] global step 199632: loss = 0.0364 (3.480 sec/step)\n","INFO:tensorflow:global step 199633: loss = 0.0315 (3.550 sec/step)\n","I0611 13:51:25.301634 140666084398976 learning.py:507] global step 199633: loss = 0.0315 (3.550 sec/step)\n","INFO:tensorflow:global step 199634: loss = 0.0379 (3.461 sec/step)\n","I0611 13:51:28.764346 140666084398976 learning.py:507] global step 199634: loss = 0.0379 (3.461 sec/step)\n","INFO:tensorflow:global step 199635: loss = 0.0364 (3.498 sec/step)\n","I0611 13:51:32.264100 140666084398976 learning.py:507] global step 199635: loss = 0.0364 (3.498 sec/step)\n","INFO:tensorflow:global step 199636: loss = 0.0320 (3.678 sec/step)\n","I0611 13:51:35.995175 140666084398976 learning.py:507] global step 199636: loss = 0.0320 (3.678 sec/step)\n","INFO:tensorflow:global step 199637: loss = 0.0496 (4.678 sec/step)\n","I0611 13:51:40.686282 140666084398976 learning.py:507] global step 199637: loss = 0.0496 (4.678 sec/step)\n","INFO:tensorflow:Recording summary at step 199637.\n","I0611 13:51:41.757769 140662738253568 supervisor.py:1050] Recording summary at step 199637.\n","INFO:tensorflow:global step 199638: loss = 0.0267 (3.670 sec/step)\n","I0611 13:51:44.366004 140666084398976 learning.py:507] global step 199638: loss = 0.0267 (3.670 sec/step)\n","INFO:tensorflow:global step 199639: loss = 0.0371 (3.488 sec/step)\n","I0611 13:51:47.856109 140666084398976 learning.py:507] global step 199639: loss = 0.0371 (3.488 sec/step)\n","INFO:tensorflow:global step 199640: loss = 0.0351 (3.454 sec/step)\n","I0611 13:51:51.311980 140666084398976 learning.py:507] global step 199640: loss = 0.0351 (3.454 sec/step)\n","INFO:tensorflow:global step 199641: loss = 0.0311 (3.485 sec/step)\n","I0611 13:51:54.799165 140666084398976 learning.py:507] global step 199641: loss = 0.0311 (3.485 sec/step)\n","INFO:tensorflow:global step 199642: loss = 0.0384 (3.436 sec/step)\n","I0611 13:51:58.236601 140666084398976 learning.py:507] global step 199642: loss = 0.0384 (3.436 sec/step)\n","INFO:tensorflow:global step 199643: loss = 0.0416 (3.551 sec/step)\n","I0611 13:52:01.790073 140666084398976 learning.py:507] global step 199643: loss = 0.0416 (3.551 sec/step)\n","INFO:tensorflow:global step 199644: loss = 0.0275 (3.487 sec/step)\n","I0611 13:52:05.279159 140666084398976 learning.py:507] global step 199644: loss = 0.0275 (3.487 sec/step)\n","INFO:tensorflow:global step 199645: loss = 0.0278 (3.658 sec/step)\n","I0611 13:52:08.938539 140666084398976 learning.py:507] global step 199645: loss = 0.0278 (3.658 sec/step)\n","INFO:tensorflow:global step 199646: loss = 0.0319 (3.465 sec/step)\n","I0611 13:52:12.405312 140666084398976 learning.py:507] global step 199646: loss = 0.0319 (3.465 sec/step)\n","INFO:tensorflow:global step 199647: loss = 0.0460 (3.518 sec/step)\n","I0611 13:52:15.924577 140666084398976 learning.py:507] global step 199647: loss = 0.0460 (3.518 sec/step)\n","INFO:tensorflow:global step 199648: loss = 0.0299 (3.563 sec/step)\n","I0611 13:52:19.489921 140666084398976 learning.py:507] global step 199648: loss = 0.0299 (3.563 sec/step)\n","INFO:tensorflow:global step 199649: loss = 0.0505 (3.431 sec/step)\n","I0611 13:52:22.922338 140666084398976 learning.py:507] global step 199649: loss = 0.0505 (3.431 sec/step)\n","INFO:tensorflow:global step 199650: loss = 0.0284 (3.528 sec/step)\n","I0611 13:52:26.452234 140666084398976 learning.py:507] global step 199650: loss = 0.0284 (3.528 sec/step)\n","INFO:tensorflow:global step 199651: loss = 0.0342 (3.501 sec/step)\n","I0611 13:52:29.955585 140666084398976 learning.py:507] global step 199651: loss = 0.0342 (3.501 sec/step)\n","INFO:tensorflow:global step 199652: loss = 0.0390 (3.523 sec/step)\n","I0611 13:52:33.480033 140666084398976 learning.py:507] global step 199652: loss = 0.0390 (3.523 sec/step)\n","INFO:tensorflow:global step 199653: loss = 0.0381 (3.561 sec/step)\n","I0611 13:52:37.043087 140666084398976 learning.py:507] global step 199653: loss = 0.0381 (3.561 sec/step)\n","INFO:tensorflow:global step 199654: loss = 0.0438 (3.511 sec/step)\n","I0611 13:52:40.556498 140666084398976 learning.py:507] global step 199654: loss = 0.0438 (3.511 sec/step)\n","INFO:tensorflow:global step 199655: loss = 0.0438 (3.495 sec/step)\n","I0611 13:52:44.053249 140666084398976 learning.py:507] global step 199655: loss = 0.0438 (3.495 sec/step)\n","INFO:tensorflow:global step 199656: loss = 0.0334 (3.424 sec/step)\n","I0611 13:52:47.479475 140666084398976 learning.py:507] global step 199656: loss = 0.0334 (3.424 sec/step)\n","INFO:tensorflow:global step 199657: loss = 0.0424 (3.555 sec/step)\n","I0611 13:52:51.036789 140666084398976 learning.py:507] global step 199657: loss = 0.0424 (3.555 sec/step)\n","INFO:tensorflow:global step 199658: loss = 0.0282 (3.469 sec/step)\n","I0611 13:52:54.507543 140666084398976 learning.py:507] global step 199658: loss = 0.0282 (3.469 sec/step)\n","INFO:tensorflow:global step 199659: loss = 0.0416 (3.421 sec/step)\n","I0611 13:52:57.930027 140666084398976 learning.py:507] global step 199659: loss = 0.0416 (3.421 sec/step)\n","INFO:tensorflow:global step 199660: loss = 0.0494 (3.524 sec/step)\n","I0611 13:53:01.456241 140666084398976 learning.py:507] global step 199660: loss = 0.0494 (3.524 sec/step)\n","INFO:tensorflow:global step 199661: loss = 0.0307 (3.495 sec/step)\n","I0611 13:53:04.952832 140666084398976 learning.py:507] global step 199661: loss = 0.0307 (3.495 sec/step)\n","INFO:tensorflow:global step 199662: loss = 0.0272 (3.445 sec/step)\n","I0611 13:53:08.399503 140666084398976 learning.py:507] global step 199662: loss = 0.0272 (3.445 sec/step)\n","INFO:tensorflow:global step 199663: loss = 0.0296 (3.480 sec/step)\n","I0611 13:53:11.881219 140666084398976 learning.py:507] global step 199663: loss = 0.0296 (3.480 sec/step)\n","INFO:tensorflow:global step 199664: loss = 0.0381 (3.616 sec/step)\n","I0611 13:53:15.499139 140666084398976 learning.py:507] global step 199664: loss = 0.0381 (3.616 sec/step)\n","INFO:tensorflow:global step 199665: loss = 0.0429 (3.521 sec/step)\n","I0611 13:53:19.021894 140666084398976 learning.py:507] global step 199665: loss = 0.0429 (3.521 sec/step)\n","INFO:tensorflow:global step 199666: loss = 0.0250 (3.425 sec/step)\n","I0611 13:53:22.448978 140666084398976 learning.py:507] global step 199666: loss = 0.0250 (3.425 sec/step)\n","INFO:tensorflow:global step 199667: loss = 0.0639 (3.445 sec/step)\n","I0611 13:53:25.896992 140666084398976 learning.py:507] global step 199667: loss = 0.0639 (3.445 sec/step)\n","INFO:tensorflow:global step 199668: loss = 0.0250 (3.429 sec/step)\n","I0611 13:53:29.328200 140666084398976 learning.py:507] global step 199668: loss = 0.0250 (3.429 sec/step)\n","INFO:tensorflow:global step 199669: loss = 0.0424 (3.465 sec/step)\n","I0611 13:53:32.796218 140666084398976 learning.py:507] global step 199669: loss = 0.0424 (3.465 sec/step)\n","INFO:tensorflow:global step 199670: loss = 0.0390 (3.952 sec/step)\n","I0611 13:53:37.068869 140666084398976 learning.py:507] global step 199670: loss = 0.0390 (3.952 sec/step)\n","INFO:tensorflow:Recording summary at step 199670.\n","I0611 13:53:38.655893 140662738253568 supervisor.py:1050] Recording summary at step 199670.\n","INFO:tensorflow:global step 199671: loss = 0.0345 (4.064 sec/step)\n","I0611 13:53:41.135049 140666084398976 learning.py:507] global step 199671: loss = 0.0345 (4.064 sec/step)\n","INFO:tensorflow:global step 199672: loss = 0.0355 (3.455 sec/step)\n","I0611 13:53:44.592157 140666084398976 learning.py:507] global step 199672: loss = 0.0355 (3.455 sec/step)\n","INFO:tensorflow:global step 199673: loss = 0.0247 (3.504 sec/step)\n","I0611 13:53:48.101241 140666084398976 learning.py:507] global step 199673: loss = 0.0247 (3.504 sec/step)\n","INFO:tensorflow:global step 199674: loss = 0.0460 (3.514 sec/step)\n","I0611 13:53:51.617486 140666084398976 learning.py:507] global step 199674: loss = 0.0460 (3.514 sec/step)\n","INFO:tensorflow:global step 199675: loss = 0.0290 (3.497 sec/step)\n","I0611 13:53:55.116798 140666084398976 learning.py:507] global step 199675: loss = 0.0290 (3.497 sec/step)\n","INFO:tensorflow:global step 199676: loss = 0.0342 (3.515 sec/step)\n","I0611 13:53:58.633622 140666084398976 learning.py:507] global step 199676: loss = 0.0342 (3.515 sec/step)\n","INFO:tensorflow:global step 199677: loss = 0.0315 (3.472 sec/step)\n","I0611 13:54:02.107928 140666084398976 learning.py:507] global step 199677: loss = 0.0315 (3.472 sec/step)\n","INFO:tensorflow:global step 199678: loss = 0.0541 (3.528 sec/step)\n","I0611 13:54:05.637912 140666084398976 learning.py:507] global step 199678: loss = 0.0541 (3.528 sec/step)\n","INFO:tensorflow:global step 199679: loss = 0.0493 (3.473 sec/step)\n","I0611 13:54:09.113286 140666084398976 learning.py:507] global step 199679: loss = 0.0493 (3.473 sec/step)\n","INFO:tensorflow:global step 199680: loss = 0.0384 (3.554 sec/step)\n","I0611 13:54:12.669353 140666084398976 learning.py:507] global step 199680: loss = 0.0384 (3.554 sec/step)\n","INFO:tensorflow:global step 199681: loss = 0.0406 (3.482 sec/step)\n","I0611 13:54:16.153189 140666084398976 learning.py:507] global step 199681: loss = 0.0406 (3.482 sec/step)\n","INFO:tensorflow:global step 199682: loss = 0.0508 (3.517 sec/step)\n","I0611 13:54:19.671760 140666084398976 learning.py:507] global step 199682: loss = 0.0508 (3.517 sec/step)\n","INFO:tensorflow:global step 199683: loss = 0.0289 (3.451 sec/step)\n","I0611 13:54:23.125032 140666084398976 learning.py:507] global step 199683: loss = 0.0289 (3.451 sec/step)\n","INFO:tensorflow:global step 199684: loss = 0.0369 (3.513 sec/step)\n","I0611 13:54:26.640233 140666084398976 learning.py:507] global step 199684: loss = 0.0369 (3.513 sec/step)\n","INFO:tensorflow:global step 199685: loss = 0.0455 (3.486 sec/step)\n","I0611 13:54:30.128138 140666084398976 learning.py:507] global step 199685: loss = 0.0455 (3.486 sec/step)\n","INFO:tensorflow:global step 199686: loss = 0.0392 (3.526 sec/step)\n","I0611 13:54:33.655981 140666084398976 learning.py:507] global step 199686: loss = 0.0392 (3.526 sec/step)\n","INFO:tensorflow:global step 199687: loss = 0.0313 (3.451 sec/step)\n","I0611 13:54:37.108274 140666084398976 learning.py:507] global step 199687: loss = 0.0313 (3.451 sec/step)\n","INFO:tensorflow:global step 199688: loss = 0.0293 (3.509 sec/step)\n","I0611 13:54:40.619572 140666084398976 learning.py:507] global step 199688: loss = 0.0293 (3.509 sec/step)\n","INFO:tensorflow:global step 199689: loss = 0.0526 (3.536 sec/step)\n","I0611 13:54:44.157176 140666084398976 learning.py:507] global step 199689: loss = 0.0526 (3.536 sec/step)\n","INFO:tensorflow:global step 199690: loss = 0.0394 (3.469 sec/step)\n","I0611 13:54:47.627906 140666084398976 learning.py:507] global step 199690: loss = 0.0394 (3.469 sec/step)\n","INFO:tensorflow:global step 199691: loss = 0.0233 (3.511 sec/step)\n","I0611 13:54:51.141025 140666084398976 learning.py:507] global step 199691: loss = 0.0233 (3.511 sec/step)\n","INFO:tensorflow:global step 199692: loss = 0.0391 (3.550 sec/step)\n","I0611 13:54:54.692981 140666084398976 learning.py:507] global step 199692: loss = 0.0391 (3.550 sec/step)\n","INFO:tensorflow:global step 199693: loss = 0.0366 (3.535 sec/step)\n","I0611 13:54:58.229637 140666084398976 learning.py:507] global step 199693: loss = 0.0366 (3.535 sec/step)\n","INFO:tensorflow:global step 199694: loss = 0.0291 (3.476 sec/step)\n","I0611 13:55:01.708193 140666084398976 learning.py:507] global step 199694: loss = 0.0291 (3.476 sec/step)\n","INFO:tensorflow:global step 199695: loss = 0.0236 (3.531 sec/step)\n","I0611 13:55:05.240901 140666084398976 learning.py:507] global step 199695: loss = 0.0236 (3.531 sec/step)\n","INFO:tensorflow:global step 199696: loss = 0.0445 (3.545 sec/step)\n","I0611 13:55:08.787876 140666084398976 learning.py:507] global step 199696: loss = 0.0445 (3.545 sec/step)\n","INFO:tensorflow:global step 199697: loss = 0.0369 (3.494 sec/step)\n","I0611 13:55:12.283473 140666084398976 learning.py:507] global step 199697: loss = 0.0369 (3.494 sec/step)\n","INFO:tensorflow:global step 199698: loss = 0.0297 (3.460 sec/step)\n","I0611 13:55:15.745486 140666084398976 learning.py:507] global step 199698: loss = 0.0297 (3.460 sec/step)\n","INFO:tensorflow:global step 199699: loss = 0.0492 (3.494 sec/step)\n","I0611 13:55:19.241701 140666084398976 learning.py:507] global step 199699: loss = 0.0492 (3.494 sec/step)\n","INFO:tensorflow:global step 199700: loss = 0.0321 (3.478 sec/step)\n","I0611 13:55:22.722272 140666084398976 learning.py:507] global step 199700: loss = 0.0321 (3.478 sec/step)\n","INFO:tensorflow:global step 199701: loss = 0.0331 (3.596 sec/step)\n","I0611 13:55:26.320561 140666084398976 learning.py:507] global step 199701: loss = 0.0331 (3.596 sec/step)\n","INFO:tensorflow:global step 199702: loss = 0.0495 (3.511 sec/step)\n","I0611 13:55:29.833717 140666084398976 learning.py:507] global step 199702: loss = 0.0495 (3.511 sec/step)\n","INFO:tensorflow:global step 199703: loss = 0.0349 (3.509 sec/step)\n","I0611 13:55:33.344256 140666084398976 learning.py:507] global step 199703: loss = 0.0349 (3.509 sec/step)\n","INFO:tensorflow:global step 199704: loss = 0.0309 (4.057 sec/step)\n","I0611 13:55:37.775770 140666084398976 learning.py:507] global step 199704: loss = 0.0309 (4.057 sec/step)\n","INFO:tensorflow:Recording summary at step 199704.\n","I0611 13:55:39.516464 140662738253568 supervisor.py:1050] Recording summary at step 199704.\n","INFO:tensorflow:global step 199705: loss = 0.0240 (3.986 sec/step)\n","I0611 13:55:41.795745 140666084398976 learning.py:507] global step 199705: loss = 0.0240 (3.986 sec/step)\n","INFO:tensorflow:global step 199706: loss = 0.0413 (3.540 sec/step)\n","I0611 13:55:45.337708 140666084398976 learning.py:507] global step 199706: loss = 0.0413 (3.540 sec/step)\n","INFO:tensorflow:global step 199707: loss = 0.0480 (3.422 sec/step)\n","I0611 13:55:48.761996 140666084398976 learning.py:507] global step 199707: loss = 0.0480 (3.422 sec/step)\n","INFO:tensorflow:global step 199708: loss = 0.0249 (3.519 sec/step)\n","I0611 13:55:52.282322 140666084398976 learning.py:507] global step 199708: loss = 0.0249 (3.519 sec/step)\n","INFO:tensorflow:global step 199709: loss = 0.0347 (3.626 sec/step)\n","I0611 13:55:55.914519 140666084398976 learning.py:507] global step 199709: loss = 0.0347 (3.626 sec/step)\n","INFO:tensorflow:global step 199710: loss = 0.0450 (3.533 sec/step)\n","I0611 13:55:59.449682 140666084398976 learning.py:507] global step 199710: loss = 0.0450 (3.533 sec/step)\n","INFO:tensorflow:global step 199711: loss = 0.0294 (3.474 sec/step)\n","I0611 13:56:02.925367 140666084398976 learning.py:507] global step 199711: loss = 0.0294 (3.474 sec/step)\n","INFO:tensorflow:global step 199712: loss = 0.0315 (3.487 sec/step)\n","I0611 13:56:06.414072 140666084398976 learning.py:507] global step 199712: loss = 0.0315 (3.487 sec/step)\n","INFO:tensorflow:global step 199713: loss = 0.0422 (3.444 sec/step)\n","I0611 13:56:09.859825 140666084398976 learning.py:507] global step 199713: loss = 0.0422 (3.444 sec/step)\n","INFO:tensorflow:global step 199714: loss = 0.0402 (3.519 sec/step)\n","I0611 13:56:13.380099 140666084398976 learning.py:507] global step 199714: loss = 0.0402 (3.519 sec/step)\n","INFO:tensorflow:global step 199715: loss = 0.0440 (3.475 sec/step)\n","I0611 13:56:16.857002 140666084398976 learning.py:507] global step 199715: loss = 0.0440 (3.475 sec/step)\n","INFO:tensorflow:global step 199716: loss = 0.0299 (3.547 sec/step)\n","I0611 13:56:20.405939 140666084398976 learning.py:507] global step 199716: loss = 0.0299 (3.547 sec/step)\n","INFO:tensorflow:global step 199717: loss = 0.0353 (3.439 sec/step)\n","I0611 13:56:23.846895 140666084398976 learning.py:507] global step 199717: loss = 0.0353 (3.439 sec/step)\n","INFO:tensorflow:global step 199718: loss = 0.0390 (3.449 sec/step)\n","I0611 13:56:27.297272 140666084398976 learning.py:507] global step 199718: loss = 0.0390 (3.449 sec/step)\n","INFO:tensorflow:global step 199719: loss = 0.0305 (3.464 sec/step)\n","I0611 13:56:30.762952 140666084398976 learning.py:507] global step 199719: loss = 0.0305 (3.464 sec/step)\n","INFO:tensorflow:global step 199720: loss = 0.0336 (3.604 sec/step)\n","I0611 13:56:34.369010 140666084398976 learning.py:507] global step 199720: loss = 0.0336 (3.604 sec/step)\n","INFO:tensorflow:global step 199721: loss = 0.0280 (3.470 sec/step)\n","I0611 13:56:37.841050 140666084398976 learning.py:507] global step 199721: loss = 0.0280 (3.470 sec/step)\n","INFO:tensorflow:global step 199722: loss = 0.0342 (3.552 sec/step)\n","I0611 13:56:41.395342 140666084398976 learning.py:507] global step 199722: loss = 0.0342 (3.552 sec/step)\n","INFO:tensorflow:global step 199723: loss = 0.0372 (3.473 sec/step)\n","I0611 13:56:44.869986 140666084398976 learning.py:507] global step 199723: loss = 0.0372 (3.473 sec/step)\n","INFO:tensorflow:global step 199724: loss = 0.0290 (3.438 sec/step)\n","I0611 13:56:48.311845 140666084398976 learning.py:507] global step 199724: loss = 0.0290 (3.438 sec/step)\n","INFO:tensorflow:global step 199725: loss = 0.0331 (3.503 sec/step)\n","I0611 13:56:51.821346 140666084398976 learning.py:507] global step 199725: loss = 0.0331 (3.503 sec/step)\n","INFO:tensorflow:global step 199726: loss = 0.0264 (3.452 sec/step)\n","I0611 13:56:55.275318 140666084398976 learning.py:507] global step 199726: loss = 0.0264 (3.452 sec/step)\n","INFO:tensorflow:global step 199727: loss = 0.0365 (3.480 sec/step)\n","I0611 13:56:58.757050 140666084398976 learning.py:507] global step 199727: loss = 0.0365 (3.480 sec/step)\n","INFO:tensorflow:global step 199728: loss = 0.0313 (3.467 sec/step)\n","I0611 13:57:02.226228 140666084398976 learning.py:507] global step 199728: loss = 0.0313 (3.467 sec/step)\n","INFO:tensorflow:global step 199729: loss = 0.0493 (3.506 sec/step)\n","I0611 13:57:05.733532 140666084398976 learning.py:507] global step 199729: loss = 0.0493 (3.506 sec/step)\n","INFO:tensorflow:global step 199730: loss = 0.0315 (3.536 sec/step)\n","I0611 13:57:09.271781 140666084398976 learning.py:507] global step 199730: loss = 0.0315 (3.536 sec/step)\n","INFO:tensorflow:global step 199731: loss = 0.0375 (3.493 sec/step)\n","I0611 13:57:12.767211 140666084398976 learning.py:507] global step 199731: loss = 0.0375 (3.493 sec/step)\n","INFO:tensorflow:global step 199732: loss = 0.0294 (3.412 sec/step)\n","I0611 13:57:16.181647 140666084398976 learning.py:507] global step 199732: loss = 0.0294 (3.412 sec/step)\n","INFO:tensorflow:global step 199733: loss = 0.0347 (3.485 sec/step)\n","I0611 13:57:19.669541 140666084398976 learning.py:507] global step 199733: loss = 0.0347 (3.485 sec/step)\n","INFO:tensorflow:global step 199734: loss = 0.0358 (3.513 sec/step)\n","I0611 13:57:23.184321 140666084398976 learning.py:507] global step 199734: loss = 0.0358 (3.513 sec/step)\n","INFO:tensorflow:global step 199735: loss = 0.0198 (3.455 sec/step)\n","I0611 13:57:26.640638 140666084398976 learning.py:507] global step 199735: loss = 0.0198 (3.455 sec/step)\n","INFO:tensorflow:global step 199736: loss = 0.0329 (3.507 sec/step)\n","I0611 13:57:30.149251 140666084398976 learning.py:507] global step 199736: loss = 0.0329 (3.507 sec/step)\n","INFO:tensorflow:global step 199737: loss = 0.0393 (3.521 sec/step)\n","I0611 13:57:33.672730 140666084398976 learning.py:507] global step 199737: loss = 0.0393 (3.521 sec/step)\n","INFO:tensorflow:global step 199738: loss = 0.0404 (3.886 sec/step)\n","I0611 13:57:37.813945 140666084398976 learning.py:507] global step 199738: loss = 0.0404 (3.886 sec/step)\n","INFO:tensorflow:Recording summary at step 199738.\n","I0611 13:57:39.494991 140662738253568 supervisor.py:1050] Recording summary at step 199738.\n","INFO:tensorflow:global step 199739: loss = 0.0478 (3.851 sec/step)\n","I0611 13:57:41.981554 140666084398976 learning.py:507] global step 199739: loss = 0.0478 (3.851 sec/step)\n","INFO:tensorflow:global step 199740: loss = 0.0455 (3.408 sec/step)\n","I0611 13:57:45.391344 140666084398976 learning.py:507] global step 199740: loss = 0.0455 (3.408 sec/step)\n","INFO:tensorflow:global step 199741: loss = 0.0455 (3.570 sec/step)\n","I0611 13:57:48.966846 140666084398976 learning.py:507] global step 199741: loss = 0.0455 (3.570 sec/step)\n","INFO:tensorflow:global step 199742: loss = 0.0343 (3.512 sec/step)\n","I0611 13:57:52.480644 140666084398976 learning.py:507] global step 199742: loss = 0.0343 (3.512 sec/step)\n","INFO:tensorflow:global step 199743: loss = 0.0370 (3.473 sec/step)\n","I0611 13:57:55.955263 140666084398976 learning.py:507] global step 199743: loss = 0.0370 (3.473 sec/step)\n","INFO:tensorflow:global step 199744: loss = 0.0215 (3.430 sec/step)\n","I0611 13:57:59.387320 140666084398976 learning.py:507] global step 199744: loss = 0.0215 (3.430 sec/step)\n","INFO:tensorflow:global step 199745: loss = 0.0431 (3.441 sec/step)\n","I0611 13:58:02.830428 140666084398976 learning.py:507] global step 199745: loss = 0.0431 (3.441 sec/step)\n","INFO:tensorflow:global step 199746: loss = 0.0417 (3.464 sec/step)\n","I0611 13:58:06.296035 140666084398976 learning.py:507] global step 199746: loss = 0.0417 (3.464 sec/step)\n","INFO:tensorflow:global step 199747: loss = 0.0321 (3.462 sec/step)\n","I0611 13:58:09.760066 140666084398976 learning.py:507] global step 199747: loss = 0.0321 (3.462 sec/step)\n","INFO:tensorflow:global step 199748: loss = 0.0339 (3.530 sec/step)\n","I0611 13:58:13.291720 140666084398976 learning.py:507] global step 199748: loss = 0.0339 (3.530 sec/step)\n","INFO:tensorflow:global step 199749: loss = 0.0242 (3.508 sec/step)\n","I0611 13:58:16.801319 140666084398976 learning.py:507] global step 199749: loss = 0.0242 (3.508 sec/step)\n","INFO:tensorflow:global step 199750: loss = 0.0382 (3.470 sec/step)\n","I0611 13:58:20.273262 140666084398976 learning.py:507] global step 199750: loss = 0.0382 (3.470 sec/step)\n","INFO:tensorflow:global step 199751: loss = 0.0323 (3.566 sec/step)\n","I0611 13:58:23.841627 140666084398976 learning.py:507] global step 199751: loss = 0.0323 (3.566 sec/step)\n","INFO:tensorflow:global step 199752: loss = 0.0249 (3.441 sec/step)\n","I0611 13:58:27.284458 140666084398976 learning.py:507] global step 199752: loss = 0.0249 (3.441 sec/step)\n","INFO:tensorflow:global step 199753: loss = 0.0303 (3.463 sec/step)\n","I0611 13:58:30.748874 140666084398976 learning.py:507] global step 199753: loss = 0.0303 (3.463 sec/step)\n","INFO:tensorflow:global step 199754: loss = 0.0351 (3.498 sec/step)\n","I0611 13:58:34.248637 140666084398976 learning.py:507] global step 199754: loss = 0.0351 (3.498 sec/step)\n","INFO:tensorflow:global step 199755: loss = 0.0554 (3.465 sec/step)\n","I0611 13:58:37.715895 140666084398976 learning.py:507] global step 199755: loss = 0.0554 (3.465 sec/step)\n","INFO:tensorflow:global step 199756: loss = 0.0345 (3.471 sec/step)\n","I0611 13:58:41.189531 140666084398976 learning.py:507] global step 199756: loss = 0.0345 (3.471 sec/step)\n","INFO:tensorflow:global step 199757: loss = 0.0387 (3.407 sec/step)\n","I0611 13:58:44.598304 140666084398976 learning.py:507] global step 199757: loss = 0.0387 (3.407 sec/step)\n","INFO:tensorflow:global step 199758: loss = 0.0312 (3.534 sec/step)\n","I0611 13:58:48.134130 140666084398976 learning.py:507] global step 199758: loss = 0.0312 (3.534 sec/step)\n","INFO:tensorflow:global step 199759: loss = 0.0303 (3.492 sec/step)\n","I0611 13:58:51.628074 140666084398976 learning.py:507] global step 199759: loss = 0.0303 (3.492 sec/step)\n","INFO:tensorflow:global step 199760: loss = 0.0468 (3.498 sec/step)\n","I0611 13:58:55.127698 140666084398976 learning.py:507] global step 199760: loss = 0.0468 (3.498 sec/step)\n","INFO:tensorflow:global step 199761: loss = 0.0327 (3.570 sec/step)\n","I0611 13:58:58.699792 140666084398976 learning.py:507] global step 199761: loss = 0.0327 (3.570 sec/step)\n","INFO:tensorflow:global step 199762: loss = 0.0316 (3.518 sec/step)\n","I0611 13:59:02.219574 140666084398976 learning.py:507] global step 199762: loss = 0.0316 (3.518 sec/step)\n","INFO:tensorflow:global step 199763: loss = 0.0463 (3.461 sec/step)\n","I0611 13:59:05.682706 140666084398976 learning.py:507] global step 199763: loss = 0.0463 (3.461 sec/step)\n","INFO:tensorflow:global step 199764: loss = 0.0382 (3.545 sec/step)\n","I0611 13:59:09.229483 140666084398976 learning.py:507] global step 199764: loss = 0.0382 (3.545 sec/step)\n","INFO:tensorflow:global step 199765: loss = 0.0315 (3.540 sec/step)\n","I0611 13:59:12.771555 140666084398976 learning.py:507] global step 199765: loss = 0.0315 (3.540 sec/step)\n","INFO:tensorflow:global step 199766: loss = 0.0405 (3.418 sec/step)\n","I0611 13:59:16.191836 140666084398976 learning.py:507] global step 199766: loss = 0.0405 (3.418 sec/step)\n","INFO:tensorflow:global step 199767: loss = 0.0363 (3.596 sec/step)\n","I0611 13:59:19.790185 140666084398976 learning.py:507] global step 199767: loss = 0.0363 (3.596 sec/step)\n","INFO:tensorflow:global step 199768: loss = 0.0329 (3.540 sec/step)\n","I0611 13:59:23.331878 140666084398976 learning.py:507] global step 199768: loss = 0.0329 (3.540 sec/step)\n","INFO:tensorflow:global step 199769: loss = 0.0291 (3.513 sec/step)\n","I0611 13:59:26.846483 140666084398976 learning.py:507] global step 199769: loss = 0.0291 (3.513 sec/step)\n","INFO:tensorflow:global step 199770: loss = 0.0381 (3.513 sec/step)\n","I0611 13:59:30.360912 140666084398976 learning.py:507] global step 199770: loss = 0.0381 (3.513 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I0611 13:59:33.575002 140662755038976 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:global step 199771: loss = 0.0271 (3.526 sec/step)\n","I0611 13:59:33.889631 140666084398976 learning.py:507] global step 199771: loss = 0.0271 (3.526 sec/step)\n","INFO:tensorflow:global step 199772: loss = 0.0272 (5.225 sec/step)\n","I0611 13:59:39.462512 140666084398976 learning.py:507] global step 199772: loss = 0.0272 (5.225 sec/step)\n","INFO:tensorflow:Recording summary at step 199772.\n","I0611 13:59:39.462889 140662738253568 supervisor.py:1050] Recording summary at step 199772.\n","INFO:tensorflow:global step 199773: loss = 0.0429 (3.494 sec/step)\n","I0611 13:59:42.959402 140666084398976 learning.py:507] global step 199773: loss = 0.0429 (3.494 sec/step)\n","INFO:tensorflow:global step 199774: loss = 0.0286 (3.465 sec/step)\n","I0611 13:59:46.425982 140666084398976 learning.py:507] global step 199774: loss = 0.0286 (3.465 sec/step)\n","INFO:tensorflow:global step 199775: loss = 0.0358 (3.458 sec/step)\n","I0611 13:59:49.885511 140666084398976 learning.py:507] global step 199775: loss = 0.0358 (3.458 sec/step)\n","INFO:tensorflow:global step 199776: loss = 0.0243 (3.624 sec/step)\n","I0611 13:59:53.511482 140666084398976 learning.py:507] global step 199776: loss = 0.0243 (3.624 sec/step)\n","INFO:tensorflow:global step 199777: loss = 0.0399 (3.461 sec/step)\n","I0611 13:59:56.974531 140666084398976 learning.py:507] global step 199777: loss = 0.0399 (3.461 sec/step)\n","INFO:tensorflow:global step 199778: loss = 0.0299 (3.458 sec/step)\n","I0611 14:00:00.434571 140666084398976 learning.py:507] global step 199778: loss = 0.0299 (3.458 sec/step)\n","INFO:tensorflow:global step 199779: loss = 0.0316 (3.491 sec/step)\n","I0611 14:00:03.927892 140666084398976 learning.py:507] global step 199779: loss = 0.0316 (3.491 sec/step)\n","INFO:tensorflow:global step 199780: loss = 0.0300 (3.457 sec/step)\n","I0611 14:00:07.387119 140666084398976 learning.py:507] global step 199780: loss = 0.0300 (3.457 sec/step)\n","INFO:tensorflow:global step 199781: loss = 0.0375 (3.486 sec/step)\n","I0611 14:00:10.874811 140666084398976 learning.py:507] global step 199781: loss = 0.0375 (3.486 sec/step)\n","INFO:tensorflow:global step 199782: loss = 0.0492 (3.465 sec/step)\n","I0611 14:00:14.342171 140666084398976 learning.py:507] global step 199782: loss = 0.0492 (3.465 sec/step)\n","INFO:tensorflow:global step 199783: loss = 0.0347 (3.534 sec/step)\n","I0611 14:00:17.878410 140666084398976 learning.py:507] global step 199783: loss = 0.0347 (3.534 sec/step)\n","INFO:tensorflow:global step 199784: loss = 0.0382 (3.479 sec/step)\n","I0611 14:00:21.358734 140666084398976 learning.py:507] global step 199784: loss = 0.0382 (3.479 sec/step)\n","INFO:tensorflow:global step 199785: loss = 0.0430 (3.487 sec/step)\n","I0611 14:00:24.847018 140666084398976 learning.py:507] global step 199785: loss = 0.0430 (3.487 sec/step)\n","INFO:tensorflow:global step 199786: loss = 0.0377 (3.540 sec/step)\n","I0611 14:00:28.388506 140666084398976 learning.py:507] global step 199786: loss = 0.0377 (3.540 sec/step)\n","INFO:tensorflow:global step 199787: loss = 0.0318 (3.515 sec/step)\n","I0611 14:00:31.904829 140666084398976 learning.py:507] global step 199787: loss = 0.0318 (3.515 sec/step)\n","INFO:tensorflow:global step 199788: loss = 0.0387 (3.484 sec/step)\n","I0611 14:00:35.390795 140666084398976 learning.py:507] global step 199788: loss = 0.0387 (3.484 sec/step)\n","INFO:tensorflow:global step 199789: loss = 0.0434 (3.481 sec/step)\n","I0611 14:00:38.873542 140666084398976 learning.py:507] global step 199789: loss = 0.0434 (3.481 sec/step)\n","INFO:tensorflow:global step 199790: loss = 0.0276 (3.480 sec/step)\n","I0611 14:00:42.355706 140666084398976 learning.py:507] global step 199790: loss = 0.0276 (3.480 sec/step)\n","INFO:tensorflow:global step 199791: loss = 0.0331 (3.491 sec/step)\n","I0611 14:00:45.848722 140666084398976 learning.py:507] global step 199791: loss = 0.0331 (3.491 sec/step)\n","INFO:tensorflow:global step 199792: loss = 0.0292 (3.512 sec/step)\n","I0611 14:00:49.362294 140666084398976 learning.py:507] global step 199792: loss = 0.0292 (3.512 sec/step)\n","INFO:tensorflow:global step 199793: loss = 0.0323 (3.475 sec/step)\n","I0611 14:00:52.838744 140666084398976 learning.py:507] global step 199793: loss = 0.0323 (3.475 sec/step)\n","INFO:tensorflow:global step 199794: loss = 0.0364 (3.492 sec/step)\n","I0611 14:00:56.332283 140666084398976 learning.py:507] global step 199794: loss = 0.0364 (3.492 sec/step)\n","INFO:tensorflow:global step 199795: loss = 0.0342 (3.433 sec/step)\n","I0611 14:00:59.766880 140666084398976 learning.py:507] global step 199795: loss = 0.0342 (3.433 sec/step)\n","INFO:tensorflow:global step 199796: loss = 0.0409 (3.552 sec/step)\n","I0611 14:01:03.320950 140666084398976 learning.py:507] global step 199796: loss = 0.0409 (3.552 sec/step)\n","INFO:tensorflow:global step 199797: loss = 0.0201 (3.590 sec/step)\n","I0611 14:01:06.913086 140666084398976 learning.py:507] global step 199797: loss = 0.0201 (3.590 sec/step)\n","INFO:tensorflow:global step 199798: loss = 0.0337 (3.487 sec/step)\n","I0611 14:01:10.402115 140666084398976 learning.py:507] global step 199798: loss = 0.0337 (3.487 sec/step)\n","INFO:tensorflow:global step 199799: loss = 0.0378 (3.485 sec/step)\n","I0611 14:01:13.888988 140666084398976 learning.py:507] global step 199799: loss = 0.0378 (3.485 sec/step)\n","INFO:tensorflow:global step 199800: loss = 0.0364 (3.503 sec/step)\n","I0611 14:01:17.394106 140666084398976 learning.py:507] global step 199800: loss = 0.0364 (3.503 sec/step)\n","INFO:tensorflow:global step 199801: loss = 0.0521 (3.444 sec/step)\n","I0611 14:01:20.840094 140666084398976 learning.py:507] global step 199801: loss = 0.0521 (3.444 sec/step)\n","INFO:tensorflow:global step 199802: loss = 0.0233 (3.548 sec/step)\n","I0611 14:01:24.390891 140666084398976 learning.py:507] global step 199802: loss = 0.0233 (3.548 sec/step)\n","INFO:tensorflow:global step 199803: loss = 0.0491 (3.468 sec/step)\n","I0611 14:01:27.860607 140666084398976 learning.py:507] global step 199803: loss = 0.0491 (3.468 sec/step)\n","INFO:tensorflow:global step 199804: loss = 0.0279 (3.591 sec/step)\n","I0611 14:01:31.453621 140666084398976 learning.py:507] global step 199804: loss = 0.0279 (3.591 sec/step)\n","INFO:tensorflow:global step 199805: loss = 0.0475 (3.633 sec/step)\n","I0611 14:01:35.093019 140666084398976 learning.py:507] global step 199805: loss = 0.0475 (3.633 sec/step)\n","INFO:tensorflow:Recording summary at step 199805.\n","I0611 14:01:37.321905 140662738253568 supervisor.py:1050] Recording summary at step 199805.\n","INFO:tensorflow:global step 199806: loss = 0.0347 (4.485 sec/step)\n","I0611 14:01:39.580009 140666084398976 learning.py:507] global step 199806: loss = 0.0347 (4.485 sec/step)\n","INFO:tensorflow:global step 199807: loss = 0.0455 (3.473 sec/step)\n","I0611 14:01:43.054679 140666084398976 learning.py:507] global step 199807: loss = 0.0455 (3.473 sec/step)\n","INFO:tensorflow:global step 199808: loss = 0.0449 (3.496 sec/step)\n","I0611 14:01:46.552355 140666084398976 learning.py:507] global step 199808: loss = 0.0449 (3.496 sec/step)\n","INFO:tensorflow:global step 199809: loss = 0.0326 (3.476 sec/step)\n","I0611 14:01:50.030377 140666084398976 learning.py:507] global step 199809: loss = 0.0326 (3.476 sec/step)\n","INFO:tensorflow:global step 199810: loss = 0.0302 (3.445 sec/step)\n","I0611 14:01:53.477431 140666084398976 learning.py:507] global step 199810: loss = 0.0302 (3.445 sec/step)\n","INFO:tensorflow:global step 199811: loss = 0.0300 (3.523 sec/step)\n","I0611 14:01:57.001902 140666084398976 learning.py:507] global step 199811: loss = 0.0300 (3.523 sec/step)\n","INFO:tensorflow:global step 199812: loss = 0.0335 (3.532 sec/step)\n","I0611 14:02:00.535584 140666084398976 learning.py:507] global step 199812: loss = 0.0335 (3.532 sec/step)\n","INFO:tensorflow:global step 199813: loss = 0.0320 (3.449 sec/step)\n","I0611 14:02:03.986091 140666084398976 learning.py:507] global step 199813: loss = 0.0320 (3.449 sec/step)\n","INFO:tensorflow:global step 199814: loss = 0.0477 (3.513 sec/step)\n","I0611 14:02:07.501218 140666084398976 learning.py:507] global step 199814: loss = 0.0477 (3.513 sec/step)\n","INFO:tensorflow:global step 199815: loss = 0.0213 (3.438 sec/step)\n","I0611 14:02:10.941051 140666084398976 learning.py:507] global step 199815: loss = 0.0213 (3.438 sec/step)\n","INFO:tensorflow:global step 199816: loss = 0.0531 (3.547 sec/step)\n","I0611 14:02:14.490756 140666084398976 learning.py:507] global step 199816: loss = 0.0531 (3.547 sec/step)\n","INFO:tensorflow:global step 199817: loss = 0.0392 (3.528 sec/step)\n","I0611 14:02:18.025593 140666084398976 learning.py:507] global step 199817: loss = 0.0392 (3.528 sec/step)\n","INFO:tensorflow:global step 199818: loss = 0.0299 (3.487 sec/step)\n","I0611 14:02:21.514773 140666084398976 learning.py:507] global step 199818: loss = 0.0299 (3.487 sec/step)\n","INFO:tensorflow:global step 199819: loss = 0.0423 (3.512 sec/step)\n","I0611 14:02:25.028391 140666084398976 learning.py:507] global step 199819: loss = 0.0423 (3.512 sec/step)\n","INFO:tensorflow:global step 199820: loss = 0.0351 (3.488 sec/step)\n","I0611 14:02:28.518231 140666084398976 learning.py:507] global step 199820: loss = 0.0351 (3.488 sec/step)\n","INFO:tensorflow:global step 199821: loss = 0.0318 (3.602 sec/step)\n","I0611 14:02:32.121831 140666084398976 learning.py:507] global step 199821: loss = 0.0318 (3.602 sec/step)\n","INFO:tensorflow:global step 199822: loss = 0.0359 (3.487 sec/step)\n","I0611 14:02:35.611002 140666084398976 learning.py:507] global step 199822: loss = 0.0359 (3.487 sec/step)\n","INFO:tensorflow:global step 199823: loss = 0.0392 (3.516 sec/step)\n","I0611 14:02:39.128859 140666084398976 learning.py:507] global step 199823: loss = 0.0392 (3.516 sec/step)\n","INFO:tensorflow:global step 199824: loss = 0.0300 (3.557 sec/step)\n","I0611 14:02:42.687425 140666084398976 learning.py:507] global step 199824: loss = 0.0300 (3.557 sec/step)\n","INFO:tensorflow:global step 199825: loss = 0.0459 (3.478 sec/step)\n","I0611 14:02:46.167595 140666084398976 learning.py:507] global step 199825: loss = 0.0459 (3.478 sec/step)\n","INFO:tensorflow:global step 199826: loss = 0.0353 (3.572 sec/step)\n","I0611 14:02:49.741110 140666084398976 learning.py:507] global step 199826: loss = 0.0353 (3.572 sec/step)\n","INFO:tensorflow:global step 199827: loss = 0.0311 (3.426 sec/step)\n","I0611 14:02:53.168528 140666084398976 learning.py:507] global step 199827: loss = 0.0311 (3.426 sec/step)\n","INFO:tensorflow:global step 199828: loss = 0.0376 (3.653 sec/step)\n","I0611 14:02:56.823740 140666084398976 learning.py:507] global step 199828: loss = 0.0376 (3.653 sec/step)\n","INFO:tensorflow:global step 199829: loss = 0.0353 (3.482 sec/step)\n","I0611 14:03:00.307789 140666084398976 learning.py:507] global step 199829: loss = 0.0353 (3.482 sec/step)\n","INFO:tensorflow:global step 199830: loss = 0.0385 (3.516 sec/step)\n","I0611 14:03:03.825847 140666084398976 learning.py:507] global step 199830: loss = 0.0385 (3.516 sec/step)\n","INFO:tensorflow:global step 199831: loss = 0.0326 (3.457 sec/step)\n","I0611 14:03:07.284425 140666084398976 learning.py:507] global step 199831: loss = 0.0326 (3.457 sec/step)\n","INFO:tensorflow:global step 199832: loss = 0.0286 (3.436 sec/step)\n","I0611 14:03:10.722340 140666084398976 learning.py:507] global step 199832: loss = 0.0286 (3.436 sec/step)\n","INFO:tensorflow:global step 199833: loss = 0.0362 (3.409 sec/step)\n","I0611 14:03:14.132838 140666084398976 learning.py:507] global step 199833: loss = 0.0362 (3.409 sec/step)\n","INFO:tensorflow:global step 199834: loss = 0.0214 (3.434 sec/step)\n","I0611 14:03:17.568578 140666084398976 learning.py:507] global step 199834: loss = 0.0214 (3.434 sec/step)\n","INFO:tensorflow:global step 199835: loss = 0.0328 (3.487 sec/step)\n","I0611 14:03:21.057105 140666084398976 learning.py:507] global step 199835: loss = 0.0328 (3.487 sec/step)\n","INFO:tensorflow:global step 199836: loss = 0.0290 (3.518 sec/step)\n","I0611 14:03:24.576995 140666084398976 learning.py:507] global step 199836: loss = 0.0290 (3.518 sec/step)\n","INFO:tensorflow:global step 199837: loss = 0.0602 (3.440 sec/step)\n","I0611 14:03:28.019096 140666084398976 learning.py:507] global step 199837: loss = 0.0602 (3.440 sec/step)\n","INFO:tensorflow:global step 199838: loss = 0.0438 (3.509 sec/step)\n","I0611 14:03:31.529581 140666084398976 learning.py:507] global step 199838: loss = 0.0438 (3.509 sec/step)\n","INFO:tensorflow:global step 199839: loss = 0.0251 (3.477 sec/step)\n","I0611 14:03:35.008697 140666084398976 learning.py:507] global step 199839: loss = 0.0251 (3.477 sec/step)\n","INFO:tensorflow:Recording summary at step 199839.\n","I0611 14:03:37.015531 140662738253568 supervisor.py:1050] Recording summary at step 199839.\n","INFO:tensorflow:global step 199840: loss = 0.0313 (4.518 sec/step)\n","I0611 14:03:39.531868 140666084398976 learning.py:507] global step 199840: loss = 0.0313 (4.518 sec/step)\n","INFO:tensorflow:global step 199841: loss = 0.0339 (3.494 sec/step)\n","I0611 14:03:43.027148 140666084398976 learning.py:507] global step 199841: loss = 0.0339 (3.494 sec/step)\n","INFO:tensorflow:global step 199842: loss = 0.0523 (3.469 sec/step)\n","I0611 14:03:46.498100 140666084398976 learning.py:507] global step 199842: loss = 0.0523 (3.469 sec/step)\n","INFO:tensorflow:global step 199843: loss = 0.0288 (3.605 sec/step)\n","I0611 14:03:50.105021 140666084398976 learning.py:507] global step 199843: loss = 0.0288 (3.605 sec/step)\n","INFO:tensorflow:global step 199844: loss = 0.0243 (3.482 sec/step)\n","I0611 14:03:53.588937 140666084398976 learning.py:507] global step 199844: loss = 0.0243 (3.482 sec/step)\n","INFO:tensorflow:global step 199845: loss = 0.0361 (3.494 sec/step)\n","I0611 14:03:57.084387 140666084398976 learning.py:507] global step 199845: loss = 0.0361 (3.494 sec/step)\n","INFO:tensorflow:global step 199846: loss = 0.0394 (3.463 sec/step)\n","I0611 14:04:00.549776 140666084398976 learning.py:507] global step 199846: loss = 0.0394 (3.463 sec/step)\n","INFO:tensorflow:global step 199847: loss = 0.0289 (3.509 sec/step)\n","I0611 14:04:04.060363 140666084398976 learning.py:507] global step 199847: loss = 0.0289 (3.509 sec/step)\n","INFO:tensorflow:global step 199848: loss = 0.0314 (3.595 sec/step)\n","I0611 14:04:07.656738 140666084398976 learning.py:507] global step 199848: loss = 0.0314 (3.595 sec/step)\n","INFO:tensorflow:global step 199849: loss = 0.0345 (3.506 sec/step)\n","I0611 14:04:11.163987 140666084398976 learning.py:507] global step 199849: loss = 0.0345 (3.506 sec/step)\n","INFO:tensorflow:global step 199850: loss = 0.0433 (3.551 sec/step)\n","I0611 14:04:14.716626 140666084398976 learning.py:507] global step 199850: loss = 0.0433 (3.551 sec/step)\n","INFO:tensorflow:global step 199851: loss = 0.0315 (3.527 sec/step)\n","I0611 14:04:18.245496 140666084398976 learning.py:507] global step 199851: loss = 0.0315 (3.527 sec/step)\n","INFO:tensorflow:global step 199852: loss = 0.0464 (3.539 sec/step)\n","I0611 14:04:21.786147 140666084398976 learning.py:507] global step 199852: loss = 0.0464 (3.539 sec/step)\n","INFO:tensorflow:global step 199853: loss = 0.0240 (3.461 sec/step)\n","I0611 14:04:25.249283 140666084398976 learning.py:507] global step 199853: loss = 0.0240 (3.461 sec/step)\n","INFO:tensorflow:global step 199854: loss = 0.0247 (3.445 sec/step)\n","I0611 14:04:28.696417 140666084398976 learning.py:507] global step 199854: loss = 0.0247 (3.445 sec/step)\n","INFO:tensorflow:global step 199855: loss = 0.0407 (3.484 sec/step)\n","I0611 14:04:32.182157 140666084398976 learning.py:507] global step 199855: loss = 0.0407 (3.484 sec/step)\n","INFO:tensorflow:global step 199856: loss = 0.0383 (3.454 sec/step)\n","I0611 14:04:35.639017 140666084398976 learning.py:507] global step 199856: loss = 0.0383 (3.454 sec/step)\n","INFO:tensorflow:global step 199857: loss = 0.0318 (3.501 sec/step)\n","I0611 14:04:39.142204 140666084398976 learning.py:507] global step 199857: loss = 0.0318 (3.501 sec/step)\n","INFO:tensorflow:global step 199858: loss = 0.0272 (3.621 sec/step)\n","I0611 14:04:42.764421 140666084398976 learning.py:507] global step 199858: loss = 0.0272 (3.621 sec/step)\n","INFO:tensorflow:global step 199859: loss = 0.0308 (3.444 sec/step)\n","I0611 14:04:46.210370 140666084398976 learning.py:507] global step 199859: loss = 0.0308 (3.444 sec/step)\n","INFO:tensorflow:global step 199860: loss = 0.0547 (3.428 sec/step)\n","I0611 14:04:49.640704 140666084398976 learning.py:507] global step 199860: loss = 0.0547 (3.428 sec/step)\n","INFO:tensorflow:global step 199861: loss = 0.0265 (3.548 sec/step)\n","I0611 14:04:53.190262 140666084398976 learning.py:507] global step 199861: loss = 0.0265 (3.548 sec/step)\n","INFO:tensorflow:global step 199862: loss = 0.0309 (3.475 sec/step)\n","I0611 14:04:56.667240 140666084398976 learning.py:507] global step 199862: loss = 0.0309 (3.475 sec/step)\n","INFO:tensorflow:global step 199863: loss = 0.0387 (3.533 sec/step)\n","I0611 14:05:00.202357 140666084398976 learning.py:507] global step 199863: loss = 0.0387 (3.533 sec/step)\n","INFO:tensorflow:global step 199864: loss = 0.0318 (3.507 sec/step)\n","I0611 14:05:03.711448 140666084398976 learning.py:507] global step 199864: loss = 0.0318 (3.507 sec/step)\n","INFO:tensorflow:global step 199865: loss = 0.0323 (3.569 sec/step)\n","I0611 14:05:07.282324 140666084398976 learning.py:507] global step 199865: loss = 0.0323 (3.569 sec/step)\n","INFO:tensorflow:global step 199866: loss = 0.0261 (3.555 sec/step)\n","I0611 14:05:10.839246 140666084398976 learning.py:507] global step 199866: loss = 0.0261 (3.555 sec/step)\n","INFO:tensorflow:global step 199867: loss = 0.0329 (3.444 sec/step)\n","I0611 14:05:14.285485 140666084398976 learning.py:507] global step 199867: loss = 0.0329 (3.444 sec/step)\n","INFO:tensorflow:global step 199868: loss = 0.0300 (3.515 sec/step)\n","I0611 14:05:17.802482 140666084398976 learning.py:507] global step 199868: loss = 0.0300 (3.515 sec/step)\n","INFO:tensorflow:global step 199869: loss = 0.0306 (3.525 sec/step)\n","I0611 14:05:21.333787 140666084398976 learning.py:507] global step 199869: loss = 0.0306 (3.525 sec/step)\n","INFO:tensorflow:global step 199870: loss = 0.0506 (3.498 sec/step)\n","I0611 14:05:24.834955 140666084398976 learning.py:507] global step 199870: loss = 0.0506 (3.498 sec/step)\n","INFO:tensorflow:global step 199871: loss = 0.0261 (3.589 sec/step)\n","I0611 14:05:28.425783 140666084398976 learning.py:507] global step 199871: loss = 0.0261 (3.589 sec/step)\n","INFO:tensorflow:global step 199872: loss = 0.0379 (3.545 sec/step)\n","I0611 14:05:31.972951 140666084398976 learning.py:507] global step 199872: loss = 0.0379 (3.545 sec/step)\n","INFO:tensorflow:global step 199873: loss = 0.0441 (3.768 sec/step)\n","I0611 14:05:35.742822 140666084398976 learning.py:507] global step 199873: loss = 0.0441 (3.768 sec/step)\n","INFO:tensorflow:global step 199874: loss = 0.0371 (4.498 sec/step)\n","I0611 14:05:40.310605 140666084398976 learning.py:507] global step 199874: loss = 0.0371 (4.498 sec/step)\n","INFO:tensorflow:Recording summary at step 199874.\n","I0611 14:05:41.474543 140662738253568 supervisor.py:1050] Recording summary at step 199874.\n","INFO:tensorflow:global step 199875: loss = 0.0447 (3.779 sec/step)\n","I0611 14:05:44.093688 140666084398976 learning.py:507] global step 199875: loss = 0.0447 (3.779 sec/step)\n","INFO:tensorflow:global step 199876: loss = 0.0334 (3.564 sec/step)\n","I0611 14:05:47.659496 140666084398976 learning.py:507] global step 199876: loss = 0.0334 (3.564 sec/step)\n","INFO:tensorflow:global step 199877: loss = 0.0370 (3.424 sec/step)\n","I0611 14:05:51.085300 140666084398976 learning.py:507] global step 199877: loss = 0.0370 (3.424 sec/step)\n","INFO:tensorflow:global step 199878: loss = 0.0257 (3.528 sec/step)\n","I0611 14:05:54.614700 140666084398976 learning.py:507] global step 199878: loss = 0.0257 (3.528 sec/step)\n","INFO:tensorflow:global step 199879: loss = 0.0257 (3.472 sec/step)\n","I0611 14:05:58.088851 140666084398976 learning.py:507] global step 199879: loss = 0.0257 (3.472 sec/step)\n","INFO:tensorflow:global step 199880: loss = 0.0308 (3.465 sec/step)\n","I0611 14:06:01.555721 140666084398976 learning.py:507] global step 199880: loss = 0.0308 (3.465 sec/step)\n","INFO:tensorflow:global step 199881: loss = 0.0335 (3.588 sec/step)\n","I0611 14:06:05.145783 140666084398976 learning.py:507] global step 199881: loss = 0.0335 (3.588 sec/step)\n","INFO:tensorflow:global step 199882: loss = 0.0460 (3.576 sec/step)\n","I0611 14:06:08.723052 140666084398976 learning.py:507] global step 199882: loss = 0.0460 (3.576 sec/step)\n","INFO:tensorflow:global step 199883: loss = 0.0426 (3.494 sec/step)\n","I0611 14:06:12.218900 140666084398976 learning.py:507] global step 199883: loss = 0.0426 (3.494 sec/step)\n","INFO:tensorflow:global step 199884: loss = 0.0369 (3.454 sec/step)\n","I0611 14:06:15.674724 140666084398976 learning.py:507] global step 199884: loss = 0.0369 (3.454 sec/step)\n","INFO:tensorflow:global step 199885: loss = 0.0304 (3.659 sec/step)\n","I0611 14:06:19.335355 140666084398976 learning.py:507] global step 199885: loss = 0.0304 (3.659 sec/step)\n","INFO:tensorflow:global step 199886: loss = 0.0328 (3.438 sec/step)\n","I0611 14:06:22.775029 140666084398976 learning.py:507] global step 199886: loss = 0.0328 (3.438 sec/step)\n","INFO:tensorflow:global step 199887: loss = 0.0246 (3.457 sec/step)\n","I0611 14:06:26.234254 140666084398976 learning.py:507] global step 199887: loss = 0.0246 (3.457 sec/step)\n","INFO:tensorflow:global step 199888: loss = 0.0373 (3.475 sec/step)\n","I0611 14:06:29.710607 140666084398976 learning.py:507] global step 199888: loss = 0.0373 (3.475 sec/step)\n","INFO:tensorflow:global step 199889: loss = 0.0425 (3.546 sec/step)\n","I0611 14:06:33.259071 140666084398976 learning.py:507] global step 199889: loss = 0.0425 (3.546 sec/step)\n","INFO:tensorflow:global step 199890: loss = 0.0373 (3.484 sec/step)\n","I0611 14:06:36.744724 140666084398976 learning.py:507] global step 199890: loss = 0.0373 (3.484 sec/step)\n","INFO:tensorflow:global step 199891: loss = 0.0403 (3.580 sec/step)\n","I0611 14:06:40.326852 140666084398976 learning.py:507] global step 199891: loss = 0.0403 (3.580 sec/step)\n","INFO:tensorflow:global step 199892: loss = 0.0337 (3.476 sec/step)\n","I0611 14:06:43.804736 140666084398976 learning.py:507] global step 199892: loss = 0.0337 (3.476 sec/step)\n","INFO:tensorflow:global step 199893: loss = 0.0439 (3.488 sec/step)\n","I0611 14:06:47.294366 140666084398976 learning.py:507] global step 199893: loss = 0.0439 (3.488 sec/step)\n","INFO:tensorflow:global step 199894: loss = 0.0494 (3.561 sec/step)\n","I0611 14:06:50.857544 140666084398976 learning.py:507] global step 199894: loss = 0.0494 (3.561 sec/step)\n","INFO:tensorflow:global step 199895: loss = 0.0443 (3.486 sec/step)\n","I0611 14:06:54.345325 140666084398976 learning.py:507] global step 199895: loss = 0.0443 (3.486 sec/step)\n","INFO:tensorflow:global step 199896: loss = 0.0269 (3.436 sec/step)\n","I0611 14:06:57.782802 140666084398976 learning.py:507] global step 199896: loss = 0.0269 (3.436 sec/step)\n","INFO:tensorflow:global step 199897: loss = 0.0243 (3.425 sec/step)\n","I0611 14:07:01.209992 140666084398976 learning.py:507] global step 199897: loss = 0.0243 (3.425 sec/step)\n","INFO:tensorflow:global step 199898: loss = 0.0318 (3.492 sec/step)\n","I0611 14:07:04.703265 140666084398976 learning.py:507] global step 199898: loss = 0.0318 (3.492 sec/step)\n","INFO:tensorflow:global step 199899: loss = 0.0413 (3.477 sec/step)\n","I0611 14:07:08.182190 140666084398976 learning.py:507] global step 199899: loss = 0.0413 (3.477 sec/step)\n","INFO:tensorflow:global step 199900: loss = 0.0247 (3.459 sec/step)\n","I0611 14:07:11.643422 140666084398976 learning.py:507] global step 199900: loss = 0.0247 (3.459 sec/step)\n","INFO:tensorflow:global step 199901: loss = 0.0285 (3.459 sec/step)\n","I0611 14:07:15.103965 140666084398976 learning.py:507] global step 199901: loss = 0.0285 (3.459 sec/step)\n","INFO:tensorflow:global step 199902: loss = 0.0271 (3.429 sec/step)\n","I0611 14:07:18.535205 140666084398976 learning.py:507] global step 199902: loss = 0.0271 (3.429 sec/step)\n","INFO:tensorflow:global step 199903: loss = 0.0230 (3.460 sec/step)\n","I0611 14:07:21.997489 140666084398976 learning.py:507] global step 199903: loss = 0.0230 (3.460 sec/step)\n","INFO:tensorflow:global step 199904: loss = 0.0225 (3.558 sec/step)\n","I0611 14:07:25.557748 140666084398976 learning.py:507] global step 199904: loss = 0.0225 (3.558 sec/step)\n","INFO:tensorflow:global step 199905: loss = 0.0318 (3.474 sec/step)\n","I0611 14:07:29.034729 140666084398976 learning.py:507] global step 199905: loss = 0.0318 (3.474 sec/step)\n","INFO:tensorflow:global step 199906: loss = 0.0328 (3.526 sec/step)\n","I0611 14:07:32.563535 140666084398976 learning.py:507] global step 199906: loss = 0.0328 (3.526 sec/step)\n","INFO:tensorflow:global step 199907: loss = 0.0378 (3.778 sec/step)\n","I0611 14:07:36.347751 140666084398976 learning.py:507] global step 199907: loss = 0.0378 (3.778 sec/step)\n","INFO:tensorflow:Recording summary at step 199907.\n","I0611 14:07:38.415204 140662738253568 supervisor.py:1050] Recording summary at step 199907.\n","INFO:tensorflow:global step 199908: loss = 0.0368 (4.564 sec/step)\n","I0611 14:07:40.914174 140666084398976 learning.py:507] global step 199908: loss = 0.0368 (4.564 sec/step)\n","INFO:tensorflow:global step 199909: loss = 0.0272 (3.519 sec/step)\n","I0611 14:07:44.435224 140666084398976 learning.py:507] global step 199909: loss = 0.0272 (3.519 sec/step)\n","INFO:tensorflow:global step 199910: loss = 0.0433 (3.601 sec/step)\n","I0611 14:07:48.038159 140666084398976 learning.py:507] global step 199910: loss = 0.0433 (3.601 sec/step)\n","INFO:tensorflow:global step 199911: loss = 0.0476 (3.598 sec/step)\n","I0611 14:07:51.641515 140666084398976 learning.py:507] global step 199911: loss = 0.0476 (3.598 sec/step)\n","INFO:tensorflow:global step 199912: loss = 0.0422 (3.468 sec/step)\n","I0611 14:07:55.111642 140666084398976 learning.py:507] global step 199912: loss = 0.0422 (3.468 sec/step)\n","INFO:tensorflow:global step 199913: loss = 0.0336 (3.504 sec/step)\n","I0611 14:07:58.617084 140666084398976 learning.py:507] global step 199913: loss = 0.0336 (3.504 sec/step)\n","INFO:tensorflow:global step 199914: loss = 0.0340 (3.472 sec/step)\n","I0611 14:08:02.090738 140666084398976 learning.py:507] global step 199914: loss = 0.0340 (3.472 sec/step)\n","INFO:tensorflow:global step 199915: loss = 0.0378 (3.452 sec/step)\n","I0611 14:08:05.544641 140666084398976 learning.py:507] global step 199915: loss = 0.0378 (3.452 sec/step)\n","INFO:tensorflow:global step 199916: loss = 0.0394 (3.502 sec/step)\n","I0611 14:08:09.048420 140666084398976 learning.py:507] global step 199916: loss = 0.0394 (3.502 sec/step)\n","INFO:tensorflow:global step 199917: loss = 0.0407 (3.635 sec/step)\n","I0611 14:08:12.685348 140666084398976 learning.py:507] global step 199917: loss = 0.0407 (3.635 sec/step)\n","INFO:tensorflow:global step 199918: loss = 0.0335 (3.436 sec/step)\n","I0611 14:08:16.123009 140666084398976 learning.py:507] global step 199918: loss = 0.0335 (3.436 sec/step)\n","INFO:tensorflow:global step 199919: loss = 0.0312 (3.574 sec/step)\n","I0611 14:08:19.699044 140666084398976 learning.py:507] global step 199919: loss = 0.0312 (3.574 sec/step)\n","INFO:tensorflow:global step 199920: loss = 0.0281 (3.507 sec/step)\n","I0611 14:08:23.207857 140666084398976 learning.py:507] global step 199920: loss = 0.0281 (3.507 sec/step)\n","INFO:tensorflow:global step 199921: loss = 0.0289 (3.490 sec/step)\n","I0611 14:08:26.699270 140666084398976 learning.py:507] global step 199921: loss = 0.0289 (3.490 sec/step)\n","INFO:tensorflow:global step 199922: loss = 0.0347 (3.509 sec/step)\n","I0611 14:08:30.210535 140666084398976 learning.py:507] global step 199922: loss = 0.0347 (3.509 sec/step)\n","INFO:tensorflow:global step 199923: loss = 0.0571 (3.489 sec/step)\n","I0611 14:08:33.701018 140666084398976 learning.py:507] global step 199923: loss = 0.0571 (3.489 sec/step)\n","INFO:tensorflow:global step 199924: loss = 0.0334 (3.436 sec/step)\n","I0611 14:08:37.138314 140666084398976 learning.py:507] global step 199924: loss = 0.0334 (3.436 sec/step)\n","INFO:tensorflow:global step 199925: loss = 0.0327 (3.576 sec/step)\n","I0611 14:08:40.716483 140666084398976 learning.py:507] global step 199925: loss = 0.0327 (3.576 sec/step)\n","INFO:tensorflow:global step 199926: loss = 0.0233 (3.495 sec/step)\n","I0611 14:08:44.213371 140666084398976 learning.py:507] global step 199926: loss = 0.0233 (3.495 sec/step)\n","INFO:tensorflow:global step 199927: loss = 0.0577 (3.526 sec/step)\n","I0611 14:08:47.741249 140666084398976 learning.py:507] global step 199927: loss = 0.0577 (3.526 sec/step)\n","INFO:tensorflow:global step 199928: loss = 0.0408 (3.621 sec/step)\n","I0611 14:08:51.364309 140666084398976 learning.py:507] global step 199928: loss = 0.0408 (3.621 sec/step)\n","INFO:tensorflow:global step 199929: loss = 0.0361 (3.621 sec/step)\n","I0611 14:08:54.986779 140666084398976 learning.py:507] global step 199929: loss = 0.0361 (3.621 sec/step)\n","INFO:tensorflow:global step 199930: loss = 0.0325 (3.525 sec/step)\n","I0611 14:08:58.514199 140666084398976 learning.py:507] global step 199930: loss = 0.0325 (3.525 sec/step)\n","INFO:tensorflow:global step 199931: loss = 0.0297 (3.445 sec/step)\n","I0611 14:09:01.961915 140666084398976 learning.py:507] global step 199931: loss = 0.0297 (3.445 sec/step)\n","INFO:tensorflow:global step 199932: loss = 0.0296 (3.512 sec/step)\n","I0611 14:09:05.476527 140666084398976 learning.py:507] global step 199932: loss = 0.0296 (3.512 sec/step)\n","INFO:tensorflow:global step 199933: loss = 0.0439 (3.583 sec/step)\n","I0611 14:09:09.061544 140666084398976 learning.py:507] global step 199933: loss = 0.0439 (3.583 sec/step)\n","INFO:tensorflow:global step 199934: loss = 0.0247 (3.572 sec/step)\n","I0611 14:09:12.636002 140666084398976 learning.py:507] global step 199934: loss = 0.0247 (3.572 sec/step)\n","INFO:tensorflow:global step 199935: loss = 0.0262 (3.536 sec/step)\n","I0611 14:09:16.174263 140666084398976 learning.py:507] global step 199935: loss = 0.0262 (3.536 sec/step)\n","INFO:tensorflow:global step 199936: loss = 0.0301 (3.435 sec/step)\n","I0611 14:09:19.611013 140666084398976 learning.py:507] global step 199936: loss = 0.0301 (3.435 sec/step)\n","INFO:tensorflow:global step 199937: loss = 0.0240 (3.447 sec/step)\n","I0611 14:09:23.059336 140666084398976 learning.py:507] global step 199937: loss = 0.0240 (3.447 sec/step)\n","INFO:tensorflow:global step 199938: loss = 0.0277 (3.418 sec/step)\n","I0611 14:09:26.479115 140666084398976 learning.py:507] global step 199938: loss = 0.0277 (3.418 sec/step)\n","INFO:tensorflow:global step 199939: loss = 0.0306 (3.465 sec/step)\n","I0611 14:09:29.946051 140666084398976 learning.py:507] global step 199939: loss = 0.0306 (3.465 sec/step)\n","INFO:tensorflow:global step 199940: loss = 0.0264 (3.541 sec/step)\n","I0611 14:09:33.489470 140666084398976 learning.py:507] global step 199940: loss = 0.0264 (3.541 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I0611 14:09:33.574031 140662755038976 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:global step 199941: loss = 0.0451 (4.146 sec/step)\n","I0611 14:09:37.642618 140666084398976 learning.py:507] global step 199941: loss = 0.0451 (4.146 sec/step)\n","INFO:tensorflow:Recording summary at step 199941.\n","I0611 14:09:39.813350 140662738253568 supervisor.py:1050] Recording summary at step 199941.\n","INFO:tensorflow:global step 199942: loss = 0.0281 (3.822 sec/step)\n","I0611 14:09:42.319010 140666084398976 learning.py:507] global step 199942: loss = 0.0281 (3.822 sec/step)\n","INFO:tensorflow:global step 199943: loss = 0.0335 (3.498 sec/step)\n","I0611 14:09:45.818695 140666084398976 learning.py:507] global step 199943: loss = 0.0335 (3.498 sec/step)\n","INFO:tensorflow:global step 199944: loss = 0.0358 (3.468 sec/step)\n","I0611 14:09:49.288608 140666084398976 learning.py:507] global step 199944: loss = 0.0358 (3.468 sec/step)\n","INFO:tensorflow:global step 199945: loss = 0.0286 (3.461 sec/step)\n","I0611 14:09:52.751072 140666084398976 learning.py:507] global step 199945: loss = 0.0286 (3.461 sec/step)\n","INFO:tensorflow:global step 199946: loss = 0.0277 (3.468 sec/step)\n","I0611 14:09:56.221761 140666084398976 learning.py:507] global step 199946: loss = 0.0277 (3.468 sec/step)\n","INFO:tensorflow:global step 199947: loss = 0.0342 (3.477 sec/step)\n","I0611 14:09:59.700737 140666084398976 learning.py:507] global step 199947: loss = 0.0342 (3.477 sec/step)\n","INFO:tensorflow:global step 199948: loss = 0.0459 (3.521 sec/step)\n","I0611 14:10:03.223601 140666084398976 learning.py:507] global step 199948: loss = 0.0459 (3.521 sec/step)\n","INFO:tensorflow:global step 199949: loss = 0.0368 (3.450 sec/step)\n","I0611 14:10:06.675837 140666084398976 learning.py:507] global step 199949: loss = 0.0368 (3.450 sec/step)\n","INFO:tensorflow:global step 199950: loss = 0.0248 (3.455 sec/step)\n","I0611 14:10:10.132221 140666084398976 learning.py:507] global step 199950: loss = 0.0248 (3.455 sec/step)\n","INFO:tensorflow:global step 199951: loss = 0.0269 (3.498 sec/step)\n","I0611 14:10:13.631802 140666084398976 learning.py:507] global step 199951: loss = 0.0269 (3.498 sec/step)\n","INFO:tensorflow:global step 199952: loss = 0.0249 (3.506 sec/step)\n","I0611 14:10:17.140250 140666084398976 learning.py:507] global step 199952: loss = 0.0249 (3.506 sec/step)\n","INFO:tensorflow:global step 199953: loss = 0.0287 (3.491 sec/step)\n","I0611 14:10:20.633951 140666084398976 learning.py:507] global step 199953: loss = 0.0287 (3.491 sec/step)\n","INFO:tensorflow:global step 199954: loss = 0.0538 (3.562 sec/step)\n","I0611 14:10:24.198043 140666084398976 learning.py:507] global step 199954: loss = 0.0538 (3.562 sec/step)\n","INFO:tensorflow:global step 199955: loss = 0.0378 (3.507 sec/step)\n","I0611 14:10:27.706465 140666084398976 learning.py:507] global step 199955: loss = 0.0378 (3.507 sec/step)\n","INFO:tensorflow:global step 199956: loss = 0.0358 (3.528 sec/step)\n","I0611 14:10:31.235757 140666084398976 learning.py:507] global step 199956: loss = 0.0358 (3.528 sec/step)\n","INFO:tensorflow:global step 199957: loss = 0.0336 (3.564 sec/step)\n","I0611 14:10:34.801170 140666084398976 learning.py:507] global step 199957: loss = 0.0336 (3.564 sec/step)\n","INFO:tensorflow:global step 199958: loss = 0.0391 (3.506 sec/step)\n","I0611 14:10:38.309275 140666084398976 learning.py:507] global step 199958: loss = 0.0391 (3.506 sec/step)\n","INFO:tensorflow:global step 199959: loss = 0.0330 (3.461 sec/step)\n","I0611 14:10:41.771684 140666084398976 learning.py:507] global step 199959: loss = 0.0330 (3.461 sec/step)\n","INFO:tensorflow:global step 199960: loss = 0.0383 (3.449 sec/step)\n","I0611 14:10:45.222523 140666084398976 learning.py:507] global step 199960: loss = 0.0383 (3.449 sec/step)\n","INFO:tensorflow:global step 199961: loss = 0.0234 (3.425 sec/step)\n","I0611 14:10:48.649744 140666084398976 learning.py:507] global step 199961: loss = 0.0234 (3.425 sec/step)\n","INFO:tensorflow:global step 199962: loss = 0.0348 (3.547 sec/step)\n","I0611 14:10:52.199209 140666084398976 learning.py:507] global step 199962: loss = 0.0348 (3.547 sec/step)\n","INFO:tensorflow:global step 199963: loss = 0.0393 (3.511 sec/step)\n","I0611 14:10:55.711796 140666084398976 learning.py:507] global step 199963: loss = 0.0393 (3.511 sec/step)\n","INFO:tensorflow:global step 199964: loss = 0.0361 (3.448 sec/step)\n","I0611 14:10:59.161728 140666084398976 learning.py:507] global step 199964: loss = 0.0361 (3.448 sec/step)\n","INFO:tensorflow:global step 199965: loss = 0.0518 (3.449 sec/step)\n","I0611 14:11:02.612103 140666084398976 learning.py:507] global step 199965: loss = 0.0518 (3.449 sec/step)\n","INFO:tensorflow:global step 199966: loss = 0.0327 (3.552 sec/step)\n","I0611 14:11:06.166111 140666084398976 learning.py:507] global step 199966: loss = 0.0327 (3.552 sec/step)\n","INFO:tensorflow:global step 199967: loss = 0.0371 (3.493 sec/step)\n","I0611 14:11:09.661189 140666084398976 learning.py:507] global step 199967: loss = 0.0371 (3.493 sec/step)\n","INFO:tensorflow:global step 199968: loss = 0.0270 (3.507 sec/step)\n","I0611 14:11:13.170328 140666084398976 learning.py:507] global step 199968: loss = 0.0270 (3.507 sec/step)\n","INFO:tensorflow:global step 199969: loss = 0.0291 (3.462 sec/step)\n","I0611 14:11:16.633841 140666084398976 learning.py:507] global step 199969: loss = 0.0291 (3.462 sec/step)\n","INFO:tensorflow:global step 199970: loss = 0.0369 (3.495 sec/step)\n","I0611 14:11:20.130748 140666084398976 learning.py:507] global step 199970: loss = 0.0369 (3.495 sec/step)\n","INFO:tensorflow:global step 199971: loss = 0.0471 (3.470 sec/step)\n","I0611 14:11:23.603540 140666084398976 learning.py:507] global step 199971: loss = 0.0471 (3.470 sec/step)\n","INFO:tensorflow:global step 199972: loss = 0.0350 (3.555 sec/step)\n","I0611 14:11:27.159998 140666084398976 learning.py:507] global step 199972: loss = 0.0350 (3.555 sec/step)\n","INFO:tensorflow:global step 199973: loss = 0.0280 (3.470 sec/step)\n","I0611 14:11:30.631788 140666084398976 learning.py:507] global step 199973: loss = 0.0280 (3.470 sec/step)\n","INFO:tensorflow:global step 199974: loss = 0.0268 (3.546 sec/step)\n","I0611 14:11:34.310963 140666084398976 learning.py:507] global step 199974: loss = 0.0268 (3.546 sec/step)\n","INFO:tensorflow:global step 199975: loss = 0.0414 (4.747 sec/step)\n","I0611 14:11:39.079268 140666084398976 learning.py:507] global step 199975: loss = 0.0414 (4.747 sec/step)\n","INFO:tensorflow:Recording summary at step 199975.\n","I0611 14:11:40.217886 140662738253568 supervisor.py:1050] Recording summary at step 199975.\n","INFO:tensorflow:global step 199976: loss = 0.0303 (3.702 sec/step)\n","I0611 14:11:42.818544 140666084398976 learning.py:507] global step 199976: loss = 0.0303 (3.702 sec/step)\n","INFO:tensorflow:global step 199977: loss = 0.0252 (3.460 sec/step)\n","I0611 14:11:46.280343 140666084398976 learning.py:507] global step 199977: loss = 0.0252 (3.460 sec/step)\n","INFO:tensorflow:global step 199978: loss = 0.0338 (3.581 sec/step)\n","I0611 14:11:49.863059 140666084398976 learning.py:507] global step 199978: loss = 0.0338 (3.581 sec/step)\n","INFO:tensorflow:global step 199979: loss = 0.0512 (3.437 sec/step)\n","I0611 14:11:53.302416 140666084398976 learning.py:507] global step 199979: loss = 0.0512 (3.437 sec/step)\n","INFO:tensorflow:global step 199980: loss = 0.0384 (3.442 sec/step)\n","I0611 14:11:56.747023 140666084398976 learning.py:507] global step 199980: loss = 0.0384 (3.442 sec/step)\n","INFO:tensorflow:global step 199981: loss = 0.0425 (3.455 sec/step)\n","I0611 14:12:00.203628 140666084398976 learning.py:507] global step 199981: loss = 0.0425 (3.455 sec/step)\n","INFO:tensorflow:global step 199982: loss = 0.0414 (3.506 sec/step)\n","I0611 14:12:03.711255 140666084398976 learning.py:507] global step 199982: loss = 0.0414 (3.506 sec/step)\n","INFO:tensorflow:global step 199983: loss = 0.0301 (3.475 sec/step)\n","I0611 14:12:07.188043 140666084398976 learning.py:507] global step 199983: loss = 0.0301 (3.475 sec/step)\n","INFO:tensorflow:global step 199984: loss = 0.0343 (3.491 sec/step)\n","I0611 14:12:10.681535 140666084398976 learning.py:507] global step 199984: loss = 0.0343 (3.491 sec/step)\n","INFO:tensorflow:global step 199985: loss = 0.0409 (3.590 sec/step)\n","I0611 14:12:14.273636 140666084398976 learning.py:507] global step 199985: loss = 0.0409 (3.590 sec/step)\n","INFO:tensorflow:global step 199986: loss = 0.0386 (3.493 sec/step)\n","I0611 14:12:17.768877 140666084398976 learning.py:507] global step 199986: loss = 0.0386 (3.493 sec/step)\n","INFO:tensorflow:global step 199987: loss = 0.0300 (3.411 sec/step)\n","I0611 14:12:21.182379 140666084398976 learning.py:507] global step 199987: loss = 0.0300 (3.411 sec/step)\n","INFO:tensorflow:global step 199988: loss = 0.0452 (3.442 sec/step)\n","I0611 14:12:24.626339 140666084398976 learning.py:507] global step 199988: loss = 0.0452 (3.442 sec/step)\n","INFO:tensorflow:global step 199989: loss = 0.0300 (3.431 sec/step)\n","I0611 14:12:28.059176 140666084398976 learning.py:507] global step 199989: loss = 0.0300 (3.431 sec/step)\n","INFO:tensorflow:global step 199990: loss = 0.0324 (3.497 sec/step)\n","I0611 14:12:31.558238 140666084398976 learning.py:507] global step 199990: loss = 0.0324 (3.497 sec/step)\n","INFO:tensorflow:global step 199991: loss = 0.0258 (3.499 sec/step)\n","I0611 14:12:35.058975 140666084398976 learning.py:507] global step 199991: loss = 0.0258 (3.499 sec/step)\n","INFO:tensorflow:global step 199992: loss = 0.0295 (3.489 sec/step)\n","I0611 14:12:38.549400 140666084398976 learning.py:507] global step 199992: loss = 0.0295 (3.489 sec/step)\n","INFO:tensorflow:global step 199993: loss = 0.0353 (3.498 sec/step)\n","I0611 14:12:42.049135 140666084398976 learning.py:507] global step 199993: loss = 0.0353 (3.498 sec/step)\n","INFO:tensorflow:global step 199994: loss = 0.0320 (3.408 sec/step)\n","I0611 14:12:45.459629 140666084398976 learning.py:507] global step 199994: loss = 0.0320 (3.408 sec/step)\n","INFO:tensorflow:global step 199995: loss = 0.0338 (3.644 sec/step)\n","I0611 14:12:49.105467 140666084398976 learning.py:507] global step 199995: loss = 0.0338 (3.644 sec/step)\n","INFO:tensorflow:global step 199996: loss = 0.0330 (3.622 sec/step)\n","I0611 14:12:52.729205 140666084398976 learning.py:507] global step 199996: loss = 0.0330 (3.622 sec/step)\n","INFO:tensorflow:global step 199997: loss = 0.0525 (3.472 sec/step)\n","I0611 14:12:56.202876 140666084398976 learning.py:507] global step 199997: loss = 0.0525 (3.472 sec/step)\n","INFO:tensorflow:global step 199998: loss = 0.0368 (3.425 sec/step)\n","I0611 14:12:59.629405 140666084398976 learning.py:507] global step 199998: loss = 0.0368 (3.425 sec/step)\n","INFO:tensorflow:global step 199999: loss = 0.0432 (3.480 sec/step)\n","I0611 14:13:03.111957 140666084398976 learning.py:507] global step 199999: loss = 0.0432 (3.480 sec/step)\n","INFO:tensorflow:global step 200000: loss = 0.0499 (3.526 sec/step)\n","I0611 14:13:06.641277 140666084398976 learning.py:507] global step 200000: loss = 0.0499 (3.526 sec/step)\n","INFO:tensorflow:Stopping Training.\n","I0611 14:13:06.642226 140666084398976 learning.py:777] Stopping Training.\n","INFO:tensorflow:Finished training! Saving model to disk.\n","I0611 14:13:06.642493 140666084398976 learning.py:785] Finished training! Saving model to disk.\n","/tensorflow-1.15.2/python3.6/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n","  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B_DYeGWR7-iZ","colab_type":"code","colab":{}},"source":["!cp -r training /mydrive/faster_here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYjvCHqyCgvM","colab_type":"code","colab":{}},"source":["LOG_DIR = 'training'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","# Install\n","! npm install -g localtunnel\n","! npm i -g npm\n","# Tunnel port 6006 (TensorBoard assumed running)\n","get_ipython().system_raw('lt --port 6006 >> url1.txt 2>&1 &')\n","# Get url\n","! cat url1.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vLysjioia7Pi","colab_type":"code","colab":{}},"source":["!cp -r ./training ./test_images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahbgyVBZGK_x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587244365274,"user_tz":-330,"elapsed":1735,"user":{"displayName":"David ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgknDk-_2Sv7OVT1kJSPyQUI1x1Sjj2EFb84IU8=s64","userId":"11929545398087895742"}},"outputId":"e570519b-9a37-4748-8409-350dceeadf2d"},"source":["%cd ./tensorflow/models/research/object_detection"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/tensorflow/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kkhHiqzyHOH9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587661380420,"user_tz":-330,"elapsed":8369,"user":{"displayName":"David ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgknDk-_2Sv7OVT1kJSPyQUI1x1Sjj2EFb84IU8=s64","userId":"11929545398087895742"}},"outputId":"0794ff76-efb9-48e1-eeb4-7266161e19a2"},"source":["!bash -c 'mv training/checkpoint content/mydrive/faster/training'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mv: cannot move 'training/checkpoint' to 'content/mydrive/faster/training': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7LMIBm6q_fn3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587906720359,"user_tz":-330,"elapsed":1539,"user":{"displayName":"David ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgknDk-_2Sv7OVT1kJSPyQUI1x1Sjj2EFb84IU8=s64","userId":"11929545398087895742"}},"outputId":"45570af0-9983-4a02-d608-d160393818dd"},"source":["%cd ./tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/tensorflow\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wMYC9b98msc-","colab_type":"code","colab":{}},"source":["!zip -r tensorflow ./"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vzkE7MMm4MB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594040506406,"user_tz":-330,"elapsed":7781,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"c277c71e-5ccf-466d-c1cd-a67d35971457"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b5VkBkSD6GZD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594040528892,"user_tz":-330,"elapsed":1448,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"0231f1db-118a-460c-da32-c9e7f802034f"},"source":["%cd object_detection"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NwbKit36N4E7","colab_type":"code","colab":{}},"source":["!cp -r /mydrive/faster_here/training ./"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JabqvY_lO2tm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594040834906,"user_tz":-330,"elapsed":39451,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"f83e4606-f1b0-4e40-f9b7-2232a60cdb5d"},"source":["!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix training/model.ckpt-200000 --output_directory inference_graph\n","  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:375: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:399: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0706 13:06:49.157258 140477145139072 module_wrapper.py:139] From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0706 13:06:49.165651 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0706 13:06:49.165984 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0706 13:06:49.231713 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0706 13:06:49.273023 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0706 13:06:49.285360 140477145139072 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0706 13:06:51.298537 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0706 13:06:51.307685 140477145139072 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","W0706 13:06:51.308203 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0706 13:06:51.328006 140477145139072 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0706 13:06:51.328640 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0706 13:06:51.328851 140477145139072 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0706 13:06:51.406641 140477145139072 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","W0706 13:06:52.162875 140477145139072 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","W0706 13:06:52.189737 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","W0706 13:06:52.996544 140477145139072 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0706 13:06:53.003794 140477145139072 regularizers.py:98] Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","I0706 13:06:53.029438 140477145139072 regularizers.py:98] Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n","W0706 13:06:53.847066 140477145139072 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0706 13:06:54.285326 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0706 13:06:54.285662 140477145139072 deprecation.py:323] From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0706 13:06:54.289713 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0706 13:06:54.289967 140477145139072 deprecation.py:323] From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0706 13:06:54.291361 140477145139072 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","236 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/12.85m params)\n","  Conv (--/2.65m params)\n","    Conv/biases (512, 512/512 params)\n","    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n","  FirstStageBoxPredictor (--/36.94k params)\n","    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n","      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n","      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n","    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n","      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n","      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","  FirstStageFeatureExtractor (--/4.25m params)\n","    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n","      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n","      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n","      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n","        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n","        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n","          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n","  SecondStageBoxPredictor (--/16.40k params)\n","    SecondStageBoxPredictor/BoxEncodingPredictor (--/12.30k params)\n","      SecondStageBoxPredictor/BoxEncodingPredictor/biases (12, 12/12 params)\n","      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x12, 12.29k/12.29k params)\n","    SecondStageBoxPredictor/ClassPredictor (--/4.10k params)\n","      SecondStageBoxPredictor/ClassPredictor/biases (4, 4/4 params)\n","      SecondStageBoxPredictor/ClassPredictor/weights (1024x4, 4.10k/4.10k params)\n","  SecondStageFeatureExtractor (--/5.89m params)\n","    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n","      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n","      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n","      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n","        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n","          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n","            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n","\n","======================End of Report==========================\n","236 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/6.16k flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n","  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n","  map_2/while/mul_3 (300/300 flops)\n","  map_2/while/mul_2 (300/300 flops)\n","  map_2/while/mul_1 (300/300 flops)\n","  map_2/while/mul (300/300 flops)\n","  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n","  GridAnchorGenerator/mul (12/12 flops)\n","  GridAnchorGenerator/mul_1 (12/12 flops)\n","  GridAnchorGenerator/mul_2 (12/12 flops)\n","  GridAnchorGenerator/truediv (12/12 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n","  mul (1/1 flops)\n","  map_2/while/Less_1 (1/1 flops)\n","  map_2/while/Less (1/1 flops)\n","  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n","  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n","  map_1/while/Less_1 (1/1 flops)\n","  map_1/while/Less (1/1 flops)\n","  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n","  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n","  map/while/Less_1 (1/1 flops)\n","  map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n","  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n","  SecondStagePostprocessor/map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n","  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n","  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n","  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  GridAnchorGenerator/zeros/Less (1/1 flops)\n","  GridAnchorGenerator/mul_8 (1/1 flops)\n","  GridAnchorGenerator/mul_7 (1/1 flops)\n","  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n","  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","\n","======================End of Report==========================\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0706 13:06:56.115483 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0706 13:06:57.424767 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-07-06 13:06:57.428281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-07-06 13:06:57.496325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:57.497170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-06 13:06:57.497577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-06 13:06:57.732076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-06 13:06:57.866220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-06 13:06:57.888678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-06 13:06:58.162649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-06 13:06:58.194086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-06 13:06:58.725730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-06 13:06:58.726073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.726944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.727646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-06 13:06:58.745184: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2020-07-06 13:06:58.745585: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2efef40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-07-06 13:06:58.745623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-07-06 13:06:58.840331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.841267: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2eff100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-07-06 13:06:58.841303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-07-06 13:06:58.842665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.843447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-06 13:06:58.843534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-06 13:06:58.843579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-06 13:06:58.843623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-06 13:06:58.843669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-06 13:06:58.843720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-06 13:06:58.843768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-06 13:06:58.843810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-06 13:06:58.843927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.844660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.845341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-06 13:06:58.849397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-06 13:06:58.854049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-06 13:06:58.854089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-06 13:06:58.854108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-06 13:06:58.855644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.856463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:06:58.857178: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-07-06 13:06:58.857234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-200000\n","I0706 13:06:58.859549 140477145139072 saver.py:1284] Restoring parameters from training/model.ckpt-200000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0706 13:07:00.637803 140477145139072 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-07-06 13:07:01.634038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:01.634851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-06 13:07:01.634985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-06 13:07:01.635147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-06 13:07:01.635241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-06 13:07:01.635292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-06 13:07:01.635337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-06 13:07:01.635388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-06 13:07:01.635438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-06 13:07:01.635578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:01.636380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:01.637070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-06 13:07:01.637129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-06 13:07:01.637156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-06 13:07:01.637175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-06 13:07:01.637304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:01.638089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:01.638861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-200000\n","I0706 13:07:01.640552 140477145139072 saver.py:1284] Restoring parameters from training/model.ckpt-200000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0706 13:07:07.876145 140477145139072 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0706 13:07:07.876452 140477145139072 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 356 variables.\n","I0706 13:07:08.413110 140477145139072 graph_util_impl.py:334] Froze 356 variables.\n","INFO:tensorflow:Converted 356 variables to const ops.\n","I0706 13:07:08.564575 140477145139072 graph_util_impl.py:394] Converted 356 variables to const ops.\n","2020-07-06 13:07:08.826590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:08.827494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-06 13:07:08.827597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-06 13:07:08.827640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-06 13:07:08.827685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-06 13:07:08.827744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-06 13:07:08.827812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-06 13:07:08.827872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-06 13:07:08.827914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-06 13:07:08.828017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:08.828842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:08.829684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-06 13:07:08.829852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-06 13:07:08.829885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-06 13:07:08.830012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-06 13:07:08.830215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:08.831036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-06 13:07:08.831739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0706 13:07:09.464968 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0706 13:07:09.465658 140477145139072 deprecation.py:323] From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","W0706 13:07:09.466321 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0706 13:07:09.466538 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","W0706 13:07:09.466933 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","W0706 13:07:09.467164 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","INFO:tensorflow:No assets to save.\n","I0706 13:07:09.467560 140477145139072 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0706 13:07:09.467739 140477145139072 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: inference_graph/saved_model/saved_model.pb\n","I0706 13:07:09.992753 140477145139072 builder_impl.py:425] SavedModel written to: inference_graph/saved_model/saved_model.pb\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0706 13:07:10.035905 140477145139072 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","INFO:tensorflow:Writing pipeline config file to inference_graph/pipeline.config\n","I0706 13:07:10.036246 140477145139072 config_util.py:190] Writing pipeline config file to inference_graph/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VgD4sGZsX1Zz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_FtiOFfX46K","colab_type":"text"},"source":["#testing part\n"]},{"cell_type":"code","metadata":{"id":"AZgciLNuX2jP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595997504833,"user_tz":-330,"elapsed":14750,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"933d0a66-9913-4f18-a438-3e915ca23ab0"},"source":["%cd object_detection/\n","\n","!cp -r /mydrive/ssd/inference ./inference_graph/\n","!cp /mydrive/ssd/training/ssd_mobilenet_v2_coco.config ./training/\n","!cp /mydrive/ssd/training/graph.pbtxt ./training/\n","!cp /mydrive/ssd/training/labelmap.pbtxt ./training/\n","!cp /mydrive/ssd/training/pipeline.config ./training/"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EAFmJLLjX2wY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595997560001,"user_tz":-330,"elapsed":3329,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}}},"source":["!cp /mydrive/a.jpg ./validation_images/"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDalac847rJy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595999456944,"user_tz":-330,"elapsed":2589,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_6eH73APS40","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import sys\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","\n","# Import utilites\n","from utils import label_map_util\n","from utils import visualization_utils as vis_util\n","\n","# Name of the directory containing the object detection module we're using\n","MODEL_NAME = 'inference_graph'\n","IMAGE_NAME = ''\n","\n","# Grab path to current working directory\n","CWD_PATH = os.getcwd()\n","#CWD_PATH_VALIDATION = CWD_PATH+\"/validation_images/\"\n","\n","# Path to frozen detection graph .pb file, which contains the model that is used\n","# for object detection.\n","PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n","\n","# Path to label map file\n","PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n","\n","# Path to image\n","PATH_TO_IMAGE = os.path.join(CWD_PATH,IMAGE_NAME)\n","\n","# Number of classes the object detector can identify\n","NUM_CLASSES = 3\n","\n","# Load the label map.\n","# Label maps map indices to category names, so that when our convolution\n","# network predicts `5`, we know that this corresponds to `king`.\n","# Here we use internal utility functions, but anything that returns a\n","# dictionary mapping integers to appropriate string labels would be fine\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","# Load the Tensorflow model into memory.\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","    sess = tf.Session(graph=detection_graph)\n","\n","# Define input and output tensors (i.e. data) for the object detection classifier\n","\n","# Input tensor is the image\n","image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","\n","# Output tensors are the detection boxes, scores, and classes\n","# Each box represents a part of the image where a particular object was detected\n","detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","\n","# Each score represents level of confidence for each of the objects.\n","# The score is shown on the result image, together with the class label.\n","detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","\n","# Number of objects detected\n","num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n","\n","# Load image using OpenCV and\n","# expand image dimensions to have shape: [1, None, None, 3]\n","# i.e. a single-column array, where each item in the column has the pixel RGB value\n","image = cv2.imread('./validation_images/' + 'a.jpg')\n","#image = cv2.cvtColor(image1,cv2.COLOR_BGR2RGB)\n","image_expanded = np.expand_dims(image, axis=0)\n","\n","# Perform the actual detection by running the model with the image as input\n","(boxes, scores, classes, num) = sess.run(\n","    [detection_boxes, detection_scores, detection_classes, num_detections],\n","    feed_dict={image_tensor: image_expanded})\n","\n","# Draw the results of the detection (aka 'visulaize the results')\n","\n","vis_util.visualize_boxes_and_labels_on_image_array(\n","    image,\n","    np.squeeze(boxes),\n","    np.squeeze(classes).astype(np.int32),\n","    np.squeeze(scores),\n","    category_index,\n","    use_normalized_coordinates=True,\n","    line_thickness=8,\n","    min_score_thresh=0.80)\n","\n","# All the results have been drawn on image. Now display the image.\n","\n","\n","#cv2.imshow('Object detector', image)\n","#image2 = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n","\n","\n","plt.imshow(image)\n","cv2.imwrite('./validation_images/sxm1.jpg', image)\n","print('successfully saved')\n","\n","# Press any key to close the image\n","#cv2.waitKey(0)\n","\n","# Clean up\n","#cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvCTF59ab2Hp","colab_type":"code","colab":{}},"source":["!cp validation_images/sxm1.jpg /mydrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5WgOc75Z-1K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595998313369,"user_tz":-330,"elapsed":4074,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}}},"source":["!cp /mydrive/j.mp4 ./validation_images/"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6LIv6GQaHUN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"error","timestamp":1595922995086,"user_tz":-330,"elapsed":28210,"user":{"displayName":"David Ray","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtnfgSx8c7XEy1J7KjRWRx-p2osEYN68MZsm5P=s64","userId":"09700707514956701567"}},"outputId":"c5833e3d-db0d-4b5e-a816-20bc23482155"},"source":["# Import packages\n","import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import sys\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","\n","# Import utilites\n","from utils import label_map_util\n","from utils import visualization_utils as vis_util\n","\n","# Name of the directory containing the object detection module we're using\n","MODEL_NAME = 'inference_graph'\n","VIDEO_NAME = 'j.mp4'\n","\n","# Grab path to current working directory\n","CWD_PATH = os.getcwd()\n","\n","# Path to frozen detection graph .pb file, which contains the model that is used\n","# for object detection.\n","PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n","\n","# Path to label map file\n","PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n","\n","# Path to video\n","PATH_TO_VIDEO = os.path.join(CWD_PATH,VIDEO_NAME)\n","\n","# Number of classes the object detector can identify\n","NUM_CLASSES = 3\n","\n","# Load the label map.\n","# Label maps map indices to category names, so that when our convolution\n","# network predicts `5`, we know that this corresponds to `king`.\n","# Here we use internal utility functions, but anything that returns a\n","# dictionary mapping integers to appropriate string labels would be fine\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","# Load the Tensorflow model into memory.\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","    sess = tf.Session(graph=detection_graph)\n","\n","# Define input and output tensors (i.e. data) for the object detection classifier\n","\n","# Input tensor is the image\n","image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","\n","# Output tensors are the detection boxes, scores, and classes\n","# Each box represents a part of the image where a particular object was detected\n","detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","\n","# Each score represents level of confidence for each of the objects.\n","# The score is shown on the result image, together with the class label.\n","detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","\n","# Number of objects detected\n","num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n","\n","# Open video file\n","video = cv2.VideoCapture('./validation_images/' + 'j.mp4')\n","\n","fwidth = int(video.get(3))\n","fheight = int(video.get(4))\n","print(int(video.get(3)), int(video.get(4)))\n","\n","#(grabbed, frame) = video.read()\n","#fshape = frame.shape\n","#fheight = fshape[0]\n","#fwidth = fshape[1]\n","#print (fwidth , fheight)\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('output.avi',fourcc, 59.0, (fwidth,fheight))\n","\n","\n","\n","#out = cv2.VideoWriter('validation_images/outut.avi', fourcc, 20.0, (frame_width,frame_height))\n","#out = cv2.VideoWriter('./validation_images/outpyt.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (frame_width,frame_height))\n","\n","while(video.isOpened()):\n","\n","    # Acquire frame and expand frame dimensions to have shape: [1, None, None, 3]\n","    # i.e. a single-column array, where each item in the column has the pixel RGB value\n","    ret, frame = video.read()\n","    frame_expanded = np.expand_dims(frame, axis=0)\n","\n","    # Perform the actual detection by running the model with the image as input\n","    (boxes, scores, classes, num) = sess.run(\n","        [detection_boxes, detection_scores, detection_classes, num_detections],\n","        feed_dict={image_tensor: frame_expanded})\n","\n","    # Draw the results of the detection (aka 'visulaize the results')\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        frame,\n","        np.squeeze(boxes),\n","        np.squeeze(classes).astype(np.int32),\n","        np.squeeze(scores),\n","        category_index,\n","        use_normalized_coordinates=True,\n","        line_thickness=8,\n","        min_score_thresh=0.80)\n","\n","    # All the results have been drawn on the frame, so it's time to display it.\n","    \n","    \n","    #cv2.VideoWriter('outpu.avi', fourcc, 20.0, (int(video.get(3)), int(video.get(4))))\n","    if ret == True:\n","        out.write(frame)\n","       # cv2.imshow('Object detector', frame)\n","\n","    # Press 'q' to quit\n","        if cv2.waitKey(1) == ord('q'):\n","            break\n","\n","    else:\n","        break\n","\n","            \n","# Clean up\n","out.release()\n","video.release()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1280 720\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-af0ddc246893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     (boxes, scores, classes, num) = sess.run(\n\u001b[1;32m    101\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mdetection_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         feed_dict={image_tensor: frame_expanded})\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Draw the results of the detection (aka 'visulaize the results')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ESbIuJRubHLs","colab_type":"code","colab":{}},"source":["!cp output.avi /mydrive/"],"execution_count":null,"outputs":[]}]}